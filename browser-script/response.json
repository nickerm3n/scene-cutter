{
    "title": "Course: MCP Bootcamp: Build, Deploy & Secure Model Context Protocol | Udemy Business",
    "url": "https://epam.udemy.com/course/learn-mcp-model-context-protocol-course-and-a2a-bootcamphands-hands-on/learn/lecture/49740355#content",
    "sections": [
      {
        "title": "Section 1: Introduction & Environment Setup",
        "items": [
          {
            "title": "1. Welcome to the Course!",
            "videoUrl": "https://epam.udemy.com/assets/65239291/files/2025-05-19_13-24-37-b1dd2f826341532ef17fad685c8f49dd/2/aa00827ea2f808522f1696d1d3c844864791.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zNy1iMWRkMmY4MjYzNDE1MzJlZjE3ZmFkNjg1YzhmNDlkZC8yLyIsImV4cCI6MTc1NTc4Njk4Mn0.YzXm5buMMjI3ni7FL-eOivbRT_sxvkWLQxVuBdZM_qw&provider=cloudfront&v=1",
            "transcript": "Welcome to this course.\nI'm super happy to have you here.\nMy name is Dalton.\nI will be your instructor.\nI'm a long time data and ML engineer and worked with companies and delivered courses for companies like\nDatabricks, Apple, Amazon and many others.\nI'm quite excited about what's happening now in the field of agents with MCP and A to A and all these\ntechnologies coming up, I think standards emerging, it's always a great thing because it shows that\nthis space is getting kind of stabilized and more mature, and with standards, we can only just win.\nSo I'm very happy that you joined this course, and I'm sure that you will take the most out of it.\nIn the next videos we will go through the prerequisites.\nSo what you need in order to be successful in this course and also the course outline, and then we\nwill get hands on as soon as possible because I want to ensure that you can get your feet wet as soon\nas possible.\nAll right.\nSo without further ado, let's jump into the next video.",
            "dataPurpose": "item-0"
          },
          {
            "title": "2. A Note on Continuous Course Updates",
            "videoUrl": "https://epam.udemy.com/assets/65239305/files/2025-05-19_13-24-38-097375b8a66caf42a311274b9e8c2d46/2/aa0039c896c51e24d1ef10fc02cff1248fcc.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOC0wOTczNzViOGE2NmNhZjQyYTMxMTI3NGI5ZThjMmQ0Ni8yLyIsImV4cCI6MTc1NTc4NzA3N30.BSweK8S1lzuQ0J1vMREfyBS0sZG9kKSvn-T_3Co_0Hk&provider=cloudfront&v=1",
            "transcript": "Welcome to the studio.\nI just wanted to jump in to tell you that you can expect this course to be updated regularly.\nIn the first few months of this course, I would say you will get an update on a biweekly basis, so\nplease keep your eyes open for educational announcement that I send you and also join our Community\nDiscord server.\nIf you have any feedback or topic requests.\nOkay, I'm there and I'm reading that every day.\nYou will see a link to that server in the resources section.\nI'll see you in the next video.",
            "dataPurpose": "item-1"
          },
          {
            "title": "3. Course Blueprint",
            "videoUrl": "https://epam.udemy.com/assets/67059007/files/2025-07-30_08-00-25-12ac62025b8e69bfd83a26038076a32f/2/aa00d01dcd47a958b66ed2ab373a43dd2d15.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNy0zMF8wOC0wMC0yNS0xMmFjNjIwMjViOGU2OWJmZDgzYTI2MDM4MDc2YTMyZi8yLyIsImV4cCI6MTc1NTc4NzA4NX0.kxFLjw3KDc3WQ4ClWML_Raj6OFXZxoXwLFvuf7Gt4NI&provider=cloudfront&v=1",
            "transcript": "Let's talk a bit about what you can expect in this course.\nThis course follows a bottom to up approach, which means that we are starting with some theory and\nthen building our way up to more advanced use cases just to accommodate everyone who starts from scratch.\nThe course has three main components.\nFirst of all, we are going to cover just enough agentic theory so you can understand how llms work\nand what happens with Llms and LLM communication behind the scenes.\nSo you can understand how this whole concept of function calling and tool calling comes into play.\nYou will see a very, very low level example of that, because I want to ensure that you have a good\nmental model about how MCPs are able to integrate into the whole ecosystem.\nNow, while we are doing this, you will also see some hands on examples and you will be able to follow\nalong.\nAnd for this, of course we will have an environment setup piece of the course where I will show you\nhow you can get access to the resources and how to install everything on your laptop to get up and running\nwith this course.\nNow, once we are done with the agent theory, you will see a little bit more theory and that will be\nMCC and the whole architecture of MCC and what the problems are that MCC solve and just the ground work\nfor MCC.\nOkay.\nAnd once we are done with that we will be go hands on as soon as possible and we will cover three major\ntopics.\nThe first topic will be working with third party MCC.\nYou will be able to see how you can integrate Zapier into cloud and Cursor.\nAnd based on this framework, you will understand how you can use different MCC like Shopify or Gmail\nor Spotify or any other.\nThere are at the time of recording more than 1000 MCC out there.\nYou will also see a showcase of MCC hubs.\nSo those registries that collect all the third party MCC for you.\nSo if you want to explore what MCC can be useful for you, you will have a way to go and search and\ninstall those.\nOnce you are up and running with these third party MCC, then you will learn how you can implement your\nown MCP.\nWe are starting with a quite simple example.\nI will show you how you can integrate tools and then resources and prompts and different variations\nof these resources so to say.\nAnd then I will guide you through more production ready use cases.\nFor example you will see how you can add authentication to your MCP.\nMake MCP secure, deploy your MCP to a production endpoint, publish your MCP so everyone can use it\nand use it locally or remotely.\nOnce you complete these modules of the course, I'm going to consider you a seasoned MCP user.\nAnd then we are opening up a new part of the course, which is called the hero section.\nAnd in the hero section we are going to cover more advanced topics.\nFor example, different frameworks like Long chain or OpenAI and different use cases.\nAnd I'm going to add more and more content to the hero topic as soon as they are becoming relevant for\nworking with MCPs.\nSo I hope that such a structure will be useful for you.\nSo let's go and get our hands dirty.",
            "dataPurpose": "item-2"
          },
          {
            "title": "4. Pro Tips for Maximizing Your Course Experience",
            "videoUrl": "https://epam.udemy.com/assets/65239295/files/2025-05-19_13-24-38-fdc6862e5538150f56ef950b572b2a18/2/aa004c99fb24bce9b0f577ee6f77d677094f.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOC1mZGM2ODYyZTU1MzgxNTBmNTZlZjk1MGI1NzJiMmExOC8yLyIsImV4cCI6MTc1NTc4NzA5Mn0.YWC740US-8Un319Hk6hnTYpIYwlaDsXrb8Qc1qHIBUs&provider=cloudfront&v=1",
            "transcript": "Let me give you a few pro tips about how to make the most out of this course.\nThere will be only a few resources attached to this course, so I don't work with many downloadable\nresources because what I found well from students feedback is that what works great is that we have\na GitHub repository which has all the resources, and there is also a presentation that you can download.\nEven though you will not need the presentation, but a link will be provided for you.\nSo in the next lecture you will see a link to our GitHub repository, the presentations and also a community\ndiscord channel.\nAnd most of the courseware will be in the course resources.md file.\nSo let me just show these to you real quick.\nSo here is our GitHub repository.\nAnd then you will find the course resources right here.\nSo please ensure that you keep these handy.\nAgain link comes in the next section.\nAnd I would also like to invite you to our invite only discord channel which now has an MCP Cause channel,\nwhich we can use to discuss ideas, share news whatsoever for the Q&A.\nSo for course specific Q&A, I would like to ask you to use Udemy's Q&A platform.\nIt works as well.\nAnd for any other communication, feel free to join our discord.\nNow just a few other things.\nOne is about the speed.\nSo I will try to speak at a level to accommodate all audiences.\nAnd if you want to speed it up, then what?\nYou can do that here at Udemy Video Player you can change the playback rate.\nI'm sure that up to 1.5 you will be able to still enjoy the course.\nAll right.\nAnother thing that that sometimes happens to students is that they say that they cannot download the\ncourse certification certificate.\nAnd this happens because sometimes you won't see check marks besides the videos because Udemy thinks\nthat you haven't completed them.\nIn this case, you can just come back and click the check marks, and then you will be able to officially\ncomplete the course and download your certificate.\nAll right.\nAnd then the last thing is about reviews.\nObviously reviews are super important for me and I'm reading them.\nSo if you leave a review please leave a text part because that's how I can make this course even better\nand better.\nAnd Udemy is going to ask you for a review right after the first section of the course.\nNow, if you have a good sense about how the course is going, then feel free to add the review already.\nBut if you want to hold it off and experience more before you add the review, feel free to click Ask\nMe Later.\nUdemy will then ask you later for a review.\nAll right, so I believe that these are the most important pieces to make you succeed in this course.\nSo I'm excited to have you here and to get going right away.\nLet's go.",
            "dataPurpose": "item-3"
          },
          {
            "title": "Элемент 6",
            "videoUrl": "https://epam.udemy.com/assets/65239295/files/2025-05-19_13-24-38-fdc6862e5538150f56ef950b572b2a18/2/aa004c99fb24bce9b0f577ee6f77d677094f.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOC1mZGM2ODYyZTU1MzgxNTBmNTZlZjk1MGI1NzJiMmExOC8yLyIsImV4cCI6MTc1NTc4NzA5Mn0.YWC740US-8Un319Hk6hnTYpIYwlaDsXrb8Qc1qHIBUs&provider=cloudfront&v=1",
            "transcript": "Let me give you a few pro tips about how to make the most out of this course.\nThere will be only a few resources attached to this course, so I don't work with many downloadable\nresources because what I found well from students feedback is that what works great is that we have\na GitHub repository which has all the resources, and there is also a presentation that you can download.\nEven though you will not need the presentation, but a link will be provided for you.\nSo in the next lecture you will see a link to our GitHub repository, the presentations and also a community\ndiscord channel.\nAnd most of the courseware will be in the course resources.md file.\nSo let me just show these to you real quick.\nSo here is our GitHub repository.\nAnd then you will find the course resources right here.\nSo please ensure that you keep these handy.\nAgain link comes in the next section.\nAnd I would also like to invite you to our invite only discord channel which now has an MCP Cause channel,\nwhich we can use to discuss ideas, share news whatsoever for the Q&A.\nSo for course specific Q&A, I would like to ask you to use Udemy's Q&A platform.\nIt works as well.\nAnd for any other communication, feel free to join our discord.\nNow just a few other things.\nOne is about the speed.\nSo I will try to speak at a level to accommodate all audiences.\nAnd if you want to speed it up, then what?\nYou can do that here at Udemy Video Player you can change the playback rate.\nI'm sure that up to 1.5 you will be able to still enjoy the course.\nAll right.\nAnother thing that that sometimes happens to students is that they say that they cannot download the\ncourse certification certificate.\nAnd this happens because sometimes you won't see check marks besides the videos because Udemy thinks\nthat you haven't completed them.\nIn this case, you can just come back and click the check marks, and then you will be able to officially\ncomplete the course and download your certificate.\nAll right.\nAnd then the last thing is about reviews.\nObviously reviews are super important for me and I'm reading them.\nSo if you leave a review please leave a text part because that's how I can make this course even better\nand better.\nAnd Udemy is going to ask you for a review right after the first section of the course.\nNow, if you have a good sense about how the course is going, then feel free to add the review already.\nBut if you want to hold it off and experience more before you add the review, feel free to click Ask\nMe Later.\nUdemy will then ask you later for a review.\nAll right, so I believe that these are the most important pieces to make you succeed in this course.\nSo I'm excited to have you here and to get going right away.\nLet's go.",
            "dataPurpose": "item-5"
          }
        ]
      },
      {
        "title": "Section 2: Theory - Agentic AI & Tool Use - How does it work?",
        "items": [
          {
            "title": "6. Understanding Agentic AI Behavior",
            "videoUrl": "https://epam.udemy.com/assets/65239373/files/2025-05-19_13-24-39-e9b0432abed617654f061458eba3c9a6/2/aa00ec69985284ee7aa555e8a3d2c689505c.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOS1lOWIwNDMyYWJlZDYxNzY1NGYwNjE0NThlYmEzYzlhNi8yLyIsImV4cCI6MTc1NTc4NzExMH0.cODCPgn_nhLFPIBUen3B-Jv4MmQtfeqSiPC0C7_81Cs&provider=cloudfront&v=1",
            "transcript": "I'm super excited to discuss this piece of the course with you, because I believe that if you understand\nthis specific video, then you're gonna have a very, very good mental model about how agents work and\nwhat you can do with them.\nSo I hope you will like it and that you will understand it, because this will open us the mental way\nto think about how agents work and how MSPs work.\nNow here is the thing.\nSo if you think about how you interact with a chat UI, an LLM like ChatGPT or Claude or or Gemini,\nthen usually your interaction is very easy.\nYou send a chat message, you receive a response, you chat, you send a follow up message, and again\nyou receive a response.\nThat's super simple, right?\nOf course you might do some other things like attach an image or upload some documents, or include\nwork in projects or upload assets whatsoever.\nBut this is the basic workflow.\nBut there is so much more that happens behind the scenes, behind the scenes.\nThis is very much what happens here.\nAre you.\nAnd then there is an lm API so that the UI but an API.\nAnd if you communicate directly to the API, then you must provide much more context with each call,\nas if you work with the ChatGPT UI, for example, because ChatGPT and all the others do this for you\nautomatically.\nNow what happens here is that you send a so-called message request, but you can think about it as a\nas a message where you send not only your York current message.\nBut you also send the system prompt.\nSo some instructions about what to expect from the model to do.\nThis is usually optional.\nThen you also send the chat history.\nSo by default LMS if you communicate through the API they don't remember the chat history.\nYou need to send a whole conversation in each request and keep track of this conversation yourself on\nthe client side.\nAnd then you might send a bunch of other things.\nThat's why you see this here in braces.\nYou can send, for example, the maximum number of output tokens that you want to pay for.\nSo for example, you can instruct ChatGPT or Cloud or Gemini to to cut off the message when it hits\na certain number of tokens.\nLike think about it like cutting off the message when it hits like 20 words in the response, because\nyou don't want to pay for more.\nAnd then you also send a message.\nRight?\nSo your content the payload itself.\nSo this is what happens.\nAnd then you get a response.\nAnd in the response you receive things like the message itself or the response message.\nThis is what you would see on the ChatGPT UI two.\nAnd you also have depending on the on the LLM provider, you might have a stop reason.\nThe stop reason might be simply stop, which means it's all good.\nYou get all the response, but the stop reason can be for example, stopping generation because it would\nhave generated offensive content or it would have leaked personally identifiable information whatsoever.\nSo you can also inspect the stop reason.\nYou will see how many tokens you used.\nAnd also in with some providers you can see the price of your request like how much you paid for for\nthis specific request.\nAnd of course, as you probably know, you can go to Anthropic's website or OpenAI's website and just\nsign up for an API key, upload your balance with a a few tens of dollars, and then start using these\nplatforms through the API right away.\nOkay.\nAnd this goes on like that, right?\nYou have a follow up request and then you have a response.\nNow here is one thing that many people don't know about.\nAnd this will be the most important piece in the whole course I would say.\nAnd this is called the LLM tool use.\nNow what happens is that you not only can send messages, and the LLM backend not only can respond with\na message, but there is also a meta communication layer between you and the LM.\nSo for example, if you have a function defined in your Python environment which can get the current\nprice of a crypto symbol, let's say Bitcoin, then what you can do is that you can extend the LMS functionality\nby providing this function to the LM, and it's not like it doesn't go that way, that you send this\nfunction to the LM and it will execute it, uh, in their own infrastructure.\nBut it goes in a way that you implement your function for yourself in your Python file or Jupyter notebook.\nAnd then when you send the message request, then you also add a metadata, a so-called tool use or\nfunction calling metadata where you say, oh, and I also have this function.\nNow this function is called get crypto price.\nIt accepts one parameter called symbol which is the crypto symbol, and it gets the current price of\nthe cryptocurrency.\nThis you can define in a metadata and just send it to the LM.\nNow the LM takes note of it.\nIt says oh cool, I got it.\nYou have a function like that.\nAnd then you can keep on working, keep on working.\nAnd at one point you might get into a situation where in order to the LM to generate a meaningful response,\nit would need the current price of a cryptocurrency.\nAnd then what it will do is that in its response, it won't come back to you with a message, but it\nwill use an other part of the response, like telling you kind of on a meta level that, Hey, before\nI get back to you with a message, can you please call your function that you told me you have the get\ncrypto price function with this and that parameters, and then you can go execute the function on your\ncomputer and then send the follow up request.\nThe follow up request in this case can be just a very standard LM message which says for example, sure,\nthe current price of Bitcoin is this and that, and then the LM will go on and for example, write a\nhaiku about the current price of Bitcoin, if that was the original request.\nSo this is the most important piece of agents that they can expose functionality to each other.\nSo you can expose functionality to an LM.\nNow think about that.\nProbably an even better use case would be to provide web search functionality to an LLM.\nNow, most of the LMS can do that.\nAt least most of the Hastie LMS managed LMS can do that automatically, but you could simply just connect,\nfor example, to perplexity, sign up for an API key and then write a function that can do a perplexity,\nsearch and return with perplexity.\nAnswer to the LLM.\nAnd in this case you would be able to tell the LLM.\nHey, I have this function.\nIt's called perplexity search.\nIt takes a keyword argument and returns with a bunch of jsons about the, uh, the response.\nSo just let me know when you need to search the web, and then the LLM will reach out to you in a response\nwhenever it needs external information.\nSo this is the big thing with LMS.\nAnd this is what enables cooperative agents.\nI see you in the next video.",
            "dataPurpose": "item-0"
          },
          {
            "title": "7. Creating a Free Gemini AI API Token",
            "videoUrl": "https://epam.udemy.com/assets/65239345/files/2025-05-19_13-24-42-6979b8a57f98bbb5c32652a7049536cc/2/aa00d8ccd5a63a7a4547e5de48985b43f309.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC00Mi02OTc5YjhhNTdmOThiYmI1YzMyNjUyYTcwNDk1MzZjYy8yLyIsImV4cCI6MTc1NTc4NzExOH0._6bzSZty8ts7lFWMzMBQCfIocQopVCI5dmPykFhTaIw&provider=cloudfront&v=1",
            "transcript": "We are going to use the Gemini API for our LLM groundwork for the tool calling demo.\nAt least if you only want to watch through the demo of two calling, but you don't want to follow it\nhands on, that's completely fine.\nThen you don't need to create a Gemini API key now, and you will still be able to do the full course\nhands on when we get to the MCP part.\nSo again, this is now only for the native low level tool calling demo.\nIf you want to experiment a little bit with these capabilities of labs and there are tool of choices\nGemini because Gemini offers us a free API based access.\nThat's a thing that at the moment OpenAI and cloud doesn't offer.\nSo please come to the website AI studio Com or just Google.\nGoogle AI studio and go to the first hit.\nAnd once you're here.\nEnsure that you are logged in and then click get API key.\nOnce you click get API key click create API key.\nAnd then it says generating API key.\nOnce you have your API key generated please copy it.\nAnd then let's go to Visual Studio Code and add it to our dot env file.\nHere we are in Visual Studio Code.\nLet's open env and simply replace the add your API key here with the API key generated.\nAnd once you're done with that, you're good to go with the hands on tool calling demo.",
            "dataPurpose": "item-1"
          },
          {
            "title": "8. Agentic AI Behavior and Tool Calling Hands on",
            "videoUrl": "https://epam.udemy.com/assets/65239465/files/2025-05-19_13-24-41-26d4c2ee6c417e17348e14cb53f88e19/2/aa00c827e8951ae5642f85e927e0ad174da2.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC00MS0yNmQ0YzJlZTZjNDE3ZTE3MzQ4ZTE0Y2I1M2Y4OGUxOS8yLyIsImV4cCI6MTc1NTc4NzEyNX0.fggJFb5cwpDSlYEKpkMCWsS4J8rZ8aQB4_vEq-HSU10&provider=cloudfront&v=1",
            "transcript": "Now that you have added the Gemini API key to the env file, let us validate that it's actually there.\nSo we are going to use the load env function from the Python library that manages this file, and reads\neverything from this file into the system environment.\nThen we're going to go and just check if the Gemini API key is there.\nAnd then if it's there, we create a Google Gen AI model.\nAnd we're going to use here Gemini to flash.\nEverything that we use here has been already imported here.\nRight.\nLike the gen AI model and the load function.\nLet me execute it.\nIt works well and it should work well for you too.\nSo it says the Gemini model loaded successfully.\nAnd this is the model that.\nI've loaded.\nNow let's go and chat a little bit with our Gemini backend.\nSo let's send it the message.\nWhat is the current price of Bitcoin?\nThe way to chat with Gemini in a native way is to start a chat with the chat, and then send a chat\nmessage and just read out the text piece of the response.\nAll right, so this is the simplest way to go.\nNow I'm executing it by pressing Ctrl enter.\nSo here we go.\nIt says unfortunately I cannot provide you with exact real time price of bitcoin because it fluctuates.\nYou should go and take a look at these exchanges.\nNow one of the exchanges it suggests us to use is Binance, which is one of the largest crypto exchange.\nSo let's implement this functionality that Gemini on our computer is able to reach out to Binance and\npull in the current crypto price.\nOkay, here is a simple implementation.\nBut before we get there, I also want to show you the full response here.\nWe put the response text to the screen.\nAnd now let's see what we've actually what we actually got from Gemini.\nSo this is the response uh low level.\nSo it says um this is the response.\nWe are done.\nThe response itself has well, a single candidate.\nAnd this candidate, this is our response.\nIt says it has a part and it has a tax base.\nAnd here comes the unfortunate.\nI'll provide you with the exact real time price of Bitcoin.\nSo the actual text.\nRight.\nSo this is how we receive the response from the model with a bunch of metadata.\nSo it says that this is what the model said.\nAnd the reason is setup as we discussed briefly the reason can be anything else.\nLike if you specify a maximum token count, you can run out of tokens.\nIf the LLM would generate a swear word, then it might just stop right there.\nSo this would pop up in the finish.\nReason.\nAnd there are a bunch of other metadata about uh, the also the input like how many tokens you use and\nalso the output.\nAll right.\nSo this is what we actually receive and we extract the text from that in such a simple example.\nSo let us move on and add this, uh, Bitcoin functionality.\nNow I'm certainly not an expert on uh, on bitcoin and, and crypto, but what I know is that if you\nwant to take a look at the USD price of Bitcoin, at least on Binance, then the simplest you can do\nthrough the API is to compare the Bitcoin price to a stablecoin, which is called USDt.\nSo we are going to use here USDt.\nIf you are not a crypto expert either either then just take it as is okay.\nSo this approximates the USD price of Bitcoin.\nSo if you take a look at the Binance API, you will see that this is the exact code that you can do\nto get the current price of Bitcoin.\nWe're going to use the request library which is a probably the most popular Python library for accessing\nAPIs and websites.\nWe just pull in this URL and then take the responses JSON and print it to the screen.\nLet's take a look.\nOkay, so this is what Binance tells us.\nIt says for this specific pair.\nSo this specific symbol the price is now this value okay.\nSo now we have an LLM.\nWe know how to get a Bitcoin price.\nSo we just need to glue everything together right.\nSo let's create a function that does exactly the same.\nIt extracts a certain symbol price from Binance.\nThis is what you've already seen.\nIt just parameterized now with a symbol.\nAnd we extract the price itself from the response JSON because that was a dictionary, right?\nSo let's define this function.\nThat's nothing fancy, it's just a Python function.\nLet's use it with the btc USDt symbol.\nAll right.\nIt says this is the BTC price.\nWe converted everything into a float.\nThat's why we don't have that many digits at the end.\nSo now we have a function that we can pass to to the LM.\nSo let's go.\nLet's implement this.\nNow what we're going to do is to create kind of a metadata definition that we can pass to Gemini and\nintroduce Gemini to our Bitcoin currency, uh function.\nOkay.\nSo the way to go and this is Gemini specific.\nThis is just how to do it.\nIf you take a look at the Gemini documentation, you will see that like that's the way to do it.\nYou can define function declarations and send it to Gemini.\nI will say I have a function which is called get crypto price.\nThe description is get cryptocurrency price in USDt from Binance.\nIt is important what you write in the description, because the LLM will need to decide when and if\nit needs to use a certain tool, a certain function.\nIt will only use it if you if the discussion is about crypto price.\nBut it's important that you, uh, you add a meaningful description here so it knows what it is about.\nThen we have a bunch of parameters.\nI mean, we actually have a single parameter which is the symbol, right?\nThe type is a string.\nAnd then here is a description.\nIt says this is a cryptocurrency trading pair symbol.\nIt can be BTC, USDt or ETH Th USDt for Ethereum.\nAnd I also give it some hints because we cannot really rely on Gemini knowing how to use Binance.\nI mean, it might have a notion about how Binance API work because it can very easily be part of their\nGemini training data, like all the dump from the Binance documentation.\nBut it's better to be safe than sorry, right?\nSo I would just say just for you to know, the symbol for Bitcoin is BTC, USDt, and the symbol for\nEthereum is ETH, USDt.\nOkay.\nAnd we also pass that there is one required symbol and one required parameter.\nAnd that is the symbol a bit of a complex definition.\nBut that's what we need to inject into Gemini to get started.\nI would also like to draw your attention to the fact that we never mentioned our function here.\nSo we never actually used the get crypto price function object by chance.\nNow the name of our function declaration is Get crypto price, but it has technically nothing to do\nwith this function.\nWe are just talking metadata here, so I'm just telling Gemini that, hey, I have a function and I\nwant you to refer to this function as crypto price.\nAnd this is how this function works.\nBut Gemini will won't it won't be able to directly call your function in this case okay.\nSo it's all just metadata definition.\nSo let's execute it.\nOf course it gets executed because it's just a standard Python dictionary.\nAnd then now I'm going to start a new chat and send the message the same message saying what is the\ncurrent price of Bitcoin?\nBut I'm also on top of the message.\nI'm also sending a tool definition.\nAll right.\nSo I will tell Gemini that I also have access to tools.\nSo if you want to me to use tools just let me know.\nSo let's go and execute this.\nThis is going to be exciting.\nAll right.\nSo here is the response.\nYou see the response is very much the same.\nThen it's true.\nAnd here is the response whatsoever.\nBut here now if you take a look at the parts here you see that.\nNow we don't have a text response but we have a function called response.\nAnd Gemini tells us, hey, I don't want to give you any text answer yet.\nCan you just go and call your get crypto price function with the argument BTC USD and send me back the\nresults.\nAnd that's very much it.\nSo let's do that.\nLet's execute the get crypto price function with the symbol.\nGemini wanted us to execute it with extract the price.\nAnd once we get the price, let's just send it back as is.\nSo Gemini just adds this, you know, call this function.\nAnd what it wants us to provide it with is the result of this function.\nSo I'm just going to convert it into string and send it back execute it.\nAnd then here we go.\nThere is a new message appearing.\nAnd here is the response.\nSo it says now I can send you a text and the text is okay.\nThanks for confirming the current price of Bitcoin.\nIs this and that.\nOkay.\nSo now if I'm just taking a look at the final response is the text and I can pop this up on the screen.\nAnd now I have an Agentic Gemini that is not only able to talk with me, but also use tools.\nTools that I provide it with.\nAnd with the help of my tool, now it will be able to extract the and get the price of of Bitcoin.\nNow this is the trick.\nAnd if you understand what happened here, then I believe you understand very much everything that enables\nagent to be so powerful.\nSo we can use Llms and provide them with functions and then execute these functions on their behalf\non our computer.\nWhat you've seen here, this was now very, very low level so to say.\nSo I don't think too many People interact with Llms on such a low level.\nThere are frameworks with, for example, long chain, with the help of which you will be able to just\ndefine a function and add it to the LLM.\nAnd the long chain will be able to do this whole back and forth.\nRight.\nSo if there is a tool call, it will actually call the function and return the result.\nAnd what you will see is just the end result.\nYou ask for Bitcoin with the two registries and you will see this end result.\nFor example, if you use long chain or or another agent library.\nSo there is like lots and lots of uh, abstraction on top in modern systems.\nBut I wanted to ensure that you understand the kind of the bottom of how it works.\nSo you have the best possible mental model as we are moving on, so you can understand fully how mcps-prs\nwork.\nSo congrats, and I'll see you in the next video.",
            "dataPurpose": "item-2"
          }
        ]
      },
      {
        "title": "Section 3: Environment Setup",
        "items": [
          {
            "title": "9. Prerequisites",
            "videoUrl": "https://epam.udemy.com/assets/65239281/files/2025-05-19_13-24-38-61f8c120da454c7d8a57a6936cc14cd2/2/aa00d37e73e50a40e3c3b41d73c783e0c892.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOC02MWY4YzEyMGRhNDU0YzdkOGE1N2E2OTM2Y2MxNGNkMi8yLyIsImV4cCI6MTc1NTc4NzEzN30.5IcavXB_jzlEWAKnYnLs1m16Vf4u6aUGIVHw7fTW7_8&provider=cloudfront&v=1",
            "transcript": "In order to follow this course, you will need a few tools installed on your Mac or Windows or Linux.\nBut first of all, you will need a working Python installation.\nTake a look at the course resources to check out the minimum supported version of Python.\nYou will also need to have a Node.js installation.\nI'm going to send you links to how you can install it, in case you don't have it in the course.\nResources.\nAnd then two other tools that we will use for showing you how you can integrate MCC into LMS.\nOne is called a competitor and the other is cursor which is an AI development environment.\nAgain I'm gonna send you resources on how to install those, but you should be able to install those\nbasically on your own.\nIt's quite straightforward.\nAnd for the editor I'm going to use Visual Studio Code.\nAnd I would strongly suggest you to use Visual Studio Code just that, so that we have a completely\ncompatible workflow in the course.\nBut if you are very technical and you have your own choice of IDE, then feel free to go with that.\nWe are not going to do anything Visual Studio Code specific in this course.\nAll right.\nSo this is all you need.\nPlease ensure that you have these installed and then you will be ready to go and follow the hands on\npieces.",
            "dataPurpose": "item-0"
          },
          {
            "title": "10. GitHub & Source Code Access",
            "videoUrl": "https://epam.udemy.com/assets/65239283/files/2025-05-19_13-24-37-ab87596d7aa58468b76e7f51b4d77b3a/2/aa0098d85590c89399f500d3ecd062fcd60e.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zNy1hYjg3NTk2ZDdhYTU4NDY4Yjc2ZTdmNTFiNGQ3N2IzYS8yLyIsImV4cCI6MTc1NTc4NzE0NH0.H3Nn6zUYn6BAyQ5f_d_UFd6rTiK4EgpE2RhDhln8vf8&provider=cloudfront&v=1",
            "transcript": "Let's go on and set up the code for our work.\nPlease come to the repository of the course which is here Node1 slash MCP course on GitHub.\nAnd the easiest way to set it up is to simply go and do a clone and GitHub.\nSo I will just copy the URL and then go to Visual Studio.\nHere in Visual Studio you have the source control panel and you can say Clone Repository.\nClick it, then paste the URL, select the destination like your desktop or any folder that you like,\nand click Select as Repository destination.\nThen you can go on and open the project.\nAnd here we go.",
            "dataPurpose": "item-1"
          },
          {
            "title": "11. Installing the uv package manager",
            "videoUrl": "https://epam.udemy.com/assets/65239287/files/2025-05-19_13-24-37-5b9f14d34482d7ba4f921f6928b4b6c2/2/aa008ebf0f812f7c03c1990cea31eb9d2ea9.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zNy01YjlmMTRkMzQ0ODJkN2JhNGY5MjFmNjkyOGI0YjZjMi8yLyIsImV4cCI6MTc1NTc4NzE1Mn0.jDvmksLcv3mthaKw4-4NIoJK5JXI43_naa78_XKzfVY&provider=cloudfront&v=1",
            "transcript": "We are going to use UV as our package manager.\nUV is a next generation Python package manager.\nYou can think about it as a next generation pip with some extra on top.\nIt's super fast and it works very, very well.\nAs you will see, it will be a single click to install all the dependencies and set up our Python project.\nIf you go to UVs website.\nThen you will find instructions for installing it to macOS and to windows.\nPlease go ahead install UV and I'll see you in the next video where we are going to set up our whole\nworking environment.",
            "dataPurpose": "item-2"
          },
          {
            "title": "12. Setting up your Working Environment",
            "videoUrl": "https://epam.udemy.com/assets/65239293/files/2025-05-19_13-24-37-3b26ff79bd0ad2747c389ca0d5e87537/2/aa005f11835a1884a0613975c83b6900c1f3.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zNy0zYjI2ZmY3OWJkMGFkMjc0N2MzODljYTBkNWU4NzUzNy8yLyIsImV4cCI6MTc1NTc4NzE1OX0.S4z9BcrKRnpm0lS-lHOit-Mp8IFjrRoDcA0yUf-3PvA&provider=cloudfront&v=1",
            "transcript": "Now that you have, you've installed.\nLet us set up our Python environment.\nWhat you want to do is to create a new terminal in VS code, and then create a virtual environment with\nyou've.\nYou can do this by saying you've virtualenv dot v and v where dot v and v is the folder your virtualenv\nis going to be created in.\nThen you can activate it.\nIf you are on windows then this will be a slightly different command.\nJust copy and paste it.\nAnd here now you can see that we have our virtual installed.\nAnd let's just install the dependencies.\nNow the dependencies are here in py Project.toml.\nThis is the UV standard place to store dependencies.\nHere you can see the project name and a bunch of dependencies that we are using.\nAgain, don't worry if these dependencies don't look exactly like on my screen because as I update the\ncourse, they are going to be changed.\nSo let's install the dependencies.\nYou can do this by executing UV sync.\nUV sync will install everything from Pyproject.toml.\nAll right.\nSo now you are very well set up for completing the first hands on lab.",
            "dataPurpose": "item-3"
          },
          {
            "title": "13. VSCode Notebook Setup",
            "videoUrl": "https://epam.udemy.com/assets/65239301/files/2025-05-19_13-24-38-cda24945a31c68489d3d2352c60c8994/2/aa0062e9f202244b1f25167c38aee5a91119.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOC1jZGEyNDk0NWEzMWM2ODQ4OWQzZDIzNTJjNjBjODk5NC8yLyIsImV4cCI6MTc1NTc4NzE2N30.6VqLQar-IUESGiuytJQBPbqMOFVicH2EuPpU6PEutHQ&provider=cloudfront&v=1",
            "transcript": "Let's open our first notebook and ensure that we are up and running.\nThis is called tool underscore calling dot ipynb.\nIf you see more files here, don't worry about those as they might change as the course gets updated.\nSo click or double click to calling dot ipynb.\nNow mine is a vanilla Visual Studio Code environment, so I will need to install the Python package,\nthe Python extension.\nAnd that's okay.\nIf you don't have a Python extension installed, please go on and install it.\nOnce it's installed, come back to tool calling again.\nAnd what you see here is a notebook which I'm sure you are familiar with.\nLet us execute the first cell to ensure that we are up and running.\nNow either you can just click play or you can press shift enter as you wish.\nI'm gonna click play here.\nAnd then it says, oh well first you get to execute and install the Python Jupyter extension which is\nokay.\nSo let's install this.\nAnd then we get to select the kernel which means Python environment.\nSo click Python environments.\nAnd the environment that's in your VM should be the first item in the list.\nSo please click it and you should be able to see the message.\nWe are up and running.\nAnd if you see that then congrats, you are set up for the whole course.",
            "dataPurpose": "item-4"
          }
        ]
      },
      {
        "title": "Section 4: MCP Overview and Architecture",
        "items": [
          {
            "title": "14. The Problem MCPs Solve",
            "videoUrl": "https://epam.udemy.com/assets/65239317/files/2025-05-19_13-24-38-7705ee01edb0536f18315260a7d502d0/2/aa00dbee7786b6efc78c08f8bc0300ab4b52.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOC03NzA1ZWUwMWVkYjA1MzZmMTgzMTUyNjBhN2Q1MDJkMC8yLyIsImV4cCI6MTc1NTc4NzE3OH0.cBgy3ZHbYvS0LHDcTXwBECEMIsquZ_DRHZP_sXhpm0c&provider=cloudfront&v=1",
            "transcript": "Let's imagine that your anthropic, the creator of cloud, which is a ChatGPT competitor, and you want\nto add web search functionality to cloud.\nNow, in this case, what would you do with your current knowledge?\nNow you already know that you would be able to create a tool calling inside cloud that, uh, that could\ntalk to the LLM and register a Google search or a perplexity search function in the telegram.\nAnd if you think about this function, it could be like a simple Python function, right.\nThat just uses the perplexity API, submits a search term and returns the result to the LLM.\nNow this is what you would do, right?\nSo that could work well, but you would need to create your own specific implementation inside the client\ninside cloud.\nAnd then if you wanted to add more for example, you wanted to add uh, slack.\nSo for example, taking the perplexity results and sending it to a slack channel.\nYou would need to set up a new tool calling with a new Python or JavaScript function that would communicate\nwith the slack API, and taking the results and sending it to slack API.\nThat works actually well.\nAnd then let's imagine your cursor, the AI development environment, and you want to do the same.\nYou want to reach out to perplexity.\nIf you need some information about Python package, or you need to look up a documentation whatsoever,\nand you also want to send things to slack, for example, a summary of what you did today or whatsoever.\nSo in this case in cursor you would need to set up these tools.\nThe perplexity calling Python function register it to the LM cursor uses.\nAnd you know just run your own and you see where this leads.\nIt leads into an exploded word.\nThere we are, exploding the complexity of the whole eye to eye or eye to service provider communication\nas we are adding more clients like Cloud and Courser.\nLet's assume you're adding ChatGPT, and then ChatGPT would need to implement all of these APIs.\nOr as you're adding providers like on top of Slack and Perplexity, you can add, for example, a Google\nDrive provider.\nSo you can work with your Google Drive folders and files.\nIn this case, you would need to implement these Google Drive API and function calling and tool use\nin every client there.\nAnd you can clearly see that this say that this is not sustainable, right.\nSo this is the actual problem now that I tours and I native tool providers are on the rise.\nAnd this is exactly what MCP is going to solve as an emerging standard.\nAnd we will review how it does it in the next video.",
            "dataPurpose": "item-0"
          },
          {
            "title": "15. MCP Architecture",
            "videoUrl": "https://epam.udemy.com/assets/65239303/files/2025-05-19_13-24-38-06246a03c25525bf0acfadde7cfde0a1/2/aa0042c51932edbbc9c1e91d775f5d73787c.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOC0wNjI0NmEwM2MyNTUyNWJmMGFjZmFkZGU3Y2ZkZTBhMS8yLyIsImV4cCI6MTc1NTc4NzE4Nn0.QN7k2Ephmr_6GLCnFHpwCx_-klKoDfj7MByiYow0zYo&provider=cloudfront&v=1",
            "transcript": "If you want to understand how MCP work, there are a few concepts that you need to be familiar with.\nAnd here are a few terms.\nNow, just to keep it simple, I will reference Cloud and Corsair as hosts and slack and perplexity\nas service providers.\nOkay, so you want to connect them somehow.\nMCP comes in with a few components.\nFirst of all, the MCP client, you don't need to worry too much about this.\nThe MCP client is kind of the MCP functionality in Corsair or Cloud that enables these services to work\nwith the MCP technology so you can more or less forget about this for now.\nThen there is MCP protocol, which is the language how the MCP client communicates with the MCP servers\nthat we are going to cover in a second.\nYou can also kind of safely forget about the MCP protocol for now too.\nAnd what I want you to focus on is the MCP server.\nNow what is the MCP server?\nLet's imagine that I am perplexity, and I want to provide an easy way to these hosts to connect to\nme and use my services.\nSo that is to execute web searches.\nNow in this case, perplexity can implement an MCP server.\nAnd this MCP server would expose the functionality that that perplexity provides.\nFor example, a standard web search or search or deep research along with all of the parameters that\ncome with these.\nSo for example, the type of search, the keywords, if it's a follow up search or an initial search\nwhatsoever.\nSo perplexity implements an MCP server and gives it to you as an open source component or host it somewhere.\nAnd then you as the host.\nAs an MCP enabled host, you will be able to simply connect to perplexities MCP server and discuss with\nperplexity what services it provides and then just use them.\nSo that's the big thing, right?\nThat now with MCP we have a standard way to expose services to hosts and for hosts to discover services\nand discover functionalities of service providers.\nSo as MCP says in the documentation, you can think about MCP as a USB-C cable that you can just plug\nin into every provider, like Slack or Perplexity.\nAnd the other end you can plug in to every host because they are all compatible.\nIt's a standard communication channel, and you will see in the next videos how an MCP server is implemented\nand how you can think about this whole concept in more depth.",
            "dataPurpose": "item-1"
          },
          {
            "title": "16. MCP Architecture Terms",
            "videoUrl": "https://epam.udemy.com/assets/65239309/files/2025-05-19_13-24-38-79112fc0a1a24d200cfba8c3485be619/2/aa00eef9e7851d484e3a5cc01b5b128c4744.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOC03OTExMmZjMGExYTI0ZDIwMGNmYmE4YzM0ODViZTYxOS8yLyIsImV4cCI6MTc1NTc4NzE5M30.ipJfIzsof6mQq0HRGN5jnQxGfmJPORmNvqHs8QConhg&provider=cloudfront&v=1",
            "transcript": "Once again, let's review the main concepts because these will be super important as we're moving on.\nSo Mcpe hosts are your AI software, right?\nLike cloud or ChatGPT or Corsar.\nThen we have the MCP protocol, which is the language MCP uses.\nI told you, that's not too important.\nThen we have the MCP servers.\nThese are these components that bridge the communication between your host and the server provider.\nAnd then there is also a concept of an MCP client, which is the client module that sits inside your\nhost and enables MCP functionality.\nAll right.\nSo please remember MCP servers and MCP hosts for sure.\nAnd here is a more detailed architecture diagram from the MCP website.\nSo the way you can think about this whole thing is that you have your host, and then you have MCP servers\nthat are somehow installed mostly on your computer.\nYou will see.\nAnd these servers, as small components, are connected to different tool providers and data services\nand remote services whatsoever.\nAnd manage the communication.\nAnd your MCP client with the host will be able to choose which service to use.\nSo when you say go to the internet and look for this and that, then it will be able to know that it\nmust use now a perplexity search and not send a slack message.\nRight.\nSo the LLM itself will be routing the whole agent tool use.\nSo what MCP server tools and which use case.",
            "dataPurpose": "item-2"
          },
          {
            "title": "17. MCP - Key Functionalities",
            "videoUrl": "https://epam.udemy.com/assets/65239315/files/2025-05-19_13-24-38-6feb81e9640f85730c371fb0b345829a/2/aa00911eab9987e25c549b9a762f017f48fa.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOC02ZmViODFlOTY0MGY4NTczMGMzNzFmYjBiMzQ1ODI5YS8yLyIsImV4cCI6MTc1NTc4NzIwMH0.J0U5kNObWQe6JHzx6JJtokVZ-bIXNCUwTKUQDAL7lr4&provider=cloudfront&v=1",
            "transcript": "Maps provide you with different functionalities, and here are the most important ones I believe way.\nThe most important is called tours, which is the tool use provider.\nThis is very much what we've discussed so far.\nSo you can expose tool usage to LMS.\nBut there are also others like resources.\nSo you can provide LMS with resources like files for example.\nAnd there are also prompts which is kind of an interesting concept, but the MCP itself will be able\nto send a prompt to the LM.\nSo for example, if there is a prompt you like a lot, then you can integrate it into an MCP server.\nSo you don't need to type it in all the time.\nThere are also a few others that are partially supported by the technologies at the time being, for\nexample, I picked two.\nOne is routes where you can kind of shield your LLM and your MCP by defining what resources a certain\nMCP provides.\nSo for example, you can say that I as an MCP provide you a database about this and those users, but\nonly ask me if you want to access these specific resources.\nAnd then there is sampling.\nSampling is um it's basically LLM functionality.\nSo an MCP will be able to expose an interface, the MCP server for next token prediction service.\nSo an LLM can just work with an MCP to to generate next tokens.\nBut again these are in some software internally supported but not that widely supported across the ecosystem.\nSo we are going to focus on tools resources and grants.",
            "dataPurpose": "item-3"
          },
          {
            "title": "18. MCP Feature - Tool Use",
            "videoUrl": "https://epam.udemy.com/assets/65239313/files/2025-05-19_13-24-39-dbdd2d1514f99fb114ec242733107f61/2/aa00c0840cf2b0137404168f28906aaf98cb.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOS1kYmRkMmQxNTE0Zjk5ZmIxMTRlYzI0MjczMzEwN2Y2MS8yLyIsImV4cCI6MTc1NTc4NzIwOH0.HwOJ6vcDvjMc96_8pgwvEGXyyNcr3vDPjEBtm38T3AI&provider=cloudfront&v=1",
            "transcript": "You are going to see that their main functionality, the tool use is extremely easy to implement.\nNow that takes you to implement a Python or JavaScript function with the tool you want to use.\nHere I simply want to create a tool that runs a command.\nSo it takes a command as an argument and it executes it in a shell.\nRight.\nAnd then returns with the output of this tool call.\nI also added some comments here.\nAnd in order to take this function and convert it into an Mcpp tool, I simply want to annotate it with\nMrp2.\nOf course, this is here.\nNow an annotation, so it's missing an add sign, but you will see in the example how this works.\nSo you simply annotate a function with MCP tool after you install the MCP library.\nAnd that basically is 90% of your MCP server implementation.\nIf you want to keep things simple.\nSo this is tool use in MCP.",
            "dataPurpose": "item-4"
          },
          {
            "title": "19. MCP Feature - Resources",
            "videoUrl": "https://epam.udemy.com/assets/65239319/files/2025-05-19_13-24-38-af52fbc797bb02261fac0d9856e8e556/2/aa00d51885649ced35c88bfb0cb9ec21c0c1.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOC1hZjUyZmJjNzk3YmIwMjI2MWZhYzBkOTg1NmU4ZTU1Ni8yLyIsImV4cCI6MTc1NTc4NzIxNX0.JDPjyEkC2GAAuE03zNUCVhXeD6v68Eez7nEH87KWgEw&provider=cloudfront&v=1",
            "transcript": "On top of tours, MPs are also able to expose resources.\nNow imagine you have a bunch of files, like internal documentation that you want to make available\nfor the host LM and this case you can create a resource definition.\nJust take a look here.\nSo you you would implement two functions.\nOne is an app list resources annotated function list resources, which returns a bunch of resources\nthat you want to make available like here.\nIn this example I want to make a single resource available that is the course resources for this specific\nMCP course.\nAnd it is a local file on my computer.\nIt's called course resources.\nYou see the URI here.\nSo this is the path.\nAnd the Mime type is markdown right.\nIt's a markdown document.\nSo this way you can signal to the LM what resources you have available for sharing.\nAnd then you can also implement the read resource function which takes a URI like this one up here.\nAnd then what you would do is simply based on the URI, implement how to read this resource and how\nto return it to the LM.\nIt's simple right?\nSo this is the way to expose resources to LM applications.",
            "dataPurpose": "item-5"
          },
          {
            "title": "20. MCP Feature - Prompts",
            "videoUrl": "https://epam.udemy.com/assets/65239323/files/2025-05-19_13-24-38-85528a7e8af57b5ebae7f0a68d671ba3/2/aa0098b01115566d34221f77300253048d18.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOC04NTUyOGE3ZThhZjU3YjVlYmFlN2YwYTY4ZDY3MWJhMy8yLyIsImV4cCI6MTc1NTc4NzIyMn0.7CQ0XOhhWQOxYgKX8gdZEbPzjjW-rHAgwlTXnW16xnc&provider=cloudfront&v=1",
            "transcript": "There is another feature of MCP that, to be honest, I found a bit hard to grasp at first.\nAnd these are prompts.\nSo MCP will be able to provide the host with a prompt.\nAnd that's very much it.\nSo what does this mean.\nIt means that you might have some prompts that you like a lot.\nHere is a simple example.\nSo for example you might have a code review prompt with some specific instructions.\nSo let's imagine every time you make a code review then you always want to review your code for best\npractices, potential issues and improvements.\nAnd you always wanted to focus on the core logic.\nAnd you want simple answers in and as bullet points.\nAll right.\nAnd you also want to have like an expert level code review.\nSo instead of prompting this every time.\nSo instead of typing this in every time you work with code in an LLM, you can simply create a code\nreview MCP feature.\nAnd in this case in an MCP enabled host you can just click code Review and paste your code.\nAnd then you can get like a full code review.\nBut behind the scenes all that happens is that actually this prompt will be injected into the LLM with\nthe argument given the code that you want to review.\nSo it is a quite simple concept.\nAnd also it can be super, super useful if you want to reuse the same instructions from time to time.",
            "dataPurpose": "item-6"
          },
          {
            "title": "Role Play 1: Basic MCP Concepts Role Play",
            "videoUrl": null,
            "transcript": "",
            "dataPurpose": "item-7"
          }
        ]
      },
      {
        "title": "Section 5: Finding and Integrating Third-Party MCPs into your AI Tool",
        "items": [
          {
            "title": "21. Downloading Claude Desktop and Cursor (Free Versions)",
            "videoUrl": "https://epam.udemy.com/assets/65239321/files/2025-05-19_13-24-38-1bfc4ecb7d2a5c63228350e2dd108896/2/aa00a9643247b3eaf3e95efc783a2f061b13.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOC0xYmZjNGVjYjdkMmE1YzYzMjI4MzUwZTJkZDEwODg5Ni8yLyIsImV4cCI6MTc1NTc4NzI2N30.mkfKkYoaQHoM8sNE1VSNSr9DsxLoNh5s17VK4G4fZ98&provider=cloudfront&v=1",
            "transcript": "As we're going to integrate our MacBook into Cloud Desktop and the Cursor Eye editor, I'd like to ask\nyou to download them and set them up.\nBoth offer free accounts so you don't need to pay for anything, but both require signups, so you will\nneed to sign up for those.\nFor cloud, it's important that you download the desktop client because MCP only works in the desktop\nclient and not on the web.\nAll right.\nSo download cloud please.\nAnd also then go to the Cursor Eye Editors website and download cursor.\nAnd we take it from there.",
            "dataPurpose": "item-0"
          },
          {
            "title": "22. Zapier Intro & Signup",
            "videoUrl": "https://epam.udemy.com/assets/65239325/files/2025-05-19_13-24-38-885bf806a627a18dc56a9dce3ff9b44c/2/aa000938be46482613345bb3ea44c39524fe.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOC04ODViZjgwNmE2MjdhMThkYzU2YTlkY2UzZmY5YjQ0Yy8yLyIsImV4cCI6MTc1NTc4NzI3NH0.5w-vn84vC_2_wlUOY3xl2c4XpYWk1O5foHeZ75DgFNg&provider=cloudfront&v=1",
            "transcript": "The first use case I would like to show you is how to integrate Zapier's automation with cloud.\nZapier is an automation framework.\nYou can create a diverse set of workflows, from sending emails to working with Google Docs to talking\nwith LMS whatsoever.\nAnd it also provides an MCP server.\nSo that's what what we are going to do is we're gonna sign up to Zapier and then integrate Zapier's\nMCP into our cloud instance.\nAnd we do this with a workload that we are going to create, which is a very simple email sending workflow.\nOkay.\nSo I just very quickly guide you through how to sign up for Zapier.\nBut it should be very, very straightforward.\nYou can sign up with Google.\nSo let's just sign up with Google.\nAlright.\nYou might need to go through some of the questions and then we can get started.",
            "dataPurpose": "item-1"
          },
          {
            "title": "23. Setting up Zapier's MCP Server",
            "videoUrl": "https://epam.udemy.com/assets/67015457/files/2025-07-28_13-01-52-366e79dd69e5e35be0519ab71fd1f1a9/2/aa000c801205d645f600a7d1f12cdc65ec7c.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNy0yOF8xMy0wMS01Mi0zNjZlNzlkZDY5ZTVlMzViZTA1MTlhYjcxZmQxZjFhOS8yLyIsImV4cCI6MTc1NTc4NzI4Mn0.kDLG1Md_U-HupXRPiKG3gPGL0c8G30vlZPoniM6t72Q&provider=cloudfront&v=1",
            "transcript": "Now that you have signed up for Zapier and also have a working cloud installation, let's set up our\nZapier MVP.\nPlease come to MCP.\nIt might redirect you to another URL, but this is what you want to see.\nThis up here MCP panel.\nYou see that this is still in beta at the time of the recording.\nAnd what we are going to do here is now we are going to create an MCP that can send emails on our behalf.\nAnd later we're going to integrate this into cloud.\nSo first let's click new MCP server.\nAnd here you will need to select the client.\nAnd please don't do anything just yet because cloud is in the list where this is not what we want to\ndo.\nBut I want to show you why cloud is in the list, okay?\nSo please don't do anything for now.\nJust watch my screen.\nSo if I click upload and I create an Mcpe server again, don't do this.\nThen if I click connect it will say that I should go to cloud AI settings slash connectors.\nAnd then I will be able to work with the Zapier MVP right away.\nThat works great, but the problem is that it is a pro or teams feature.\nHere is my cloud.\nAnd if I click the connectors here in cloud and I can click Manage connectors, then you will see that\nI have a bunch of local connectors which are okay.\nThey will, as far as I know, work in the free version.\nBut if you want to then connect to more sophisticated connectors like Zapier, then those will require\nthe Pro version.\nI logged out and I logged back in.\nAnd now what you see is my personal cloud subscription.\nSo this is a pro version.\nSo I want to show you what you would see if you were a cloud subscriber.\nSo if you were a subscriber you would be able to see manage connectors.\nAnd here you would be able to connect to a bunch of connectors.\nSo if I say like browse connectors then I would have Zapier here.\nAll right.\nSo there is like a modern and paid version way of connecting to Zapier, but we don't want to use that\nas most of you will not have a paid cloud subscription.\nSo let me go back to the Zapier page.\nI'm going to go and delete this MCP server.\nAnd now I would like to ask you to follow what I do.\nSo click new MCP server.\nAnd here just scroll all the way to the bottom and say other connections and this will be our send email.\nZapier MCB.\nOkay.\nSo now I have an SMTP server set up and I can define what this SMTP server should do.\nI will click Add tool.\nPlease click Add tool, click Gmail and then Gmail.\nJust look for send email.\nYeah here it is.\nOkay.\nI can also select my Gmail account.\nYou might need to connect your account at this moment, but I will just say let's use this specific\nemail.\nAnd once you created your account click save.\nAnd now you have the send email set up and working.\nAnd now we will be ready to connect this MCP to cloud.\nWhat you need to do in order to do that is to click connect.\nAnd here you will be able to copy the URL that we are gonna need to use in cloud.\nFirst in the transport, ensure that it's set to Streamable http.\nYou will see along the course that a few times I refer to SSH, sometimes a streamable http.\nYou will learn more on that later, but the idea is that streamable http is now the the current modern\nway for MPs to communicate, but we still have the deprecated way called SSH.\nBut just like a few weeks back, SSH was still kind of the standard and streamable as HTTP was only\nsupported by a few Clients.\nSo now streaming over HTTP is more and more adapted.\nSo click stream HTTP and forget about SSH for now.\nAnd here you have two ways to connect.\nOne is the server specific URL where you encode the authentication token into the URL.\nJust like the naive simple way for connecting and authenticating to an MCP.\nBut the recent MCP implementations support OAuth and you will learn more about OAuth in later in the\ncourse.\nFor now, OAuth is something like login with Google, right?\nStuff like that.\nThat's all.\nSo what I would like to ask you to do is to copy this OAuth server URL and just save it somewhere.\nOkay.\nSo this one, the OAuth server URL.\nSave it somewhere because this is what we are going to use as we are moving on in the next videos.\nOkay.",
            "dataPurpose": "item-2"
          },
          {
            "title": "24. Here is the JSON MCP configuration for your Zapier's MCP",
            "videoUrl": null,
            "transcript": "",
            "dataPurpose": "item-3"
          },
          {
            "title": "25. Evertything MCP - In case Zapier Wouldn't Work",
            "videoUrl": "https://epam.udemy.com/assets/65239327/files/2025-05-19_13-24-39-9cf7e4a78fc5c15010ac41ff3d198dab/2/aa00dd6e108d898b86ce63cfd3c04bfcae65.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOS05Y2Y3ZTRhNzhmYzVjMTUwMTBhYzQxZmYzZDE5OGRhYi8yLyIsImV4cCI6MTc1NTc4NzI5OX0.tl4m1osSQj-DLakzk3gGpDM2-13tScUd3nCxjIWYtDM&provider=cloudfront&v=1",
            "transcript": "Hey, I just wanted to jump in here.\nToday is the 12th of May.\nAt the time of the recording of this video.\nAnd some students reported issues with Zapier.\nIn the next videos, you will see how you can integrate Zapier into clothes and then cursor and send\nan email with Zapier.\nNow, it seems that there is an issue on the Zapier side at the moment.\nSo if you encounter any problems using Zapier tools, which you will recognize by the tools, the Zapier\ntools not popping up here in the next videos, and most probably here on the top right, you will see\nan error message.\nNow, if this happens, I would like you to provide you with a way out from this situation.\nI'm going to monitor the Zapier development, and as soon as it's fixed, I will go and update the course\naccordingly.\nOkay, so in the next videos you will see how you can set up an MCP configuration for cloud, and you\nwill be implementing something like this.\nSo you will need to change the JSON file.\nMore on that later.\nSo you will see that in the next video.\nBut if it doesn't work with Zapier, what I'd like to ask you is to fall back to, um, model context\nprotocol reference implementation, which is called server everything.\nOkay.\nSo you can still see how third parties are implemented in cloud.\nOnce again, it doesn't matter if you don't understand this piece of code yet.\nWe will cover that in the in the next video.\nNow I'm going to provide you with the source code also in the course resources.\nAnd also as a note after this video.\nSo you can copy it and please copy it and keep it handy in case you would run into any issues.\nNow what this specific MCP does is that it gives you a few examples about what you can do with MCP,\nfor example, you can use it as a calculator.\nNow, what this tool does is that it can add two numbers.\nHere you will see the everything tool set once again.\nAnd here is an add functionality.\nAnd on the back end it's an actual add two numbers implementation in Python.\nSo when you want to use it you can just pick two large numbers here are mine and execute it.\nAnd you will see right away how Clode uses the tools for adding these two numbers.\nYou see, like it says, I will use add and it goes the MCP two to add up two numbers.\nNow once again I would suggest you to go with Zapier.\nBut if you run into issues then please just fall back to this implementation and it's going to work\nfor you.\nAnd I will ensure that I'm closely monitoring Zapier's MCP development in the next few weeks and update\nthe course if there are any changes or or any developments on fixing things on this side.\nI'll see you in the next video.",
            "dataPurpose": "item-4"
          },
          {
            "title": "26. Connecting Zapier's MCP to Claude - Make Claude Send Email Summaries",
            "videoUrl": "https://epam.udemy.com/assets/67059551/files/2025-07-30_08-14-27-5d53c077e480aafe0172cd3c67d03723/2/aa00bfea64f907a8f0592769f69b87913e04.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNy0zMF8wOC0xNC0yNy01ZDUzYzA3N2U0ODBhYWZlMDE3MmNkM2M2N2QwMzcyMy8yLyIsImV4cCI6MTc1NTc4NzMyOX0.EM4QmNAKiU-VGiZw9vEH4OexLh4DxrPFTQYgzgHP2zk&provider=cloudfront&v=1",
            "transcript": "Let's integrate the Zapier MCP into cloud.\nPlease have cloud open, and if you click this little icon then you will see all your MCPs listed.\nNow, you probably don't have a file system MCP enabled in your cloud desktop, but for some reason\nthat's something I just cannot deactivate it.\nI use it for everyday tasks, so I'm going to show you how you can add the MCP to the free cloud version.\nI would like to ask you to come to the menu and click settings.\nAnd here you will find the developer.\nNow the developer.\nThis menu is the place where you can add custom MCPs.\nSo once you are here again your list might be empty without the file system.\nI would like to ask you to click Edit Config.\nEdit config takes you to your Explorer or Finder window where you will find the cloud desktop config\ndot JSON file.\nPlease go and open it in Visual Studio Code or in your favorite editor.\nOnce you opened it, it will be probably an empty file.\nAnd now I'd like to ask you to come to the GitHub repository of the course.\nAnd here you find the course resources, which is, as you know, our central central place for all\nthe resources about the course.\nNow, I'd like to ask you to copy this code and integrating the Smcp and paste it here.\nOkay.\nBefore we dwell into this code, I would like to ask you to delete this space disappear URL section.\nSo ensure that it's empty.\nAnd now paste the URL that you copied from the Zapier MCP page.\nHere we go.\nThis is ours.\nNow, just a quick detour.\nWhat you see here is a so-called local MCP.\nHistorically, all the MCP were local processes.\nSo you executed an MCP server locally on your computer, which was able to communicate to some third\nparty services.\nNow this has changed.\nWe have now remote MCP servers, but at the moment of recording, Klod only supports remote MCP servers,\nwhich means direct connections to MCP services.\nIt only supports it through connectors.\nSo as part of your paid plan.\nSo because of this we use now a so-called local MCP server, which is like the the standard easy way\nfor interacting with MCP.\nAnd if you use a local MCP FTP server.\nThere is an NTP package called MCP remote, which is a local package that can kind of proxy to remote\nMCP servers.\nSo it's enough if you get the intuition of this for now.\nBut the idea is that because some of these LM based softwares like Cload, they only support local MCP\nservers in their free versions.\nWe need to pull a small component that acts locally, but that lets us connect to remote servers through\nthis local component.\nAnd this is the MCP remote package on NTP.\nThat's why you see these command and arguments here and the MCP remote command.\nNow once you have added your URL to this JSON, you're good.\nEnsure that you save it and you can go back to cloud.\nAnd actually what we will need we need to do with cloud is to restart it.\nSo let's just go and restart cloud.\nAnd a pop up is coming up right away.\nAnd this is the OAuth part of MCP.\nSo Zapier connects now through an OAuth authentication.\nWhich means that in the URL that you pasted into the JSON config, there is no authentication information.\nBut through the MCP protocol, Zapier instructs the cloud to log in to Zapier so it can act on your\nbehalf.\nSo you will see that the MCP CLI proxy this is this small, uh, remote local connection bridge once\nto access your Zapier account, let's just click allow.\nAuthorization successful.\nSo let's go back to cloud.\nAnd now if you click the search and tours menu, you will see your Zapier MCP connector here.\nAnd here you see that it has editors, editors and Gmail.\nSend email.\nSo it has a tool called Gmail send email.\nSo let's just make it send an email.\nOkay I'll just paste this here.\nSo I say write a haiku about the importance of continuous learning and send it to MCP course@gmail.com.\nAnd I just click send.\nAnd it writes the haiku.\nHere is my haiku.\nAnd now it calls the Gmail send email action.\nAnd Claude right away tells me if I want to allow Zapier to use this tool.\nSo it says it wants to use the Gmail, send email with this specific recipient and this subject and\na certain body.\nOkay.\nAnd I will say always.\nHello.\nAnd now my email has been sent.\nLet me take a look at my email inbox.\nHere we go.\nLet me refresh.\nAnd here is my email.\nWonderful.\nSo this works now.\nAnd from this point on, cloud will be automatically used Zapier to send emails whenever needed.\nIf you want to change this behavior, you can come to settings.\nAnd here in settings now, Zapier will show up as a connector.\nSo you see there is a local MCP called Zapier MCP.\nIf you click Dot dot and you click Tools and Settings, then here you will see which tool of this MCP\nto use without asking or which tools should ask for permissions.\nAll right.\nSo this went well.",
            "dataPurpose": "item-5"
          },
          {
            "title": "27. Adding Zapier MCP to Cursor",
            "videoUrl": "https://epam.udemy.com/assets/65239337/files/2025-05-19_13-24-39-ae7a5ed863f789c32e2687d7c312abe0/2/aa006224746d45267a3ddf99f45df0ea6383.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOS1hZTdhNWVkODYzZjc4OWMzMmUyNjg3ZDdjMzEyYWJlMC8yLyIsImV4cCI6MTc1NTc4NzMzN30.GBXiMEExAjr9lgQZjJkdRkWx34gpQCYBoYR1HInmpdg&provider=cloudfront&v=1",
            "transcript": "Let's go on and add Zapier's SMTP server into cursor.\nWhat you see on my screen is my cursor now, and a few things to do before you will be able to add them.\nWell, the first of all what what's important is that you are logged in into cursor because you want\nto ensure that the agent mode is enabled, and that is only enabled once you are logged in.\nAll right.\nNow once you're logged in, you can go to Cursor and Settings and Cursor settings.\nAnd then here you will see a menu called M.c.p.s.\nPlease click this.\nWhat you will see is either an empty list or if cursor has some preset MCPs for you already, those\nwill pop up in the list.\nWhat we want to add is a new global MCP server, so click Add New Global MCP server.\nIt will take you to a JSON config similarly to how you worked with code.\nAnd I'd like to ask you to go to the course resources and paste the MCP server that I showed you there,\nand replace your token with the token itself that you generated with Zapier.\nAs you can see here, this definition is similar, but not exactly the same as what we use with with\ncloud.\nThe reason for that is that cursor supports now a newer generation of the MCP integration protocols.\nAnd this is let's call it the global MCP URL.\nSo you don't necessarily need to provide a command, but you can also simply provide a URL to access\nan MCP.\nNow this is probably how most of the MCP are going to work later in the future at the at the moment\nof the maturity of MCC.\nIt's still like some tourists using these global URL scheme, which again is the better way to go.\nAnd some other use the uh, NTP remote or uh, some other command to access MCC, which work just as\nwell.\nBut this is the best way and this is the way cursor wants you to integrate MCC.\nSo once you added this you can go and ensure that it has been saved.\nAnd once you close it you will see that the Zapier MCP has been popped up.\nAnd it has a tool called Gmail.\nSend email.\nOkay, this is exactly what we want to have.\nSo at this point, for example, what we can do is to go and just summarize the course resources from\nthis repository.\nSo I have the course resources here.\nRight.\nSo I can just go and now tell cursor to summarize it and send it in an email to my email address.\nSo let me just paste an instruction for that here.\nSo it says send an email to MCP course at gmail.com with a small summary of course resources.\nAnd I can just execute it.\nAnd depending if you run cursor in YOLO mode which is a setting you can find in uh, in the preferences,\nit might just shoot an email right away.\nOr if you don't use cursor in a YOLO mode, then it will ask for permission for sending this email.\nA YOLO mode basically means that, uh, that cursor won't ask you for permission.\nIt will just do whatever it wants to do, which I think is an amazing mode.\nIt is a little bit, uh, dangerous, right?\nBecause it lets cursor execute commands on your behalf.\nBut if you are into cursor A with a good cursor rule that you can also set up here in the setting,\nyou can tell cursor like what kind of commands it should use using YOLO mode and what kind of commands,\nfor example, deleting stuff that it just shouldn't execute even in YOLO mode without explicit approval.\nNow, if you take a look here, it created a summary of the course resources, and then it says I'm\ncalling an Macp tool, which is the Gmail send email tool.\nAnd here we go.\nIt sent this to MCP course at gmail.com.\nAs a quick summary, here is the subject and here is the body.\nLet me switch to Gmail and see if this email has arrived.\nAnd here we go right.\nYou see summary of MCB bootcamp course resources.\nAnd then here it is.\nSo it's a markdown of the course resources.\nSo as you see in cursor things are very very easy.\nAnd for what I see now is that cursor is making lots and lots of development on integrating MCB in a\nmodern way.\nSo that's great.\nAnd they work very, very well.",
            "dataPurpose": "item-6"
          }
        ]
      },
      {
        "title": "Section 6: Where to find the MCP that match your needs",
        "items": [
          {
            "title": "28. Third-Party MCP Hubs",
            "videoUrl": "https://epam.udemy.com/assets/65239381/files/2025-05-19_13-24-39-f7b1571d71098d715083fba46f298ed0/2/aa00c4ba0fe5b7029afdd799302697631284.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOS1mN2IxNTcxZDcxMDk4ZDcxNTA4M2ZiYTQ2ZjI5OGVkMC8yLyIsImV4cCI6MTc1NTc4NzM0OH0.vBEMFekGpslZiDdsN7KSee6pNMNeZxODCKYHhrG-wxw&provider=cloudfront&v=1",
            "transcript": "If you want to explore what MCP servers are available for you to use out in the world, there are many\nwebsites you can turn to.\nI want to show you the three largest, or at least the three most important at the time of the recording\nof this video.\nNow let's start with the official MCP server repository with the reference implementation of a few MCP\nservers.\nThese are implementations that are created by anthropic, the inventor of MCP.\nIt's under Model Context Protocol servers on GitHub.\nAnd if you open this repo then you will see a bunch of reference servers.\nSo here are a bunch working with file systems and git and Google services and databases and so on.\nAnd for example, if you want to integrate slack into your solution, there is an SMTP server for that.\nSo I click slack.\nThen here you will be able to see, as with all the other MCP servers, you will be able to see like\nwhat functionalities this provides you like list channels, posting messages, replying to threads and\nso on.\nAnd also if you keep scrolling down here, you will be able to see how to integrate this into your MCP\nserver.\nThere is also, you know, some setup instructions on how you get your tokens and channel IDs whatsoever.\nAnd then you can just take the slack piece, for example, and add it into cloud, or add it into courser\nand get started.\nOkay.\nSo these are reference implementations.\nThey work like 100% very very well.\nThese are all US officials.\nAnd there is a bunch of others that anthropic lists as official implementations.\nSo these are like verified well Well-crafted implementations of MCP servers.\nAll right.\nThere is another one, another website that I like a lot.\nIt's a misery.\nIt's called misery here.\nIt's a community website for MCP servers, but it's also somewhat more interactive.\nLike let's take a look if, for example, if I want to use web search, it's all categorized.\nYou see that there are more than 100 web search MCP servers listed.\nAnd here is for example, perplexity search.\nSo if I go to perplexity, then I can add here my perplexity API key, which is, you know, I'm just\nadding some random string here, a bunch of letter XS.\nAnd then when I say connect, then here it will tell me how I can integrate perplexity into cloud.\nFor example, if I click JSON, it again gives you the JSON for perplexity.\nSearch.\nAnd here is the API key.\nRight.\nSo if you want to try this out, you must sign up for an account.\nUh, with perplexity.\nIt's free.\nAnd get an API key and then just add this into cloud.\nOr you can also add this into courser.\nProbably exactly the same JSON that you get for both.\nIt also has VSCode and windsurf which is a Corsair competitor.\nAnd the menu bar and a few others.\nOkay.\nSo Smithery very very well crafted website here.\nAnd then there is a third one which might be relevant for you.\nAnd this is Corsair's own MCP directory.\nIt has a bit of a focus on technical implementations or technologies.\nSo for example, if let's say your website uses or your solution uses redshift, which is an Amazon\ndata warehouse, then you can add redshift functionality to cursor.\nI've just clicked redshift.\nI click installation instructions.\nThis will take me to the official redshift MCP.\nI mean, I'm not sure if it's official to be honest, but it will take you to that implementation that\nwas on the list.\nAnd here again, if you want to work with redshift in cursor or in cloud, actually you just take the\nredshift piece from MCP servers, fill in your database credentials and get started right away.\nSo as you can see, there are like thousands of MCP servers out there and you have the opportunity to\ntry them, combine them, and just set up a complete agentic workflow and agentic features into cloud\nor cursor or any other solution that supports MCP.",
            "dataPurpose": "item-0"
          }
        ]
      },
      {
        "title": "Section 7: Implement your own MCP",
        "items": [
          {
            "title": "29. An walkthrough of the MCP Development Libraries",
            "videoUrl": "https://epam.udemy.com/assets/65239363/files/2025-05-19_13-24-38-d4c40305eb8f8a100b7fa52bc1ef26ba/2/aa001348cbde69060428b7f02473dae946cf.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOC1kNGM0MDMwNWViOGY4YTEwMGI3ZmE1MmJjMWVmMjZiYS8yLyIsImV4cCI6MTc1NTc4NzM2MH0.R_CxFtj5nFCQQOPcyGTYLNN2mX_H226sMwsSb-w0bJM&provider=cloudfront&v=1",
            "transcript": "In this section we are going to implement our own MCP server.\nWhat you see on my screen right now, it is the official MCP documentation.\nAnd I just want to show you what languages and frameworks are supported at the moment.\nSo we have the Python SDK and this is what we are going to use here in the course.\nBut there is also a TypeScript SDK.\nAnd if you remember when we executed the Npx command for the Zapier implementation, that implicitly\nmeant that the Zapier implementation uses the TypeScript SDK.\nThen we also have a Java SDK, Kotlin SDK, and also a C sharp SDK that we can use.\nAnd on the top of that, you can also use any technology and just wrap it into a Docker container and\nprovide this as an MCP server, which is probably the best you can do if you want to do something more\nsophisticated with security and everything else enabled, I'm going to show you how we can work with\nthe Python SDK.\nIf you're interested in the full doc, you can come to this GitHub page and you will see that it follows\na similar pattern on how things are implemented as what I've showed you and what I'm gonna show you.\nIt uses you've you've for the package manager and, uh, builds a super simple greeting MCP.\nBut what I don't want to do is to guide you through the documentation.\nYou can do this yourself.\nSo we are going to come up with our own use case, which is somewhat more exciting than just saying\nhello.\nAnd this will be fetching Bitcoin prices real time from Binance.\nAnd we are going to implement an MCP for that.\nOkay.\nSo this is what you're going to do.\nAnd I'll see you in the next video.",
            "dataPurpose": "item-0"
          },
          {
            "title": "30. Hello World with Python FastMCP",
            "videoUrl": "https://epam.udemy.com/assets/65239371/files/2025-05-19_13-24-39-58aa0f4b096376cc7170efc48b24ecf0/2/aa00a642156e088b4dd70e15fcb0f993328a.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOS01OGFhMGY0YjA5NjM3NmNjNzE3MGVmYzQ4YjI0ZWNmMC8yLyIsImV4cCI6MTc1NTc4NzM2OH0.cgdMCN8R63xwR2KGCkc9wS_LjQEVyXN7YTfPBLnEkgg&provider=cloudfront&v=1",
            "transcript": "Let's review the packages.\nThe Python MCP framework requires.\nAnd then let's create a bare bone MCP server.\nSo first the packages.\nIf you take a look at pyproject.toml then you will see the dependencies here right.\nAnd for the dependencies basically all we need is the MCP package with the CLI extra.\nThat means that we want to install the official MCP package, but we also want to add this extra command\nline interface utility.\nWith that all right I had this pinned to a certain version.\nIf you see a different version don't worry about that.\nThat would only mean that I updated the course.\nAnd now we are working with a newer version of MCP.\nAll right, so just take the Pyproject.toml as is.\nWe are also ending a request package, which is a package to make HTTP requests, because this is how\nwe are gonna communicate with Binance.\nAnd this is very much what you need to do.\nYou have already activated the virtual environment and installed everything.\nBut just as a quick recap, for those of you who didn't, you can install everything by saying vsync,\nall right, and then activate the virtual environment by saying source.\nThis is not for Mac source dot env dot bin dot activate okay.\nAnd then you will see this dot band.\nAnd in the course resources you will see the command for for windows On activating the virtual environment.\nAll right.\nSo now our virtual environment has been activated and we are ready to start working with our first own\nMCP server.\nYou will see a reference solution which is called the Binance MCP reference implementation here.\nThis is like the lazy way to go.\nYou can just go and take a look if you want, but I will suggest you to start from scratch to understand\nyou.\nEverything, every you understand every little step along the way.\nSo let us just create a folder called Binance MCP and then add a Python file into it and fill it in\nwith the minimum possible working MCP code.\nAll right.\nSo this will be a true MCP MVP.\nAll right.\nSo this is a new folder Binance As MCP.\nAnd within this folder let's create a new file.\nBinance MCP dot Pi.\nPlease use underscores and hyphens.\nOkay, because Python likes them better.\nAll right so here is my Binance MCP code.\nNow the first thing once you have this is um is to import the MCP package of course.\nAnd the MCP package we are going to use is called fast MCP.\nThis is the official Python MCP implementation.\nAnd it is called fast MCP because it abstracts away many of the complexities of the MCP protocol.\nAnd it provides you a very easy to use, annotation based MCP development workflow.\nAll right.\nSo let's um go and import this.\nSo this is, uh, from MCP server dot cpp.\nAnd I want to import the first MCP class.\nAll right.\nNow I have this.\nThat's great.\nLet's create an MCP object.\nI'm going to call it MCP.\nAnd this will be a fast MCP.\nAnd you can give it a name.\nI'm going to give this a name.\nBinance MCP.\nAll right.\nAnd now the only thing I want to do is to start MCP.\nSo if I start this Python function and this Python file.\nSo this is the standard for if the name is main right.\nThen let's print starting Binance Finance.\nMCP.\nAnd then just run this MCP.\nSo I just say MCP.\nRun.\nAll right.\nThis must suffice.\nLet's take a look.\nI'm gonna CD into Binance MCP and then execute Python.\nBinance MCP.\nAll right.\nAnd it is starting.\nAmazing.\nIt doesn't know anything yet.\nIt can't do anything yet.\nBut it's there.\nAnd we got the MCP package up and running.\nSo that's a good first step.\nSo let's just close it by pressing Ctrl C.\nSo Ctrl C both on the Mac and on the windows.\nAnd we're good.\nSo in the next video I will show you how to add actual functionality into this Python file.\nI'll see you there.",
            "dataPurpose": "item-1"
          },
          {
            "title": "31. A note to students joining from the US",
            "videoUrl": null,
            "transcript": "",
            "dataPurpose": "item-2"
          },
          {
            "title": "32. Adding Real-Time Crypto Price Knowledge to our MCP",
            "videoUrl": "https://epam.udemy.com/assets/65239383/files/2025-05-19_13-24-40-eff7e7877b8fff473181fbb4fe23a959/2/aa00d3d3251703c72f5cd84d6a17aeff3b09.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC00MC1lZmY3ZTc4NzdiOGZmZjQ3MzE4MWZiYjRmZTIzYTk1OS8yLyIsImV4cCI6MTc1NTc4NzM4NX0.Ze4HYGjV8SiHFDOnFqrSlZ4TNeKFW5KmqEidpoVrvRA&provider=cloudfront&v=1",
            "transcript": "Now we are ready to add actual functionality to this MCP server.\nLet's implement the main function that takes a crypto symbol, and then makes a request to Binance and\npulls the exact actual price of that symbol and returns it to whatever line using this MCP.\nThe good news is that with the fast MCP framework, you can just go and implement your function as if\nit was a standard Python function.\nSo let's just take a look.\nSo I go and say um, get price.\nSo I want to implement the get price which takes an actual symbol.\nWhich is a string.\nAnd it can return.\nWell I will just put here any okay.\nAnd what I want to do is I take the Binance URL.\nLet me just paste it from my clipboard.\nSo I take the Binance URL.\nThis is the URL where you can download the current price for any cryptocurrency.\nAnd then we make a request to this URL.\nSo I just say response as a request.\nDot requests dot get URL.\nNow this is very much the base logic.\nWe need to add a few more imports right.\nSo for example I need requests.\nAnd I also need the any type.\nAnd the semicolon here.\nOkay.\nNow all I want to do is to throw an exception if something goes wrong and return the Responses JSON\nas a dictionary, otherwise with requests.\nIt's very, very easy to do.\nI can say response dot res for status, which means that if there is an error, throw an exception and\notherwise I just go and say return response dot JSON.\nAll right.\nSo we are done with our initial implementation.\nI just want to add one more little piece.\nIn my experience, Llms can have a hard time figuring out the actual symbol for Binance because this\nis Binance specific thingy.\nSo I just add a new function, kind of an internal function, which I will call get symbol from name.\nAnd if we take a name like Bitcoin or BTC and then it can return the actual Binance symbol name.\nI'm going to copy paste it.\nSo you don't need to watch me type this in because this will be just boilerplate, so to say.\nSo I can say if the names is Bitcoin or BTC then return BTC to USDt, which is the current bitcoin price.\nAnd if it's Ethereum or ETH, then return this symbol, which is the symbol for the current Ethereum\nprice.\nAnd otherwise, let's assume that this name is the actual symbol.\nSo let's just return the uppercase version of that symbol and I'll just patch this here.\nI know that this is not the nicest way to go, just overriding the symbol variable, but this is what\nI'm gonna do because, uh, this keeps the course very easy to follow.\nSo I just say symbol should be get symbol by name, the actual symbol that I receive.\nSo this is kind of a fix, right?\nFor, uh, the cases if if the LRM doesn't know the the Binance symbol Similarly, there are a few steps\nto follow in order to make this code MCP compatible.\nFirst, we are going to add the MCP tool annotation, and this very much connects the get price function\nto the MCP servers framework, right.\nSo that's one thing.\nThe other one is that we need to add comments to our function.\nAnd because the docstrings actually provide valuable information to the LM and it will help the LM decide\nwhen and how to call this function, I'll just paste a docstring here.\nSo it says it's get price.\nWhat it does is it gets the current price of a crypto asset from Binance.\nThese are the arguments.\nIs the symbol right.\nAnd then it returns the current price of the crypto asset.\nSo that's the second one.\nAnd just to keep everything clear, let us remove the print tag from here.\nOkay.\nSo it doesn't, uh, put everything to the output that not the MCP framework itself wants to put it\nto the output.\nSo let's try to execute it.\nI am already in the Binance MCP folder.\nSo if I say Python Binance MCP dot pi, you will be able to see that it comes up and running.\nBut it doesn't do anything right.\nSo no error message means it is running no output because I removed the output.\nAnd now just contrast it a few times.\nAnd this was a very good smoke test.\nSo our MCP server is now running and we are ready to go on and debug the server.\nIn the next few videos.",
            "dataPurpose": "item-3"
          },
          {
            "title": "33. Understanding how MCPs Handle Paths",
            "videoUrl": "https://epam.udemy.com/assets/65239397/files/2025-05-19_13-24-44-d98a074e4555b63e5248543592c0dd41/2/aa0090e27e5118e4d5900451686d9c7113f8.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC00NC1kOThhMDc0ZTQ1NTViNjNlNTI0ODU0MzU5MmMwZGQ0MS8yLyIsImV4cCI6MTc1NTc4NzQxNX0.svo17CeaaZV5q6QB6FsG31jrpRqNNP81rzBvWxTRqQA&provider=cloudfront&v=1",
            "transcript": "In order to have a robust and safe local MCP implementation, we are going to need to take notion of\ntwo paths in your system.\nOne is the Python files path and the other one is your Python executables path.\nI'm going to show you how to get both both on windows and on a mac.\nFor getting the MCP Pi path, that's super easy.\nAnd it's the same in both Windows and Mac.\nYou can right click it and you can say copy path.\nAnd let me just paste this here.\nSo now I have the full path of my Binance MCP Python file.\nAll right.\nSo that's a check on a mac.\nIf you want to get your Python executables path.\nThen after ensuring that your virtualenv is activated you can simply say which Python.\nAnd then here we go.\nThis is now my Python executables path.\nBath.\nPlease take notion of both because we will need that later on.\nWindows.\nIf you want to get the Python path, then in a PowerShell terminal you can just say get command Python\npath.\nBut there is uh one issue with this it can actually work, but maybe it's better if we replace the backslashes\nwith slashes.\nYou can do this with these hyphen replace extension okay.\nSo now you have the Python path.\nAnd on windows I would like to ask you to do the same with your Binance MCP file path.\nSo if you have backslashes in there just replace them with slashes so that it looks something like that.\nAll right.\nYou can of course find these commands in the course resources.\nAnd now we are moving on.\nAnd I'm going to show you how you can use the built in MCP debugger.",
            "dataPurpose": "item-4"
          },
          {
            "title": "34. A note on recent changes in MCP Inspector",
            "videoUrl": null,
            "transcript": "",
            "dataPurpose": "item-5"
          },
          {
            "title": "35. MCP Inspector - The Best Way to Debug MCPs",
            "videoUrl": "https://epam.udemy.com/assets/67015459/files/2025-07-28_13-01-53-0d54313fe34847b70390bf24f7fdb7dc/2/aa00c07066cb046972ba4122554f35a2d04d.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNy0yOF8xMy0wMS01My0wZDU0MzEzZmUzNDg0N2I3MDM5MGJmMjRmN2ZkYjdkYy8yLyIsImV4cCI6MTc1NTc4NzQzM30.WfnbQX_e_lWLh923dG9wI491hjRI7NhbCeFD3jqc1yM&provider=cloudfront&v=1",
            "transcript": "Once you have finished developing an MCP, your best friend for debugging the MCP will be the so called\nMCP Inspector.\nThe MCP Inspector is the official debugging and tracing tool from anthropic.\nTo take a deeper look into the MCC that you developed.\nSo let's take a look at how it works.\nHere I already have my Python executable and my MCC absolute path, so please have this handy because\nwe will need to pass to the MCP inspector.\nLike what's the python command and what is my Python script.\nSo the MCP script.\nAnd if you want to launch the MCP inspector it's an npm package.\nSo you can say model context protocol.\nOf course you can just copy and paste it from the course resources.\nAnd it's called the inspector.\nIf you execute it like this, you will have the latest version.\nBut I want to pin this to a certain version to ensure that, uh, what you see and what you get in your\nlocal computer are compatible.\nSo I will add tag it with a pinned version.\nAnd now what I will need to pass is the Python executable as the first parameter, and my Python implementation\nas a second executable.\nOkay, let me execute it.\nIf you start it for the first time, you might have a confirmation if you want to access it, and then\nit should open automatically.\nLet me go back to Visual Studio Code.\nSo if it doesn't open automatically, what you will see is that here is the actual URL.\nAnd I would like to ask you to open this URL and it will include the session token.\nAnd this session token is for your safety to be passed in to ensure that you know you're the one visiting\nthis URL.\nWho started the MCP Inspector?\nSo here we go.\nThis is the MCP inspector.\nSo let's see what we have here.\nFirst you must select the transport type and more on the transport types later.\nFor now just keep it at Stdio which is the the local MCP transport type.\nThen here is the command which is our Python command.\nRight.\nSo absolute path to Python.\nAnd for the argument here is my MCP pi.\nOkay.\nI can also set a bunch of environment variables if there are any environment variables that my Python\nfile.\nSo my MCP requires copy the server entry or the servers file, and in authentication, set the header\nname on a bearer token.\nIf you implement an MCP with authentication in the configuration, you can set things like the request\ntimeout and so on.\nAnd also here is your proxy session token.\nOkay.\nSo once you're done please click connect.\nYou haven't had to change anything.\nSo once you click connect hopefully you will see this green dot saying that it has connected.\nAnd here is the initialize command output.\nSo it connected to your MCP.\nAnd here are the MCP basic informations that it received from your MCP implementation.\nOkay.\nSo now here you see that we have everything that we talked about in the theoretical section.\nAnd actually even more.\nSo prompt tools.\nTools we will get back to resources and sampling stations routes Roots or if you want to debug.\nAuthentication like OAuth authentication, you also have a panel for that.\nIf you just want to do a health check you can come to ping and click Ping Server.\nAnd then here is a ping request in history.\nSo in the history uh ping meant just do a health check.\nThe response is empty.\nIt means it's all good.\nAnd here I would like to draw your attention to a little detail.\nIs that for this communication on the left side of the screen there is an error output from Amqp server.\nAnd here you see a read that the processing request of type ping request has been completed.\nAnd I find this a little bit confusing because because of two things.\nFirst of all, everything here is in red.\nIt doesn't mean that it's an error.\nDon't worry about that, okay?\nIt's just red for some reason.\nThe other is that is the error output.\nNow, if you are familiar with the Unix style standard error and resultant output, then you know that\nit doesn't necessarily mean that it's an error if it pops up on the error output.\nAnd for those of you who are not familiar with that, this is the main message.\nJust ignore the error term here.\nIt is just the output.\nIt is just how MCP is architected that it prints its debug info to the error output.\nOkay.\nBut it doesn't mean that it's, uh, that something went wrong.\nSo there's just a standard output.\nOkay.\nAnd now if I go to tours, this is what we care about, right.\nBecause the implemented tool.\nSo if I click this tours here is my Getprice tool.\nAnd I also see the command here.\nSo if I click it I can try it.\nI can just say what's the symbol.\nI can say is btc u s and run tours.\nAnd here is the tour result which is success with the current BTC version of BTC price.\nSorry.\nAnd of course, because we have this, uh, cleanse the input function that we created, I can simply\njust say BTC, and that will work, too.\nAll right.\nIt will be converted to btc, USDt.\nIf you want to take a lower level look, you can click history.\nAnd then here is a two call with the actual symbol.\nAnd then in the response you see how it works.\nThere will always be an error flag in the response that you usually don't care about.\nAnd if it was like an error coming back or a standard, uh, standard response, at least you don't\ncare about this, uh, in the MCP inspector, because if there is an error, you will see it explicitly.\nOkay.\nBut this is like the low level communication.\nSo this is MCP inspector.\nI'm sure that if you implement MCP, you're gonna use it extensively.\nSo take a look around and make yourself home with this tool, and I'll see you in the next video.",
            "dataPurpose": "item-6"
          },
          {
            "title": "36. Understanding MCP Transport Types",
            "videoUrl": "https://epam.udemy.com/assets/67015453/files/2025-07-28_13-01-52-8ccb6823c83baeba442c9b68226334f5/2/aa000a3245dc78b888e3525a37e4c0ca3e5a.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNy0yOF8xMy0wMS01Mi04Y2NiNjgyM2M4M2JhZWJhNDQyYzliNjgyMjYzMzRmNS8yLyIsImV4cCI6MTc1NTc4NzQ2Mn0.S4AY6qg4RB2_onPsXgq9ROAaOmJ9jOpEphS_GGQwkdQ&provider=cloudfront&v=1",
            "transcript": "Let's talk a little bit about transport types.\nSo once you open the MCP inspector you saw that there is Sdio SSD and HTTP as a so-called transport\ntype.\nNow what are transport types.\nTransport types are the actual way your MCP communicates with your LM.\nAnd basically like two categories of transport types, even though there are like three in total.\nOne is the local transport type which is called Stdio.\nAnd then there are the remote transport types like SSH and streamable http.\nSo if you create a local MCP as we did, then the transport type that you probably want to use is Stdio.\nStdio means that your MCP will communicate with the LM through the standard input and the standard output,\nwhich means that whatever messages it sends to sense of the alarm.\nLike, for example, here, you see the, uh, the request and the response.\nThis will be sent through the standard channels, which means like that, as if your MCP was reading\nthis from the keyboard and printing this to the screen, and then the MCP protocol and your MCP framework\nthat runs on your PC will then unpack this into into a communication stream as if it was like a proper\nclient server communication.\nSo that's like a shortcut for implementing local LMS.\nAnd I would suggest you to just go and use this, as long as you don't deploy your Lim to, uh, to\na remote endpoint.\nBut if you want to deploy your LM to a remote endpoint, then you have, uh, two other communication\ntypes.\nSo transfer types.\nOne is the server sent events and the other one is stream HTTP.\nNow forget about SCC.\nSEC is deprecated even though you will see it here and there also in this course, because even though\nit's deprecated, some of the client applications don't support Streamable HTTP yet, which is like\nthe, uh, standard remote Amqp protocol.\nSo SSA is something you don't need to worry about as HTTP.\nYou can think about as like um, a rest API.\nSo like some remote API for MCC, it's a protocol that's an extension of HTTP.\nAt least you can think about it as an extension of HTTP that equips the HTTP protocol with different\nfeatures that are essential for performant, uh, client server communication when you use MCC.\nSo that's called the HTTP.\nAnd the URL usually for connecting to HTTP endpoint will be the MCP host.\nYou know, like whatever.\nThat is a certain port of course.\nAnd then MCP.\nSo that's how we will see that it is a HTTP based HTTP standpoint.\nIf it's ZK, then you will say something like that.\nThat was by default here.\nSo some URL and slash zk.\nSo this is how you will be able to see if the endpoint is sec or HTTP.\nSo wrapping it up.\nWhat you need to remember from this is that for local super simple MVP installation, use Stdio.\nAnd when you deploy your MVP somewhere, then use Streamable http as the last point.\nThis is actually something that you can make explicit in your code.\nSo when you run your MVP server then you can define the transport.\nSo I can say for example the transport should be stdio which is the default.\nBut now it's explicit and you can put HTTP or SSH here to start.\nNot an Stdio based mocp, but an MVP that actually opens the port and communicates with a remote element.\nOkay, so that's about transport.\nAnd now on to our next video.",
            "dataPurpose": "item-7"
          },
          {
            "title": "37. Integrating our own MCP to Claude",
            "videoUrl": "https://epam.udemy.com/assets/65239417/files/2025-05-19_13-24-40-4ebbdf32962329289b30e85259048c08/2/aa00cdbbfb5cf2d1bdd11632293568005fbd.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC00MC00ZWJiZGYzMjk2MjMyOTI4OWIzMGU4NTI1OTA0OGMwOC8yLyIsImV4cCI6MTc1NTc4NzQ3MH0.60K93oU8Qhfm7OrM5wOaNxP4QQCSTpJEton638sz8gU&provider=cloudfront&v=1",
            "transcript": "I guess you can feel that our big moment is approaching, because now we are going to integrate what\nwe did into cloud.\nSo please have cloud open.\nYou will see that we already have an MVP integrated the Zapier MVP right.\nAnd let's go on and add our Binance MVP to the tool set.\nSo I'm going to go to settings.\nPlease go to settings.\nAnd here you will see in developer that Zapier is already configured.\nAnd then click Edit Config which takes you to the Cloud desktop Config.json.\nGo on open it with an editor which will take you to the JSON that you're already familiar with.\nNow all we need to do is to add our own MVP.\nWe can take the Zapier Mccp as kind of a base, and then after a comma, just add the new MVP.\nSo I'm going to call it Binance MCP.\nAnd here our command is a command.\nIs Python.\nRight.\nBut I want to ensure that Python runs in that very specific virtual environment that I created for it,\nbecause it is a local installation.\nSo I will go to my full Python path and copy that here.\nOkay.\nAnd for the arguments I only need the single argument which will be the file name, the Python file's\nname.\nRight?\nAgain, please work with a full path like that.\nI think that should cut it.\nSo let's go back to closed and restart cloud.\nNow cloud has restarted and you see right away that I have for MCC.\nAnd if you take a look you see that I have the get price MCP function right here.\nSo I have a new tool called Get price which gets the current price of a crypto asset from Binance.\nDon't worry about the inline auction returns the LM will be able to understand and handle that.\nNow I can try to use both.\nFor example, I can ask Claude to write an executive summary using the current Bitcoin price and send\nit to my Gmail.\nLet's try how that works.\nSo Claude should be able to see that it needs to use the get price from Binance MCP, right?\nPerfect.\nAllow for this chat.\nAnd now it creates a summary and sends it to my email address using the Gmail send email.\nAllow for this chat.\nOkay, it seems that this has been completed.\nLet me go to my gmail and I have new where?\nHere we go.\nSo here is the current Bitcoin price as part of an executive summary.\nAmazing.\nSo now this is truly agentic behavior.\nWe have a bunch of tools.\nAnd our LLM is able to select which tool to use when and how to combine them.\nVery good.\nSo see you in the next video.",
            "dataPurpose": "item-8"
          },
          {
            "title": "38. Debugging MCPs with Claude",
            "videoUrl": "https://epam.udemy.com/assets/65239451/files/2025-05-19_13-24-40-e34425ffb3c098b8d6ddf477bbc5af5a/2/aa00d4b51cc8d30d0124cbbdee8ec4bbfe5b.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC00MC1lMzQ0MjVmZmIzYzA5OGI4ZDZkZGY0NzdiYmM1YWY1YS8yLyIsImV4cCI6MTc1NTc4NzQ3OH0.XMsFqaVnvFcmJkOFU-QPr51zqMfkcPCdjOc09ncNJno&provider=cloudfront&v=1",
            "transcript": "As you can well expect sometimes things will go wrong.\nYou've already seen how you can debug MCC using the inspector, but in a few cases it will be not the\nMCP itself that fails, but somehow the integration.\nOr it can happen that the MCP for some reason fails only in production.\nBut it works well.\nThe inspector.\nSo let me show you how you can debug further.\nInclude for example, let me go on and break our MCP.\nI will make a very trivial error.\nJust an integration error where I have a typo.\nSo for example, instead of Binance MCP, I'll go and simply say Binance MCC okay.\nAnd save this.\nAnd now I go back to code and restart cloud.\nCloud is restarting, but it says.\nAlready at loading that there is a problem and the Binance MCP server has disconnected.\nLet me open MCP settings and here you will see that for servers that have a problem, you might have\nan error output.\nI didn't find this one to useful yet, but there is a logs folder.\nPlease open the logs folder.\nIt's actually here on the Mac in.\nIt is in your library.\nLogs and cloud.\nBut clicking the open logs folder will take you right there.\nAnd here are general log files about how MCP work and also MCP specific log files.\nSo if I take a look at the Binance MCP log.\nLet me just open this in VS code.\nHere we go.\nSo it says if I scroll way to the bottom because there is some debug info in there.\nHere we go.\nThen I should be able to see that there is a message from client.\nNow this is what you want to look for.\nSo it says that by initialization this and this and that happened.\nAnd right there it says that Python says that can't open file binance mc.py because no such file or\ndirectory exists.\nOkay.\nSo this is the best you have if you're running into integration issues.\nAnd please keep this in mind.\nSo you have the inspector and you have the MCP log for error checking and debugging.",
            "dataPurpose": "item-9"
          },
          {
            "title": "39. Integrating our MCP to Cursor",
            "videoUrl": "https://epam.udemy.com/assets/65239415/files/2025-05-19_13-24-41-eae3104d12607099cd7ed3aa64980476/2/aa004c2e620bc8038580eb1e757c5f4c60ed.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC00MS1lYWUzMTA0ZDEyNjA3MDk5Y2Q3ZWQzYWE2NDk4MDQ3Ni8yLyIsImV4cCI6MTc1NTc4NzQ4NX0.gvH8wQklmFgFiDqpd-1tDX52OD-pTlmqrR-bnSY43t0&provider=cloudfront&v=1",
            "transcript": "Now I'm going to show you how you can integrate mic into cursor.\nWe are going to follow exactly the same procedure as we did with code.\nIf you had issues with the Zapier mic, you might want to ensure that it's not running or code is not\nrunning.\nAnd then I'm sure you will be able to integrate these mic into cursor successfully.\nSo just go to Cursor Settings and Mic.\nHere you will see the Zapier MCP running with a bunch of tools right.\nAnd now you can click Add New Global MCP server.\nAnd let's just add our Binance MCP server here.\nI'm going to go back to the closed MCP JSON okay.\nBecause we can copy and paste the whole config from there.\nHere we go.\nSo this is the cloud desktop Config.json.\nEnsure that you fixed the Binance MCP so it's not missing the P in case you followed the debugging lecture\nearlier.\nAnd then just copy and paste the same config And to cursor save Amqp JSON.\nAnd now in cursor settings you see that I have Zapier Amqp and Binance MCP.\nAmazing.\nSo that's very, very simple.\nI can now go on and in a chat just add some instructions.\nFor example, send me the current Ethereum and Bitcoin price to my email, ensure that the agent mode\nis on and then cursor will understand that you want to use a tool.\nIt wants to get a use the Get price tool.\nHere we go for Bitcoin.\nIt also wants to use the Get Price tool for Ethereum.\nIt's just already two two coils.\nAnd then it wants to use the get the Gmail send email tool.\nRun this or two.\nOkay.\nAmazing.\nSo now our cursor agent retrieved the prices and sent it to my Gmail account.\nLet's take a look.\nHere it is.\nCurrent cryptocurrency prices.\nHere is Bitcoin.\nHere is Ethereum.\nAmazing.\nSo that's what simple right.",
            "dataPurpose": "item-10"
          },
          {
            "title": "40. Debugging MCPs in Cursor",
            "videoUrl": "https://epam.udemy.com/assets/65239425/files/2025-05-19_13-24-41-ead8af55860850d8f662fd447856e819/2/aa00bbcc2bba28feebe821154e8694bfab9a.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC00MS1lYWQ4YWY1NTg2MDg1MGQ4ZjY2MmZkNDQ3ODU2ZTgxOS8yLyIsImV4cCI6MTc1NTc4NzQ5Mn0.moKL6c8uc2vg9CO4ti3dBFRxf-iUf46k2VOT1ci564I&provider=cloudfront&v=1",
            "transcript": "If you're owing to an error with your cursor MCP integration, then either you will see a meaningful\nerror message here in the MCP panel, but usually couldn't really find useful information here.\nBut the MCP output and the MCP integration information is located in the console behind cursor.\nYou might know that cursor is an electron app, which means that it's it's actually kind of a Chrome\nbrowser and an app written in in a browser.\nSo you can open the developer tools of this built in browser of cursor.\nHere we go.\nAnd then here you will see all the errors coming up from the MCP servers.\nI won't be able to provide you with a real world example for that, because just generally speaking,\nI found that clothes debugging capabilities are quite good because of the log files are very, very\ndetailed.\nBut here in cursor I had a hard time to to find a useful information.\nSo what you want to do again, if you run into an integration problem, just look at these extension\nhost messages.\nAnd hopefully you find you find the solution to your problem or what you can do if you have again,\na production problem with an MCP server is to try to open it in an inspector or to try to integrate\nit into cloud and take a look at the cloud log messages.",
            "dataPurpose": "item-11"
          },
          {
            "title": "Assignment 1: Add Price Change Functionality to your MCP",
            "videoUrl": null,
            "transcript": "",
            "dataPurpose": "item-12"
          }
        ]
      },
      {
        "title": "Section 8: Working with Resources",
        "items": [
          {
            "title": "41. MCP Resources Overview",
            "videoUrl": "https://epam.udemy.com/assets/65239385/files/2025-05-19_13-24-39-e8c2464d8647e1e8f0aabbe37aa7567a/2/aa007b7217096a8e960a2c580556139098d5.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOS1lOGMyNDY0ZDg2NDdlMWU4ZjBhYWJiZTM3YWE3NTY3YS8yLyIsImV4cCI6MTc1NTc4NzUzN30.GtH93gpJ2Ur-_fxrwiQdXT7GpgRWqmT6EwDgXeaFOcY&provider=cloudfront&v=1",
            "transcript": "When you want to add extra context to your LMS and more like extra static context, then resources are\nthe best way to go with that.\nResources is a functionality where you can instruct your LMS server to access a certain resource.\nLet it be, for example, a file or a database table, or very much anything else.\nAnd to expose these resources to the LM host.\nThis way your MCP server will be able to provide extra context with the LMS.\nA typical resource is a file, like an image or a text file or PDFs that you store on your servers,\nbut it can be very much anything else, for example, database tables or some kind of a representation\nof a database table.\nEverything that you can just send to your LM, it can be also an API call like the result of an API\ncall.\nAnd this point, if you think about it, for example, in our example we have the crypto prices right.\nThose are now represented as tools, because this is the most well supported and standard way for Llms\nto interact with M.c.p.s.\nBut if you think more about it, those can be thought of more like as if they were resources.\nIt's just kind of a a table with a, with a crypto symbol and a crypto price, or just a database record\nwith a crypto symbol and the crypto price.\nSo, for example, there's also a good example for resources, even though behind the scenes there is\nan actual API call going on.\nBut that's completely okay.\nSo this is about resources.\nIf you follow the MCP protocol, if you take a look at the specification, you will see that there are\nbasically two functionalities of resources.\nOne is listing all the resources on an MCP server, and the other one is accessing a resource or reading\na resource.\nNow, at the moment of recording this video, cloud for example, doesn't support listing resources,\nbut the MCP inspectors on the protocol level it is supported.\nSo cloud at the moment likes to work with a single resource, so you can define what resources you have\nin the code.\nAnd then those are the resources cloud will be able to work with.\nThere is also another feature that is supported by MCC.\nBut again at the moment of recording this video, cloud doesn't support it yet.\nAnd this is resource templates.\nWith resource templates you can work with parameterized resources.\nNow a good example is again the crypto price.\nSo for example you can expose a resource in an Mtcp saying that this is a crypto price resource and\nit accepts one parameter which is the symbol itself.\nAnd then of course, the underlying logic on the MCP side will pick up the correct price for the symbol\nwherever this resource is called and is the LM host.\nSo the client responsibility to call this resource with the actual symbol all the time.\nAgain, this is a feature that is already supported in the MCP inspector, but not in cloud yet.\nAll right.\nWith that, let's go on and do some hands on work.",
            "dataPurpose": "item-0"
          },
          {
            "title": "42. Implementing Activity Logs",
            "videoUrl": "https://epam.udemy.com/assets/65239401/files/2025-05-19_13-24-41-0e8d162eb190c0963eddfda4ead51fbe/2/aa002226ee5b896f326679c5ffbe74d2f80a.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC00MS0wZThkMTYyZWIxOTBjMDk2M2VkZGZkYTRlYWQ1MWZiZS8yLyIsImV4cCI6MTc1NTc4NzU0NH0.UmN_uPp8rfacH6XeZ5uTTrCZmwdtg0PBfDNu8gKd1z8&provider=cloudfront&v=1",
            "transcript": "I'm going to walk you through the code of the resource implementation, and we are not implementing\nit from scratch because this code is very, very easy, but it contains some boilerplate.\nYou can take a look at the code if you open the Binance MCP with resource.py file.\nSo here is our use case.\nThe first thing I want to do is to maintain an activity log for our MCP server.\nSo whenever someone makes a request I want to put the request result.\nOr if there is an error, the error itself into a file called activity log.\nAnd here comes my implementation.\nSo I'm simply using the Pathlib for accessing paths that you might be familiar with that just like a\nmodern way for working with with paths and not OS.\nSo I just take this folder, the resource folder, which is the Binance MCP reference implementation.\nAnd then I take a look at the activity log file.\nI define the activity log file, which I want to store in this folder under the file name activity log.\nOkay, so I have this constant here.\nAnd this is where I will write everything.\nAnd I also want to go and ensure that this log file is always available.\nSo when I start my MCP if the activity log file doesn't exist I'm going to go and touch it.\nWhich means I will make the MCP create an empty file.\nOnce we are done with that, we can rework our tool.\nSo the Getprice tool and what we want to achieve is that all the activities are logged into this file.\nSo what I will do is here in the response instead of using race for status, which is in our original\ncode.\nI do some more sophisticated response analysis.\nI check if the status code is 200 or not.\nSo if it is an HTTP okay of or if we have an error.\nIf there is an error, I'm going to open the activity file and just write error.\nGetting price change for symbol.\nAnd I write the status code and also the actual text of the response.\nSo the error and I'm also raising an exception so that my MCP client knows that there was an error.\nRight.\nSo first writing it to a file so I can access it later, and then raising an exception which will behind\nthe scenes converted into an MCP error and returned to the client.\nThe first MCP library that we use here does this.\nIf the request goes through, then I simply extract the price and put the price into the activity file\nwith this message that I successfully gotten the price for a certain symbol, and I return with the\nmessage.\nThe current price of symbol is price.\nOkay, so that's like our boilerplate implementation, right?\nSo now we can log into an activity file.\nLet's take a look at how you can work with resources and how you can create this activity log resource.\nSo that then later your LM can access it.\nHere we go.\nThis will be super, super simple.\nYou can annotate any function with the resource.\nAnd then you provide it with a protocol.\nLet it be a file or a resource as you will see later or anything else really.\nIt's, uh, for you to choose.\nI would like to maybe suggest you to avoid HTTP or Https or or, you know, maybe these two because\nfrom our experience, the actual MCP implementations or the MCP clients like load, they can't understand\nthat you are also exposing an HTTP protocol, something through an MCP protocol.\nSo you might want to use resource.\nBut file works also very very well.\nAnd here you can add define name.\nAnd then you can simply define how the content of this resource is read and returned.\nSo in this case we simply open the activity log file and return the content as a byte stream to our\nlamp.\nLet's also take a look at resource templates.\nIf you want to expose a resource template that's just as simple as exposing a resource, you can annotate\nyour function with MCP dot resource.\nThen you provide it with a protocol call again, simply using resource is safe enough.\nYou also add the category.\nFor example.\nNow what I want to expose is a crypto price.\nAnd then you can also add a parameter or multiple parameters.\nIf you take a look at the function implementation it's quite easy to catch what it does.\nIt simply takes our get price tool and exposes it as a resource.\nBecause at the end of the day, price of a certain symbol is just a resource.\nIt's not really something sophisticated like an action that you need to do, right.\nSo it's just a simple thing.\nSo I'm exposing it here as a resource.\nAnd if you implement this you can specify all these parameters and then use these parameters here in\nyour actual function implementation.\nHere what we do we simply pass this symbol.\nSo the parameter to the original get price function and return with the results.",
            "dataPurpose": "item-1"
          },
          {
            "title": "43. Introduction to the MCP CLI",
            "videoUrl": "https://epam.udemy.com/assets/65239387/files/2025-05-19_13-24-39-75f3538b5e0c4bfd212504f82e280972/2/aa002a3c2fcf4f64b829c535661d7abf1489.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOS03NWYzNTM4YjVlMGM0YmZkMjEyNTA0ZjgyZTI4MDk3Mi8yLyIsImV4cCI6MTc1NTc4NzU1Mn0.ergFu8JJZVXbCnuXY4NPkq28fD5iJsXZRur1gB7svyQ&provider=cloudfront&v=1",
            "transcript": "Here is a quick thing I want to show you before we check our resources in the MCP Inspector.\nAnd this is the MCP cli.\nSo the MCP package in Python introduces the MCP CLI, which is the MCP command that you can use.\nIf you type in MCP, you will see that it comes with a bunch of features.\nYou can start a development server.\nSo fire up basically the MCP inspector or run an MCP server without the inspector, or install an MCP\nserver into the cloud desktop app.\nSo we are going to use the CLI CLI now to start our MCP inspector, because it's just easier as typing\nout the inspector command that we used earlier.",
            "dataPurpose": "item-2"
          },
          {
            "title": "44. Implementing and Debugging Resources an Resource Templates",
            "videoUrl": "https://epam.udemy.com/assets/65239395/files/2025-05-19_13-24-39-c40fd54d17fd32c9925e7729087e9099/2/aa00f3b29c4fd75ce8859b38246f68ef3c9e.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC0zOS1jNDBmZDU0ZDE3ZmQzMmM5OTI1ZTc3MjkwODdlOTA5OS8yLyIsImV4cCI6MTc1NTc4NzU1NH0.ocqjM9EGoS7b5rgInMUy8E9Z11SbHcIQiuuY_9sn618&provider=cloudfront&v=1",
            "transcript": "Now let's see if our solution works.\nYou can start with MCP dev and then point to your Python file.\nI'll execute this real quick.\nMCP Inspector is coming up and is listening on port 6074.\nLet me open that.\nFirst let's connect.\nAnd then before we do anything, I would like to use the tools panel to ensure that we have some data\nin the activity log.\nRight.\nSo let's go to tools.\nHere is my Getprice tool.\nAnd I can try to ask for Bitcoin for example.\nSo this is BTC USD right.\nRun the tool here is the actual price.\nAnd I can also ask for something that's non-existent.\nSo I can say like uh x x x x x x us TX where it says error executing tool get price.\nNow the first thing I'd like you to, uh, to notice here is that we have gotten back with an error,\nright.\nSo this is the exception that we, uh, threw in the MCP implementation.\nSo this is now red.\nOkay.\nAnd now we should have a few things in our activity file.\nRight.\nSo let me go to resources.\nAnd here in resources I will say list resources.\nAnd it says okay you have a file called activity dot log.\nLet me just click it.\nAnd then here we go.\nIn the contents you will see that we have a successful Bitcoin price and dot dot dot.\nIf I click it you will see that there is the error there too.\nAll right so it read the file.\nLet me go to VS code and show you the actual file that we wrote here.\nYou can see that indeed this is what we have written to the activity.\nSo our resources work well.\nThat is great.\nLet's take a look at the resource templates.\nSo let's click List templates.\nIt says okay I have a get crypto price resource template.\nAnd if I click it I can enter a symbol.\nAnd in this symbol I can just pass the symbol itself right.\nSo for example BTC, USD and then click Read Resource.\nAnd here we go.\nYou get the current price of btc USD.\nOkay.\nAgain what happened behind the scenes is that with the activity log we simply expose the resource through\nthe first Amqp library.\nAnd with the get crypto price, we created a crypt.\nWe created a resource template which simply called the Get Price tool.\nSo our gas price function behind the scenes.",
            "dataPurpose": "item-3"
          },
          {
            "title": "45. Accessing Resources in Claude",
            "videoUrl": "https://epam.udemy.com/assets/65432789/files/2025-05-26_11-39-50-432e7f0054d7b98e9e49ed27b08cfc0f/2/aa0000ebad7d9bc8c0164cdb833e8a9e967c.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yNl8xMS0zOS01MC00MzJlN2YwMDU0ZDdiOThlOWU0OWVkMjdiMDhjZmMwZi8yLyIsImV4cCI6MTc1NTc4NzU2N30.bwUP1gvBr8mWXmj7NM4OBE4WCV2Qx1fBFswVQQi0aXQ&provider=cloudfront&v=1",
            "transcript": "Let's see how resource management works in cloud desktop.\nFirst of all, please ensure that cloud points to the proper Python file which has the resource implementation.\nIf you followed along in your own file, then you might not need to change that.\nIf you want to work with the reference implementation, please update this path in the cloud desktop\nconfig JSON and also then go ahead and restart cloud.\nOkay, once you did this change, then if you switch to cloud you will see that we still have our tools\nof course here in the tools menu.\nBut you can also access the resources.\nSo here you see you can add a resource from the Binance MCP.\nAnd you will see the activity log file popping up here.\nYou can't see the resource templates yet because at the time of recording this video, Cloud Desktop\ndoesn't support resource templates.\nBut if you want to take a look at the activity log, you just add it to the context and then you can\nask a question, for example, how many successful requests and errors do you see in activity log?\nHere you see the answer to successful requests for BTC, USDt, and one error for our X.x.x.x symbol.\nSo that's worked quite well, right?\nOkay, so with that we are concluding resources and I see you in the next video.",
            "dataPurpose": "item-4"
          },
          {
            "title": "Assignment 2: Create Your Own Resource",
            "videoUrl": null,
            "transcript": "",
            "dataPurpose": "item-5"
          }
        ]
      },
      {
        "title": "Section 9: Implementing Prompts Into Your MCP",
        "items": [
          {
            "title": "46. Prompts - Introduction",
            "videoUrl": "https://epam.udemy.com/assets/65432787/files/2025-05-26_11-39-47-40dcb39f0fa16e2105369884d26bae4c/2/aa00883df0603f91fc8b747ae2dca3c69519.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yNl8xMS0zOS00Ny00MGRjYjM5ZjBmYTE2ZTIxMDUzNjk4ODRkMjZiYWU0Yy8yLyIsImV4cCI6MTc1NTc4NzYxMX0.FlCf5eoom6rth6cZNAAKQ9pTzhi_-Uet-CnYAWlsNi8&provider=cloudfront&v=1",
            "transcript": "To be honest, the first time when I explored MCC and I found this concept of prompts, I got quite\npuzzled because I believe it's quite easy to understand what tools are for, and it's quite easy to\nunderstand what resources are for.\nBut what can prompts be there for?\nI also had a hard time finding meaningful resources and examples of prompts, but then finally I was\nable to find a few.\nSo let me just give you a few examples.\nSo for example, if you want to do code reviews and you do code reviews all the time in cursor, then\nyou have some preferences.\nSo for example you want to tell the LLM what to pay attention to and in what style to give a code review.\nWhat are the things that don't matter for you or any other instructions that you think are important\nto you?\nSo in this case, what you would do is to just type in the same prompt message all the time for each\ncode review.\nRight now, this is what prompts can, for example, solve.\nAlso another example.\nI love learning languages and if I use code as a language tutor, what I do is that I use actually projects.\nBut at the end of the day, what I do is that I inject a prompt which defines like at what level I am\non and what kind of corrections I'm after, in what style I would like to get those and what other suggestions\nI would like to have.\nSo these, if you think about it, are very good candidates to be just packaged and put into an SMTP\nserver.\nSo for example, if you have a code review server, then you don't want your users to type in all their\npreferences or all the standard practices all the time into your code review tool, but you can have\na set of prompts that define that for such a kind of code review.\nThese are basically how I want you to code review everything.\nAnd for another type, this is how I want you to code.\nReview everything.\nAnd this way, as an app developer, you will be able to expose a prompt to the user and let the user\nselect one of these prompts and just push it into your LLM.\nNow I will show you an example about cryptos.\nSo what we are going to do is to request an executive summary about the two most popular crypto assets.\nSo I don't need to specify as a user what are the most popular assets and how to code the tools whatsoever\nto get me an executive summary, but I have this prompt provided for me in the MCP.\nSo let's see this in practice.",
            "dataPurpose": "item-0"
          },
          {
            "title": "47. Simple Prompts",
            "videoUrl": "https://epam.udemy.com/assets/65432783/files/2025-05-26_11-39-41-58986dccc56e532324adf88b50c128c8/2/aa00f2333b72b5acd06ac612337447e1271b.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yNl8xMS0zOS00MS01ODk4NmRjY2M1NmU1MzIzMjRhZGY4OGI1MGMxMjhjOC8yLyIsImV4cCI6MTc1NTc4NzYxOX0.4uzxli7BMS66rmPeMdsSmPWcmD3xBbJNBgefP0EF-b8&provider=cloudfront&v=1",
            "transcript": "What I want to do is to create a new function.\nI will call this the executive summary.\nIt returns a simple string.\nThis will be our prompt.\nI also add the docstring and it says returns an executive summary of Bitcoin and Ethereum.\nAnd I also annotate this function with the MCP prompt annotation.\nAnd once I'm done I'm ready to fill this in.\nSo just fill in the prompt that I want to pass to for example, cloud when it uses this prompt.\nThe prompt itself will be relatively simple.\nI just say give me the prices of the following crypto assets BTC and ETH provide me with an executive\nsummary including a two sentence summary including the prices including the price change and also the\npercentage change in the past 24 hours.\nJust to be on the safe side, I will also instruct my LLM.\nThrough this prompt to use the get price and the Get price price change tool.\nAlso, I can make my LLM smarter by explicitly defining the crypto to symbol mapping.\nThis is kind of a prompt way of doing this.\nGet symbol from name functionality right.\nSo we can achieve the same through this prompt.\nLet me save this.\nAnd then just go on and open the MCP inspector.\nAnd once my MCP inspector opens, I can just connect through Stdio to my Binance MCP and then go to\nprompt and click List Prompt.\nYou see that?\nNow I have an executive summary prompt.\nLet's just click it and retrieve the prompt.\nThe prompt is here.\nAnd once I expanded it, you can see that it's nothing more but the simple text that I provided my MCP\nwith.\nLet's try this in code.\nYou might want to restart code to pick up the latest changes from your MCP.\nAnd once it's done, you can click the plus icon and you will see the add from Binance MCP item.\nAnd here now besides the activity log resource there is also an executive summary prompt.\nJust click it and it will be attached to your session.\nIf I click this here then I will be able to investigate the text itself.\nWell this prompt is very much self-contained, so I will just send it straight to the LM and wait what\nit does.\nSo you see, it gets the prices and it also gets the price changes.\nAnd then it's going to create an executive summary for me.\nHere we go.\nAll right.\nSo that was all right.\nSo that was easy.\nLet's just take it a step further because you can also add parameters to prompts.\nAnd this is what we are going to implement in our next lecture.",
            "dataPurpose": "item-1"
          },
          {
            "title": "48. Parametrized Prompts",
            "videoUrl": "https://epam.udemy.com/assets/65433903/files/2025-05-26_12-31-58-4e57f1d4f1e906af6133694faede0bb1/2/aa00c66a410effda287cb08ef3622755ba7d.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yNl8xMi0zMS01OC00ZTU3ZjFkNGYxZTkwNmFmNjEzMzY5NGZhZWRlMGJiMS8yLyIsImV4cCI6MTc1NTc4NzYyNn0.eJx9jT4RQdcfzZUGwyfeaqPsEp8dgsEl4zVuLe2ndJE&provider=cloudfront&v=1",
            "transcript": "I have pasted this here for you already.\nSo let's take a look.\nIt's very, very similar to the prompt that I created earlier.\nSo now we call it a crypto summary.\nIt's still annotated with MCP prompt, but now it has a parameter.\nAnd this parameter is the crypto name itself.\nAnd if you take a look now what I want to do is to only get the current price of the following crypto\nasset and then the cryptos name.\nI also want to get the price change.\nAnd just to make our LLM smarter, I'm passing the crypto symbol mappings.\nOkay so it should be super simple.\nLet me just save this and start my MCP inspector again.\nConnect to my MCP.\nGo to prompts, list the prompts and you'll see that now I have crypto summary here too.\nAnd when I click it, it asks for my input so I can say I'm interested in BTC and then I can click Get\nPrompt.\nLet me just expand this.\nAnd there you will see that it has the tags.\nGet the current price of the following crypto asset BTC.\nSo my parameter has gotten substituted right.\nLet's see how it works in code.\nYou might want to restart code again.\nAnd once you restarted it you can go to the ad from Binance Macpaint.\nAnd then you will see that now I have a crypto summary prompt.\nAnd if I click it, it's gonna ask for my input.\nSo I can just say BTC and say add prompt.\nNow with this parameter and if I click the prompt you will see that cloud has substituted this value\ntwo.\nNow I can just send this straight to the LM.\nAnd just as in the previous use case, you will see cloud using our tools and then giving us a short\nsummary about what happened with Bitcoin in the past day.",
            "dataPurpose": "item-2"
          }
        ]
      },
      {
        "title": "Section 10: Integrating MCPs into Python, LangChain, LangGraph and LangSmith",
        "items": [
          {
            "title": "49. Calling MCP Services from Python - Using Python as an MCP Client",
            "videoUrl": "https://epam.udemy.com/assets/65239427/files/2025-05-19_13-24-44-ef047d28ea7c17db9fa04f1909389921/2/aa000f2d0d6b895c0c52fa297bf5da9c7dd4.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC00NC1lZjA0N2QyOGVhN2MxN2RiOWZhMDRmMTkwOTM4OTkyMS8yLyIsImV4cCI6MTc1NTc4NzYzOH0.IpbWCspERnPZF2BXm8Seb7xIoqXXTIuKbUhhL0Ma9kw&provider=cloudfront&v=1",
            "transcript": "You have seen already how to implement MCC into popular tools like load or Cursor.\nNow let's see how you can access MCC from native software pieces, for example from a Python file.\nWe are going to implement a simple native MCC color function.\nAnd for that I'm going to create a new file which is called MCC client.\nSo here is MCP client dot pi.\nAnd I'm going to pass in a bunch of boilerplate.\nSo I will just copy paste a bunch of code here.\nBy the way if you take a look at the course resources you will also see an MCC client Pi implementation.\nSo you can just take a look at that or follow along coding as you wish.\nSo first of all let's do some imports.\nWe are working with paths here.\nSo I'm importing Pathlib.\nAnd then I'm importing the core functions and classes which come from the official MCP package.\nAnd then again, just a little bit of boilerplate.\nI want to know what is my root folder, which is the current folder of the file.\nAnd then I also want to point to my MCP folder.\nMy MCP code is here in Binance MCP reference implementation which is here.\nBut if you followed along coding you will already see a Binance MCP folder in your workspace.\nSo just feel free to change this to to Binance MCP if you want.\nOkay.\nSo now I have my MCP folder.\nThe first thing I want to do is to recreate kind of these JSON definition like configuration for my\nMCP.\nSo my client knows how to access it.\nAnd this goes through the Stdio server parameters where I pass the command.\nSo I pass an executable and I pass the arguments.\nAnd I also can pass an environment.\nNow here I just want to call Python and pass the Binance MCP Python file from the MCP folder.\nAnd I don't want to pass any special environment whatsoever.\nRight.\nSo now I have my MCP server configured so I can use it for connecting to it.\nFor this I must create an async function that accesses and calls this MCP.\nSo I will just say async def run.\nAnd then here I will go and open a connection to my MCP.\nAnd this is how you can do that.\nBut first of all you will need to create an MCP client.\nIn our case this is now an Sdio client because this is a local MCP.\nI'm passing the server parameters here.\nRight.\nThis is the this is how I configure the whole connection.\nAnd I'm specifying a read and write Eight variables for the return values, so I can just send messages\nand retrieve messages.\nThis is simply how Stdio client works.\nOnce I'm done with that, I can create a client session and MCP client session, which will be already\nthe connection I can use to communicate with my MCP.\nOkay, so now that I have a session, I can simply say await session dot initialize.\nAnd now the session will be opened at this point.\nAnd let's say we just want for as a first step let's just let's just code it to let's just see what\nkind of tools we have in this MCP.\nSo we say the tools is a great session dot list to us.\nSo these are the tools that my MCP provides.\nAnd I want to also print these tools.\nSo I don't want to over complicate it.\nI just print it to the screen.\nLet's just wrap all of this into a into a main function.\nOkay.\nLet me paste this code here.\nSo for the main function we will need to use the Asyncio library because we want to call async functions\nfrom asynchronous main function.\nSo this is how you can call a function if you want to work with async in Python.\nAll right.\nSo this already lists our tools.\nLet's take a look if it works.\nSo I will just say Python mocp client.py.\nAnd then here we go.\nWe have a bunch of tools.\nYou see here is a getprice tool.\nAnd there must be also the gas price change to somewhere here.\nAll right.\nSo that works very very well.\nWe've been able to connect to our mocp and retrieve what to us it supports.\nSo I'm gonna go and just get rid of this code now and do the actual MCP calling.\nOkay.\nSo for calling an MCP, that's again super, super simple.\nI can just say.\nAwait session.\nAnd I must pass the functions of the tool name as a string parameter.\nAnd then I must pass the arguments as a dictionary.\nSo here I'm getting the Bitcoin's price through the get price protocol and just print the results.\nOkay.\nAs simple as it gets.\nSo if I do this again now I say python mcp client.py.\nThen you see that it actually works.\nI have some return value.\nRight.\nSo this is the result object which just says it's a list actually because there might be like several\nmessages coming back, but it's a simple text message that my MCP returned where the text content is\nthis little piece here.\nSo this is if you are if you are familiar with, with LM, uh, low level LM, uh, communication,\nthen you can see that it's like a very standard response.\nSo if you want to extract the actual value, then you can say take from the result.\nTake the content as you can see in the result.\nAnd from the content I just take the first item.\nRight.\nAnd I'm interested in, uh, the text.\nAnd actually this must be a dot because it's an object.\nOkay.\nSo now I can access the actual response itself.\nSo let me just re execute the MCP client.\nHere we go.\nAll right.\nSo that was very fast and very very easy.\nThat's perfect.\nAnd just one last thing I want to show you is that what happens if you actually make an error.\nSo if I go and say btc usd zk so I pass a symbol that's nonexistent.\nThen if I execute my client now, then it will say bad request for url.\nBTC usd zk.\nSo that works also well.\nBut just one last thing.\nMaybe if you if I print the result itself to the screen, then you will see that it's actually still\na text content.\nIt is not like an exception or anything like that, but the way an MCP signals that there was an error\nis that in the content object you will always find an Is error flag.\nAnd if you take a look here, you see that this error is true.\nSo if you want to make your own native implementation, then this is very much what you want to look\nout for.\nSo you send the request and as you receive a response, you just check if the error is true or false.\nAnd if it's true, then you know that something went wrong.",
            "dataPurpose": "item-0"
          },
          {
            "title": "50. LangChain and LangGraph Intro",
            "videoUrl": "https://epam.udemy.com/assets/65239473/files/2025-05-19_13-24-42-371f55f2b074f55cb508d46ad8727841/2/aa008abdbf1d957e5df22196e69873b4514c.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC00Mi0zNzFmNTVmMmIwNzRmNTVjYjUwOGQ0NmFkODcyNzg0MS8yLyIsImV4cCI6MTc1NTc4NzY0Nn0.sas2Q8WD_HOtvo1X2XcUPNaQPDBMSSrjC8FN3Ex5LAE&provider=cloudfront&v=1",
            "transcript": "If you read papers and articles on best practices working with LMS.\nUsually companies like anthropic say that you should keep it at the native level as long as possible,\nso don't overcomplicate things.\nBut as your maturity of the code, it just develops, at one point it might pay out to jump into a framework\nthat manages much of the boilerplate for you.\nAnd the most popular framework at the moment out there for these kind of tasks is long chain.\nAnd also in addition to that lang graph.\nSo lang chain is an open source package that you can use in Python or JavaScript.\nAnd what it does is that it kind of abstracts away the low level mechanisms of uh, of the whole LM\nprocedure.\nSo for example, tool calls can happen automatically.\nOr if you want to switch an open AI to an anthropic LM, you can do it with a with a line of code.\nAnd you don't need to overwrite or rewrite the whole interaction whatsoever.\nSo Lang chain is a great tool.\nAnd because of this, I want to show you a demo on how you can implement MCP access in Lang chain.\nFor this we will also use Lang chains framework which is called Lang graph.\nNow what Lang graph does is that it provides agentic behavior for lang chain for example automatic tool\ncalling or routing.\nSo your tool would be able to decide what to do at one point.\nAnd the LM itself would be able to decide what tools to use to achieve a certain goal.\nSo let's go on and implement our MCP tool call using these tools.",
            "dataPurpose": "item-1"
          },
          {
            "title": "51. Integrating OpenAI with LangChain",
            "videoUrl": "https://epam.udemy.com/assets/65239437/files/2025-05-19_13-24-40-a1073c01e98b619b47dbae1501efd7af/2/aa006a6d3ce878839cd58d6d6fb00b6fc60b.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC00MC1hMTA3M2MwMWU5OGI2MTliNDdkYmFlMTUwMWVmZDdhZi8yLyIsImV4cCI6MTc1NTc4NzY1M30.eCqjx4tDvdx27iydnO4KZdBxa7-O19Ta88RA_2edA9k&provider=cloudfront&v=1",
            "transcript": "For Erlang graph implementation, we are going to use the OpenAI backend because I found that even though\nGoogle has a free tier right with Gemini, but if you do two calling and you try things once, twice,\nthird, you can very, very easily run out of quota.\nSo if you want to fire off these hands on, I would like to ask you to sign up for OpenAI.\nSo not ChatGPT, but OpenAI itself, and top up your balance and then retrieve an OpenAI API key and\nadd it to your dot m if you don't want to do that in the course resources, I will also give you in\na commented out block the commands to connect to Gemini so you can give it a shot yourself.\nAll right, so first thing, just add your OpenAI API key to the dot m file that we have here and create\na folder called graph.\nIn this video we are going to first just saying hello to Liang Chen.\nLike to open AI through Liang Chen to ensure that everything works and that will enable us then to create\na tool called based agent.\nAll right, so let's create a new file in line graph and let's call it price graph price graph dot pie.\nAnd again I'm going to copy and paste a bunch of boilerplate code.\nBut feel free to just take a look at the reference solution or to code along as you wish.\nSo the usual suspects we are going to work with a async function.\nSo we import async io and we import uh pathlib.\nAnd we are we also need the dot env values right.\nSo let's also import from dot env load dot env.\nAnd let's load the dot env values.\nAnd let's create an OpenAI model.\nSo you can do this with using the chat OpenAI um object that we also need to import.\nSo here we go from long chain OpenAI.\nWe are gonna import OpenAI.\nAlso please ensure that if you started this course in its early phase, then now you come to your terminal\nand just say UV sync.\nThis will ensure that OpenAI, the ancient OpenAI package, is installed.\nOkay, so now we have a chat OpenAI model that uses the ChatGPT four or mini, the temperature set to\nzero.\nThe temperature of setting the temperature to zero means that you don't want the model to be too creative,\nbut you want it to be as deterministic as it can get.\nOkay, so let's implement our function which says just hello to ChatGPT for now.\nI'm into OpenAI for now, but we'll already call this the get crypto prices.\nI just put pass in here.\nBut you don't need to do that just to ensure I don't have any error and that I can implement the main\nfunction.\nNow the main function, what it will do, it will simply call the get crypto prices function.\nAnd that's it.\nSo async IO.\nOkay.\nAnd just print the response.\nSo let's go and execute.\nAnd let's send a simple message to OpenAI.\nFor this we will need to import a core Lang chain class which is called the human message.\nSaid.\nSo this is the message that we want to send, and I will just go and copy paste the whole code here,\nwhich will be the body of our guest crypto prices function.\nSo what we are going to do here is first create the human message with the content.\nHello.\nAnd then send this message to the model and return the model's content.\nOkay.\nWe should be quite easy.\nSo let's go and try to execute our application.\nSo I'm executing my piece of software with python.py.\nAnd you see that the hello went in.\nAnd now I have a response saying hello.\nHow can I assist you today.\nAll right.\nSo this is great.\nSo our whole long chain infrastructure is working now.\nSo we are ready to implement tool calling with mic into that.",
            "dataPurpose": "item-2"
          },
          {
            "title": "52. Agentic MCP Integration with LangGraph",
            "videoUrl": "https://epam.udemy.com/assets/65239441/files/2025-05-19_13-24-40-8a6fa34c37eab7f67a9e34a2100f5f83/2/aa0031ab1ec133109ae8b8daf841b6aaad15.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC00MC04YTZmYTM0YzM3ZWFiN2Y2N2E5ZTM0YTIxMDBmNWY4My8yLyIsImV4cCI6MTc1NTc4NzY2MX0.0GR5eReWeV4zxJ779ZAgL6R8137PD6W8W4iKWk-oEvQ&provider=cloudfront&v=1",
            "transcript": "We're accessing MSPs from LinkedIn and Landgraaf.\nYou will find link Official Python library, which is called the link chain MCP adapters and it is open\nsource on GitHub.\nIf you want to find out more about this library, I'm going to add a link to the course resources about\nit where you can read a lot about it.\nI just want to point out one little thing, and that is that even when you want to work with a single\nMCP, the canonical way to go will be this so-called Multi-server MCP client.\nSo don't let this confuse you.\nEven if you work with a single MCP, we have a full multi MCP functionality.\nAll right.\nSo let's get started and implement this for us.\nSo here is our Hello World application.\nAnd I want to first of all import the MCP adapter.\nAnd then I also want to import an agentic behavior which is called the Landgraf react agent.\nThe React agent is an agent implementation pattern and react stands for reasoning and acting, and this\nis very much the whole framework of an agent, uh, reasoning about what to do, for example, what\ntools to call and then acting in accordance of what it came up with.\nSo that's react in this sense.\nFirst of all, let's configure our MCP.\nI'm pasting the same boilerplate to what you've already seen in the native implementation.\nSo right after defining our model I will just say hey I have a root folder and I have an MCP path that\nuh goes to the reference implementation Binance MCP.\nAll right.\nAnd then now I'm going to configure my MCP, the access to my MCP.\nAnd it is slightly different than what I showed you with the native implementation because Lang chain\nhas its own way to, uh, to accepting an MCP config.\nAnd it's very, very close to the JSON Agents that you added to cloud and cursor.\nSo we will say it's a Binance MCP.\nSo that's the identifier.\nThat's the name.\nThe command is Python.\nThe arguments is the actual NCP path right.\nWith the Python file itself in this case.\nAnd the transport we want to use is stdio because this is a local MCP.\nOkay.\nAnd let's pass this MCP config into an MCP client.\nSo I will come here to get crypto prices.\nAnd I will just create a vivid block where I instantiate this Multi-server MCP client with the MCP config.\nSo at this point Lang chain will know how to work with this specific MCP.\nAnd then the rest of the code comes into this block.\nRight now, the first thing I will do is to retrieve the tools for this MCP server.\nIf you remember, in the native implementation we listed the tools just because I wanted to show you\nhow to take a look at the list of the tools, but then we specify the tool itself as a explicit string\nright here.\nThe tools, like extracting the tools, is essential because now we work with a react agent, which\nmeans that we don't want to specify which tools to use and when.\nWe just want to retrieve the tools and just pass it to the agent and let the agent figure out when to\ncall, when to call a tool, and and how.\nThis is very much what cloud and cursor does.\nRight.\nSo with that I will just go and create an agent create react agent.\nI'm passing the model so the back end to it.\nAnd I'm also passing the tours.\nSo what tours it has.\nAnd I will change the message.\nNow the human message I will just say the message itself is what are the current prices of Bitcoin and\nEthereum?\nI will call this message a query because that's like very much a technical name of of sending something\nto another lamp.\nAnd then I will go and just invoke this agent.\nI don't want to invoke the, uh, the model directly anymore, because I want the agent to get done\nof all of, uh, the underlying mechanisms.\nSo I will just say take the agent and invoke it with this specific message.\nAll right.\nAnd once it's done, I just want to return with the, um, the content of the message here.\nWhat you see.\nAnd feel free to go on and just debug it to some extent, is that the response will have a message space,\nand minus one means the last message, right.\nAnd I want to extract the content of the last message here.\nAnd then of course I want to return this answer.\nSo that's very much what I want to do.\nLet's see if it works.\nSo I will just say Python Landgraf Price graph dot pi.\nAnd you see that there are some debug messages coming up like the list of requests.\nRight.\nAnd then two tourist requests like one for Bitcoin.\nWe can assume and the other one for Ethereum we can assume.\nAnd then here is the response which are the current prices of Bitcoin and Ethereum.\nSo that's great.\nIt worked.\nBut we have one problem.\nWe can't really see what went on right.\nSo like how and why did the agent decide that it needs to call these tools.\nAnd what were the actual parameters of these calls of these tools when they when they called it.\nSo debugging can be somewhat sophisticated.\nLong chain itself actually offers some debugging capabilities.\nBut there are very, very high level and well-developed debugging frameworks for long chain and line\ngraph.\nAnd this is exactly what I want to show you in the next video.",
            "dataPurpose": "item-3"
          },
          {
            "title": "53. Debugging and Tracing MCPs with LangGraph and LangSmith",
            "videoUrl": "https://epam.udemy.com/assets/65239463/files/2025-05-19_13-24-42-cde6cd4778493b63871c899d0674379f/2/aa0097f0176d15f47f3eefbaab5b946ce12c.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC00Mi1jZGU2Y2Q0Nzc4NDkzYjYzODcxYzg5OWQwNjc0Mzc5Zi8yLyIsImV4cCI6MTc1NTc4NzY2OH0.zEUZ8jeV5esrWVK2e0v9h07016_WH1OYno_WkVz9TR4&provider=cloudfront&v=1",
            "transcript": "",
            "dataPurpose": "item-4"
          }
        ]
      },
      {
        "title": "Section 11: Deploying MCPs to Production",
        "items": [
          {
            "title": "54. Introduction to Publishing and Deploying MCPs to Production",
            "videoUrl": "https://epam.udemy.com/assets/65173351/files/2025-05-16_13-41-15-409eef0ff54ebf96519efd243b15bcbc/2/aa0033882f6bd6c9b932666b054d4877ea32.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xNl8xMy00MS0xNS00MDllZWYwZmY1NGViZjk2NTE5ZWZkMjQzYjE1YmNiYy8yLyIsImV4cCI6MTc1NTc4NzY4NX0.KGpAydHpiRORuOlsptIstEPgmzegpvOG1m503jlSSzM&provider=cloudfront&v=1",
            "transcript": "Now that you have reached this point of the course, you have already learned quite a bit what MPs are\nwas the problem they solve, how you can search for and find them, download them, install them in\ndifferent tools, right?\nHow you can create your own and how to use it locally.\nBut what you probably want to do when you create your own MCP is to put them into production.\nRight?\nAnd this is where I would like to help you in the next few lectures.\nSo I will show you how you can take an MCP, that you develop and publish it on the internet so everyone\ncan have access to it and download it and and use it automatically.\nI also want to show you then what happens if you want to host your own MCP, so you don't want to provide\nit as a Python application or a JavaScript application, but you want to expose it as a service so everyone\ncan connect to it.\nAnd then later in the course, you will see how you can make more sophisticated deployments with packaging\nand deploying to cloud services.\nSo I'm very excited to show this to you, and I hope that this will be useful for you.\nSo let's see you in the next video.",
            "dataPurpose": "item-0"
          },
          {
            "title": "55. Understanding Local and Remote MCPs",
            "videoUrl": "https://epam.udemy.com/assets/65314255/files/2025-05-21_17-40-42-ab4075f15a3f4d962a51c03099ac350d/2/aa00bbe5a45c6654a660a8b2021b7befc7c8.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yMV8xNy00MC00Mi1hYjQwNzVmMTVhM2Y0ZDk2MmE1MWMwMzA5OWFjMzUwZC8yLyIsImV4cCI6MTc1NTc4NzY5M30.KKxFLeQZTIN6yevG0td1UwlVJQ3dIi6k-ZJESHgqsv8&provider=cloudfront&v=1",
            "transcript": "Let's talk a little bit MCP history.\nThere are, technically speaking, three types of MCP when it comes to the ways you can access them.\nLet's call them local, remote and global.\nFirst, what you see here on my screen is the local MCP implementation, which means that you have your\nMCP client which can be closed desktop or cursor, for example, and then your MCP server runs locally.\nIt is installed through npm or through Pip or UV or whatever.\nSo it is a local executable.\nAnd this MCP server then connects to different endpoints like the Binance endpoint that we implemented.\nRight.\nSo you can have, for example, a Python file that runs locally and accesses Binance.\nThese are the local MCC.\nBut this is kind of an old way of working with software, right?\nToday, if you want to access third party services, then in many cases you don't need to install a\nlocal component.\nJust think about any Rest APIs, like think about the Binance API for example.\nDo we need to install a Binance client to access Binance?\nOf course not.\nWhat we need to do is simply make an HTTP request and we can use the Binance service straight right\nthere.\nAll right.\nSo local M.c.p.s.\nIs how M.c.p.s.\nStarted and still today.\nThis is the way what the majority of MCP clients support.\nI mean all of them support local MCPs, but some of them don't support anything else but many of the\nM.c.p.s.\nThen moved to the internet, especially with the new protocols like SSH and HTTP.\nSo we had to come up with a solution to that.\nAnd the solution is called the MCP remote package.\nNow what you can do with the MCP remote package, and you've seen this in action is that you have a\nglobal MCP.\nLet me just call it like that.\nSo an MCP that's hosted somewhere and I don't want to install it locally, I just want to access it.\nBut in case my MCP client doesn't have the ability to access global MCP directly because this feature\nis not implemented yet, there is a way out and it is called MCP remote.\nMCP remote bridges the local installations with the global installations by installing a lightweight\nNPM package on your computer that acts as a proxy between your remote MCP server and your MCP client\nthat only wants to do local requests.\nIf you take a look at the website of MCP remote, you will see right away that it is part of their statement.\nSo they say that as soon as your chosen MCP client supports remote authorized servers, you can remove\nit.\nSo this is like a temporary solution that the world needs at the moment for accessing global or remote\nMCC.\nSo here you see a local MCP implementation.\nAnd here you see a technically still local MCP implementation because it runs a local command, but\nit bridges the traffic to a remote global MCP.\nThe new generation of MCP are definitely remote unless they want to execute actions on your local computer.\nAnd in this case, the architecture is so much simpler.\nYou simply have your MCP client like cursor, and then you have your MCP service exposed as an API endpoint\nsomewhere out on the internet.\nIt can be your server or as you will see here in this course, it can be render Comm or Cloudflare.\nAnd then these providers host your MCP server and your client communicates directly with it.\nNow there is also a few other advantages of hosting your MCP server remotely.\nAnd this is the extra functionalities you get from these platforms.\nFor example, if you run your MCP on Cloudflare, you will be able to add authentication quite easily.\nSo the main takeaway here is that the future is definitely remote, but at the moment you will see many\nnpm remote proxy and local MC, because these are 100% compatible with every MCP client out there.",
            "dataPurpose": "item-1"
          },
          {
            "title": "56. TypeScript / Javascript - based MCPs",
            "videoUrl": "https://epam.udemy.com/assets/65173365/files/2025-05-16_13-41-25-783ace5346faf99ec6539c5cdbcd5fd2/2/aa00e94dc4082d1a09d2f94b36e61f364170.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xNl8xMy00MS0yNS03ODNhY2U1MzQ2ZmFmOTllYzY1MzljNWNkYmNkNWZkMi8yLyIsImV4cCI6MTc1NTc4NzcwMH0.JwgjjmNVqQ5NgMbk5sVanIZ9dSQokwj7JphxUg9WTBk&provider=cloudfront&v=1",
            "transcript": "So here is the thing.\nI personally believe that if you implement back end applications, then Python is a better choice than\nusing TypeScript or JavaScript.\nBut this might only be a personal choice of mine, but facing reality at the moment.\nIf you want to create your MCP and you don't want to manage it yourself.\nBy which I mean I don't want to run it somewhere in the cloud or on your own server, but you want it\nuse locally, and you want to publish it in a way that other people can download it very, very easily\nby, for example, just adding a JSON line to clothes or cursors MCP file.\nThen today TypeScript and JavaScript is an easier choice.\nSo mainly for this reason, I created an equivalent TypeScript implementation of the Binance MCP that\nwe have created.\nFor those of you who prefer Python.\nYou will see later in the course how you can take our Python application and package it and send it\nto a remote deployment service and just expose it to the whole world.\nBut for now, let's focus on TypeScript so you see how you can implement the same functionality using\nTypeScript and JavaScript.\nIn this video, I'm going to go through the code itself, and in the next video we are going to do a\ndeep dive about all the Boilerplates or all the configuration files that you need to set to have a Well-working\nTypeScript implementation.\nOnly watch this video.\nI'm in the next video.\nIf you are really interested in like what goes on behind the scenes for following on the course, what\nyou see in this video will be enough.\nAll right, so let's get started.\nIf you take a look at course resources you will see a TypeScript MCP folder.\nAnd here I submitted my implementation of the Binance MCP.\nFirst of all what I would like to ask you is to open the package.json file.\nAnd once again more on that file in the next video if you're interested in the details.\nAnd for now, what I'd like to ask you is simply change the name.\nIf you see this is my name now.\nAnd this will be the name how we are gonna publish our MCP to the npm repository.\nSo the central JavaScript repository out there.\nSo this name must be unique.\nI would like to ask you to change this.\nSo if your name is Anna, then just put Anna here or something.\nThat's kind of unique okay.\nLike your GitHub username you can leave the version at one.\nBut it's important for you to take a note now that there is a version tag in this file.\nAnd this is very much what you want to do.\nAnd sure that this file is saved.\nAnd then we are ready to take a look at the actual implementation.\nThe implementation itself is here in Binance MCC.\nSo please open it.\nAnd I tried to add a bunch of commands which references the Python, the equivalent Python functionality\nof what you see here, and the JavaScript file.\nFor those of you who are not familiar with JavaScript or TypeScript.\nSo this is actually a TypeScript file with a dot ts Extension and TypeScript is a superset of JavaScript\nwhich has which adds typing and strong typing guarantees on top of JavaScript.\nSo let's just briefly go through this file, and then we will be able to go and put this into production.\nOkay.\nSo first we are importing the official module Context Protocol libraries.\nYou see I import MCC JS and studio.\nAnd then I import a typing library from JavaScript which is called Zod.\nAnd there are a bunch of standard libraries that I also want to import, because we are accessing our\nfile system through the activity log for example.\nRight.\nThen the next thing I want to do is to extract the version from the package package.json file, the\nfile that you've seen earlier.\nI want to extract the version so that I can put it on the screen when I start my MCP.\nOkay.\nI also go and define my activity log files path.\nIt's very much the same as in Python with underscore underscore dir name as the current folder instead\nof underscore underscore file underscore underscore.\nAnd then I'm ready to go and implement the actual logic of my MCP.\nNow I'm going to go and implement the get symbol from name again exactly the same logic as what we implemented\nin Python.\nSo we're simply translating Bitcoin and BTC to the symbol name.\nAnd we do the same with Ethereum.\nThen we create our server.\nThe server's name will be Binance MCP.\nAnd it will have a version which we are passing through the variable we read from package.json.\nSo the MCP server is our main class here in in JavaScript, which is very much the same as fast MCP\nin Python, right?\nAnd now if you want to create tools and resources, you don't go through annotations in JavaScript,\nbut you call the appropriate functions.\nSo for example you can say server tool.\nNow I want to define a tool.\nThe tool name should be getprice.\nIt takes a symbol.\nThe symbols type is string.\nAnd here is the actual implementation.\nThe implementation is equivalent with our Python implementation.\nSo we are getting the symbol from the name.\nAnd then we are taking the URL making a request.\nAnd if we have an error then we read out the error from the response and add the error to the activity\nfile.\nAnd also throw an error through an exception.\nAnd if there was no error, then we simply extract the JSON from the response, extract the price Add\nit to the activity log file and then return with the current price as an LM message.\nWrite.\nThe get price change very much the same, right?\nJust reading the price changes and returning them as a message.\nAnd we don't do anything with the activity log here.\nIf you want to work with resources then you go similarly through a server function call.\nSo you say server resource.\nYou define the resource URL and then you define how your resource will be read.\nSo here we are reading the activity log file just like in Python.\nAnd we are also adding another resource the crypto price symbol.\nSo resource template where we will be able to go and call the Binance API for a certain price for a\ncertain cryptocurrency, right?\nSo it's all kind of easy.\nVery much the same.\nIt's just, uh, a similar syntax, but the logic is 100% the same to Python.\nNow, if you want to start a server, then what we will do is we define a function, an async function,\njust like in Python called start server.\nWe ensure that the activity log file is present and we take an Stdio server transport which is the local\ncommunication interface of MCC.\nRight.\nAnd then we connect to our server and we just dump some debug messages to the screen.\nAnd here in in our last few lines we are actually taking this talk server and starting it.\nOkay so this is our TypeScript file.\nAnd in the next video you will see how we can compile this TypeScript and test it.",
            "dataPurpose": "item-2"
          },
          {
            "title": "57. TypeScript-based MCP Anatomy Deep Dive",
            "videoUrl": "https://epam.udemy.com/assets/65173359/files/2025-05-16_13-41-16-fbb3bc5abf0f13c044ec09c1d27be60c/2/aa008a18cacf6506c86c60a4718e8b0456e3.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xNl8xMy00MS0xNi1mYmIzYmM1YWJmMGYxM2MwNDRlYzA5YzFkMjdiZTYwYy8yLyIsImV4cCI6MTc1NTc4NzcwOH0.zc_JhsRrHNiRd4akTn9Bze6bO62BzSwAOKjFFDTM-kM&provider=cloudfront&v=1",
            "transcript": "In this video, I quickly want to go through the architecture of a TypeScript project because this is\nwhat we want to publish to the npm repository so everyone can access it through NPCs.\nSo in case you're not familiar with the whole ecosystem, this is how you build up a TypeScript project.\nWe have our root folder here TypeScript cp and we must have two JSON files.\nOne is package.json which doesn't have to do anything with TypeScript per se.\nBut if you work with node projects so JavaScript applications then you will need it.\nIt also have a TS config dot JSON, which gives directives about how to compile your TypeScript application\ninto a JavaScript application.\nYou also have an src folder with your TypeScript file that you've already seen in the previous video,\nand a dist folder for the compiled JavaScript application once the TypeScript compiler compiles it from\nTypeScript to JavaScript.\nSo this is what you will see here.\nAnd let's just get started and go through these.\nOkay.\nLet's just go with the SFC package here in the SFC package you've already seen the TypeScript.\nAnd there is also a npm ignore file.\nThis file will define that once you're ready to publish your project and package it and send it to the\nnpm registry, which are the files that shouldn't be included.\nNow remember that this will be a JavaScript project, right?\nWe only use TypeScript for development.\nSo for example, what you will see here is that we don't need anything that has to do anything with\nTypeScript.\nSo the TypeScript files or TypeScript configuration or the original TypeScript source code.\nSo this is npm ignore.\nAnd we have our source files or TypeScript source in the src folder.\nLet's see how we configure TypeScript.\nYou will see a tsconfig.json file here.\nAnd I also added a tsconfig.json file which is not a JSON file anymore because JSON doesn't support\ncommands, right?\nBut here you can take a look at what the different directives do.\nSo let me quickly go through those.\nSo again what we want to do.\nWe implement something in TypeScript and compile it to JavaScript and publish it to npm.\nSo first of all we are going to define the ECMA script version that we're going to use.\nThat's just boilerplate that you want to keep here.\nAnd also the standard libraries that we are going to use, which is here very much the same.\nWe also define the module system which is node 16.\nSo it's a modern module system.\nThink about these as boilerplate that you just need to pass in, unless you're like an advanced TypeScript\ndeveloper.\nWe also define where we want to store the TypeScript, the JavaScript files after the compilation that\nwill be here in this, our rootdir which is src.\nIf you want to do strict type checking and a few other again just boilerplate flags.\nSo for example is module interop.\nIt will make TypeScript work in a way that different modules uh systems have maximum compatibility.\nSkip lib check will ensure that TypeScript checker.\nThe type checker won't work on declaration files for example, so it will be faster than you want to\nhave consistent casing in file names.\nSo you can run this further both on windows and on Mac and across different OSes.\nAnd also just another attribute for the module resolution.\nSo the module system that you've already seen here we define where our source files reside.\nAnd we also define like what the TypeScript compiler should not care about.\nAnd one of these things is the disk library which is our which is the TypeScript compiler output.\nSo you don't need that for compilation right.\nAnd the other one is the node modules library which is a standard location for installing the JavaScript\npackages.\nThink of it as like your your local lib folder in Python after you install some pip packages.\nSo this is the TypeScript configuration.\nDon't worry too much about that.\nI just wanted to ensure that if you're interested in it, you have some instructions about what's in\nthis file.\nThe other file is the package.json, which has then more to do with the core project itself.\nNow you've already seen part of this, right?\nSo you've seen the, name.\nSo you give a name to your project this way the name.\nWhen you publish it, you also give a version to your project and show that you bump the version.\nAnytime you make a new a change and you upload it to, uh, to npm.\nI didn't have issues uploading the same versions of files to npm, or at least I haven't realized them.\nBut when I worked with GitHub as a registry, if I want to publish everything to GitHub because GitHub\nalso has, uh, node package registry, then I had problems overwriting the same version.\nSo just make sure you change this every time you republish your package.\nSo that's the version we have the description which will be shown there, uh, on the registry page\nonce you uploaded it.\nYou also have a main file.\nThis is actually optional, but if anyone else wants to take your MCP and not run it as an MCP, but\nbuild on top of it and just include your MCP in into their own project so they get access to the functionalities\nof your MCP on the code level.\nThen this is how the module system will know what files to include.\nIf you want to use this project from a third party, there is also a bin file.\nSo when we use Npx then we tell Npx like how to what to execute when we say like Npx and our project\nname.\nAnd here come a few development specific scripts like when building, just use the TypeScript compiler\nand before doing a publishing then run npm build.\nSo build the project.\nAlso you can specify some keywords for the registry.\nThe package has an offer.\nFeel free to change that.\nA license.\nSome dev dependencies and dev dependencies mean that those dependencies are not required for running\nyour NCP, but those are required for developing your MCP.\nSo here you see these are like the type definitions for TypeScript and TypeScript itself.\nThis is what we need for development.\nBut once we publish it we don't care about TypeScript anymore because then we are going to be on the\nJavaScript level.\nBut for running it we have the standard dependencies, which is the matter context protocol SDK, and\nalso the type checking library.\nZod okay.\nAnd you can also define the engine, which in our case is node version 16 or higher.\nIt's kind of defining the Python version required to run this library.\nAnd I believe this is very much it.\nSo we went through the whole folder with every JSON and configuration and source file.\nSo in the next video we are ready to go to compile test and then publish our MCP package.",
            "dataPurpose": "item-3"
          },
          {
            "title": "58. Running MCPs Locally with npx",
            "videoUrl": "https://epam.udemy.com/assets/65173349/files/2025-05-16_13-41-08-65808eb889ddcf9515f2619d161b1ece/2/aa00e41fab722a4c81ea6beb64919a0a2864.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xNl8xMy00MS0wOC02NTgwOGViODg5ZGRjZjk1MTVmMjYxOWQxNjFiMWVjZS8yLyIsImV4cCI6MTc1NTc4NzcxNX0.41AKkYJSKIL21G9uv4h1a-iD2x7Mtp-izc8zZ2lsSwA&provider=cloudfront&v=1",
            "transcript": "First of all, let us install and test out our npm project locally.\nEnsure that you are in the TypeScript MVP folder, and once you're there, simply execute npm install\nwhich will install every dependency of our project.\nIt will also execute the compilation.\nSo at this point our project will be ready to go.\nYou can go and execute NP dot to test out our project and it should come up and run okay.\nSo that was just a simple test.\nI will control see that.\nAnd now that we have a working version let us add this to cursor.\nLet's go to Cursor Settings Gaza settings.\nMCP and add new global MCP server.\nNow as you can see, mine has been already added.\nPlease point it with this piece of code that you will find in course resources to your TypeScript MCP\nfolder, and then you should be good to go.\nSo when I go back to cursor settings, you see that I have a Binance MCP here, where I can also verify\nthat it executes the command that I wanted to execute.\nAnd it has already found our two tours.\nAll right.\nSo that's great.\nSo we've been able to get started with our npm mcp locally.\nAnd in the next video I will show you how you can publish it to npm and use it from any computer in\nthe world.",
            "dataPurpose": "item-4"
          },
          {
            "title": "59. Publishing your MCP - Making it Accessible World-Wide",
            "videoUrl": "https://epam.udemy.com/assets/65173355/files/2025-05-16_13-41-15-0caff48f73ca2a8761dc800e323dcf88/2/aa00ad8b145e8a632503718e1fa0956a580c.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xNl8xMy00MS0xNS0wY2FmZjQ4ZjczY2EyYTg3NjFkYzgwMGUzMjNkY2Y4OC8yLyIsImV4cCI6MTc1NTc4NzcyM30.zmcJMw3bQjNdgmH-hCn2G2G964enn7eE8IBAwpUnI94&provider=cloudfront&v=1",
            "transcript": "So now we are ready to publish our project to npm and make it available to the whole world.\nThe first step you need to do is to go to npm js and sign up for a free account.\nThis should be fairly simple, so I'm not going to take you through these steps, but I will show you\nwhat you will see once you are logged in.\nSo now I am logged in to npm, and I would like to ask you to click your avatar and then go to packages.\nAnd in packages you will most probably see an empty list.\nOkay, now let's go back to our editor and publish our package.\nFirst, what you will need to do is to log in to your npm account.\nYou can do this by executing npm login.\nYou can click or copy the login link and then fill in a one time password.\nOnce you've filled it in and come back to your editor, you will see that MPN has been able to log in.\nThat's great.\nNow we only have one more task to do before we publish our package.\nPlease open package.json and verify that your version is at 100, and that the name of your package\nis something unique.\nI will give this name.\nZoltan Zito course by SMTP to ensure that it's fully unique.\nOnce you're done with that, you can go and say npm publish.\nPlease execute this command.\nAnd npm will go and publish your package to the registry.\nSo now if I switch back to my browser and refresh the packages page.\nI see that my package has been published.\nAmazing.\nSo let us test this out.\nLet's go to Cursor Settings.\nGo to MCP.\nAdd new global MCP server.\nAnd what we can do is now instead of using the actual file name, we can simply use our package name.\nSo I just go to packages dot JSON and copy and paste it here.\nAll right.\nSo at this point now cursor accesses our NCP in a remote way.\nBut keep in mind that it doesn't mean that NPM dot is now hosting our MCP.\nIt only hosts the package.\nSo every time you insert this through this command, the host like loader cursor will download the MCM\npackage and run it locally.\nBut still everyone in the world will be able to use your package.\nNow let me go back to cursor settings and now you will see that the MCP is coming from the central npm\njs repository and it is working.\nSo we have gotten to a stage where you are able to implement your own MCC and publish it to npm js,\nand thus make it available to the whole world.\nCongrats.",
            "dataPurpose": "item-5"
          },
          {
            "title": "60. Production-ready MCP Transports: Streamable HTTP and SSE",
            "videoUrl": "https://epam.udemy.com/assets/65173353/files/2025-05-16_13-41-15-55d453d302049e20ded81c90137325b6/2/aa002e850e556cf2bd2d095b618560ad5bce.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xNl8xMy00MS0xNS01NWQ0NTNkMzAyMDQ5ZTIwZGVkODFjOTAxMzczMjViNi8yLyIsImV4cCI6MTc1NTc4NzczMH0.xt4uVGUV50Am7qR2f3nvFV39P23V2xin8pWmnE0JEXQ&provider=cloudfront&v=1",
            "transcript": "In this video, I would like to discuss a little bit about MC transport layer and the different transport\ntypes.\nSo far we've used a single transport type which is Stdio, but there is actually another one.\nWell, at the moment there are actually two other transport types, and I would like to just paint a\npicture about which one does what and which is kind of deprecated already and which is the one to use.\nSo let's start with, uh, with the two that are current at the time of recording, which is May 2025\nat the moment, the MCP.\nThe MCP documentation suggests that you either use Stdio for local MC, and those are the MC that we\nimplemented so far, or you use another one which is called Streamable HTTP, which is kind of new.\nSo it's been out there for for a few weeks.\nNow let's talk a little bit about studio.\nThe studio transport.\nIt's fairly simple.\nWhat it does is that it makes the client and the server processor your MCP, communicate through the\nstandard I o channels.\nIn case you're not familiar with standard I o, there is an stdin that you can see here, which is kind\nof the keyboard input for a software.\nAnd there is an stdout which is the the standard output.\nSo when you say print things come up at stdout.\nThere is also another channel called the stderr which is standard error for logging and error reporting.\nNow the stdio transport it exactly does that your client connects to the server, and it just sends\nall the messages through stdin and reads out the responses through stdout.\nThat's very, very comfy and, you know, like better tested big time because they are like the most\nbasic communication channels and, uh, computer systems.\nBut there is a drawback.\nAnd the drawback is that it only works on a local computer.\nRight.\nAnd so far, this hasn't been a problem for us because we implemented our own MCC that run on our computer,\neven when we implemented our NPM based MCP that we published there.\nWhen we executed that MCP, then cursor downloaded that MCP and interacted with it locally.\nSo Stdio worked very, very well there.\nBut if you want to deploy your MCP to a remote server and expose an endpoint.\nSo any MCP host, let's say cloud can reach out to that endpoint and work with them directly without\ndownloading the MCP code, then Stdio won't cut it.\nAnd this is why we have the Streamable HTTP protocol here.\nI don't want to explain too much at this point about the Streamable HTTP protocol.\nIt's a quite complex protocol, but what matters for us is that it works through HTTP, right?\nSo we can connect to a remote server and then communicate with the remote server.\nSo HTTP is a protocol you want to use for production applications.\nAnd this whole transport layer of MCP is moving very very fast.\nSo just a few weeks back we didn't have HTTP.\nBut the protocol that we had for this remote connection, it was the server sent events, which is SS.\nNow SE is already obsolete in the MCP protocol, but funny enough, at the moment most of the MCP hosts\nlike cloud.\nAt least if you are on the cloud, basic or or plus plan, they only support Stdio or SE.\nThey won't support streamable http.\nNow most probably if you see this video in 2025, June or later, then support will have been added\nalready.\nSo there is this interesting situation in the world that SE is deprecated, but this is what we have\nto use now.\nBy the way, streaming with HTTP behind the scenes can also uses parts of ZK, so it's not going anywhere,\nbut it's just kind of upgraded into a new protocol.\nAlso, if I take a look at the fast MCP library, so the official fast MCP library, the links for which\nyou will see in the course resources, you will see how everything, uh, happens now.\nSo SSA is still here, and it says that's like a compatibility layer.\nSo what I want to remember without over explaining this is that if you run a local MCP, Stdio will\ncut it.\nIf you run a remote MCP, then probably by the time you're watching this video, Streamable HTTP will\ncut it.\nIf you are in 2025, June or later, but at the moment we must use SSC and HSC is here to stay for a\nwhile, so compatibility will be maintained for a while.\nSo it's a safe choice.\nSo in the next video I will show you how you can take your Python MCP implementation, convert it into\nan SSC based application, and then later you will see in the course how we can deploy it to a managed\nservice to make a full featured remote MCP.\nI'll see you there.",
            "dataPurpose": "item-6"
          },
          {
            "title": "61. Adding Streamable HTTP and SSE functionalities to our MCP",
            "videoUrl": "https://epam.udemy.com/assets/65173357/files/2025-05-16_13-41-16-4402cfa45fc76781b1f03208b8adbde9/2/aa009fa5f0aedd8b22d2da8070552b7aafbe.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xNl8xMy00MS0xNi00NDAyY2ZhNDVmYzc2NzgxYjFmMDMyMDhiOGFkYmRlOS8yLyIsImV4cCI6MTc1NTc4NzczOH0.yPuRunAZT84aQTPrO7mtJJfQr9j0RxGNFcuaSugdC_k&provider=cloudfront&v=1",
            "transcript": "In this video, we are going to change our Binance MCP Python project so that it's ready to be deployed\nand put into production.\nIn order to achieve this, we must create a separate repository which I have created for you.\nSo feel free to come to Nordegren slash Binance MCP and clone this repository into your Visual Studio\nCode.\nOnce you've cloned this, you will see two relevant files.\nOne is the requirements.txt.\nWe are not going to use UV here, but we are going to use instead of UV, the standard Python virtualenv.\nAnd here are our dependencies.\nWe want to install the MCP library.\nAnd we also want to install the request library to make a request to Binance.\nRight.\nSo that's it.\nIt goes through the standard requirements.txt.\nLet us create a virtualenv and activate it and install the dependencies.\nThis is something that you are most probably able to do by yourself, but I will guide you through that\nreal quick so I can say Python minus m venv venv which will create a virtualenv for me.\nNow you see the VM folder popping up.\nPlease go and activate it depending on your platform, windows or Linux.\nI have a shorthand for it called a.\nSo now my virtual env is activated and all I need to do is to install the requirements, right?\nThere we go.\nOnce the requirements are installed, let's take a look at the changes we have to make in our Binance\nMCP.\nThere will be only a few.\nIf you take a look at the top of the file, you see that.\nNow in the first MCP constructor we are adding a port.\nSo now we want our MCP not to communicate through Stdio, but to listen on a port.\nI just gave this a random number, which is like high and unique enough that it will probably work on\nyour computer too.\nSo this port should not be taken by any other process.\nBut in case you execute these Binance MCP Pi and you see an address already used error, feel free to\njust switch it to anything else and the rest of the course will work just as well with the new settings.\nOkay, so here is mine.\nAnd the other change we need to do is that we have to tell MCP to listen not on Stdio, but on SSE or\nStreamable http.\nNow in the example you will see SSE, because that's the protocol that's widely adopted today for remote\ncommunication.\nBut for the demo Temporarily, I will switch to streaming HTTP because that's the more modern protocol.\nOkay, so please uncomment this.\nYou see a comment and uncomment enable HTTP.\nAnd at this point I should be able to execute my Python mcpe server.\nSo I will just say python minus app.py and it should be up and running.\nWonderful.\nNow what we want to do is to ensure that it runs well.\nSo let us just open the MCP inspector and inspect this MCP.\nIn order to do that I will create a new terminal.\nAnd in this terminal, execute the MCP inspector.\nIt is now listening on port 6274.\nOnce I open it, I will be able to connect to my MCP.\nSelect Streamable http as the transport type, and for the URL, just select the localhost, the port\nyou have in your Python file and then MCP.\nAnd once you're done, click connect.\nAll right it has connected.\nThat's good news.\nIf I go to tours and click List tours you will see that my tours are here.\nOkay so our MCP is functional.\nJust as a last step, let me go and change it back to SE because this is what we will need to use in\norder to make it compatible with the MCP hosts.\nSo you want to have SE here and it doesn't matter what what you have up there.\nAll right.\nVery good.\nSo in the next video I will show you how you can take now this MCP and deploy it to production on the\ninternet.",
            "dataPurpose": "item-7"
          },
          {
            "title": "62. Deploying MCPs to Production with render.com",
            "videoUrl": "https://epam.udemy.com/assets/65173363/files/2025-05-16_13-41-17-82dfd41257ddc48240bf0fd96a0e5be7/2/aa00bae620d975ab1f77a505e2999e747155.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xNl8xMy00MS0xNy04MmRmZDQxMjU3ZGRjNDgyNDBiZjBmZDk2YTBlNWJlNy8yLyIsImV4cCI6MTc1NTc4Nzc0Nn0.4r5mY8VuuDSGexUYGfCC4RTDqx_-7mQQa9aVyskBUo0&provider=cloudfront&v=1",
            "transcript": "In this video, we are going to deploy our MCP server to production on the internet with the help of\nthe service called Render Comm.\nThis way we won't need to use Python or NPM or any other libraries or software packages to access them.\nBut we will send it to a managed production service which will expose an endpoint, just as you've seen\nin the previous video, but now out on the internet.\nAnd we will be able to connect straight to that service.\nWe are going to use render comm for that.\nI personally love rendered comm.\nIt's a super easy to use service for deploying git repositories.\nI mean web services that you develop in git repositories or Docker images and render takes care of the\nwhole maintenance and execution and logging and everything of your service.\nThis.\nSo I would like to ask you to come and sign up for render so you can click Get Started and you can,\nfor example, very easily sign up with your GitHub account or as you wish.\nAnd once you signed up and logged in you will see an overview dashboard.\nI would like to ask you to keep the Binance MCP repositories URL handy.\nAnd then in your render dashboard, click Create Deploy Web Service and then click Public Git Repository.\nHere what you can do is you can basically if you connect your git with render, let me just show this\nto you as I did.\nThen you can also pick any of the, uh, private packages that you have, the private repositories,\nor you can use a public git repository or you can use an existing Docker image from a Docker image registry.\nWe are going to use the public git repository.\nSo I would like to ask you to simply paste the Binance MCC repository URL here, and then click connect.\nOnce this has been connected, you can fill in a few properties, for example a name and Binance.\nMcpp is actually good, but let me just add the prefix for me because it must be unique and then add\nthis to a project.\nSo let's just create a project for it.\nI will create a project called MCP course.\nThe environment name is production.\nThat's okay.\nIt doesn't concern us.\nThe language is Python three.\nThat's great.\nWe want to take the main branch.\nI will just go on and pick a European region.\nI can also specify a root folder where my Python files are, but I can just leave this empty because\nmy files are in the root folder themselves.\nI can also specify how to install the requirements file.\nThe defaults are great, right?\nSo when I deploy this service, I want the packages defined in requirements.txt to be installed.\nAnd I also need a start command.\nAnd my start command is fairly simple.\nI will just say Python, Binance and cp py because I have Binance app.py file here that I want to execute\nright?\nEnsure that you click the free plan.\nAnd for the environment variable, what we can do is to set the Python version.\nSo I can say like the Python version should be 3.11.11.\nBut actually if you leave this empty, that should work exactly.\nWell then you can click Deploy Web service.\nAnd that was it.\nNow the deployment has been kicked off and it might take a minute or two to get your service deployed.\nPlease just hang on and give it a minute until this finishes.\nIf you see a 404 not found error along the way, just don't worry about that.\nRender will figure out how to fix that.\nOnce you see the message your service is live, you're good to go.\nPlease scroll up to the top of the page and copy your public URL.\nThis is the URL through which you and everyone will be able to access this MCP.\nLet me just show you what you will find under this URL.\nSo I'll just paste it here.\nYou will see a not found response which is completely okay, because if you want to access an MCP that\nuses the SSH protocol, then You must add ssh.\nSo please add ssh.\nAnd now you see that this is an endpoint event.\nAnd the data is this and that.\nThat's all good.\nIt means that your MCP is out there and functional.\nLet's take a look at connect to it first from an MCP inspector.\nLet's get back to our terminal and execute the MCP inspector.\nFor the transport type select SSH and for the URL, paste your URL with the Https prefix.\nAnd don't forget to add slash ssh and then click connect.\nThe MCP inspector has connected.\nGreat.\nIf I go to tours and I see list tours I have my tours list here.\nSo that's good.\nIt means that our MCP is now out on the internet, and we can just connect to it through this global\nMCP URL and use it right away.\nAs a last step, let's add this URL to cursor.\nI'm going to go to Cursor Settings MCP add new global MCP server, and let's just add a new MCP server.\nI will call it Binance MCP.\nAnd now I don't need to use a command anymore.\nI just want to use a URL.\nSo I don't want to install anything to my computer.\nI just go to my render endpoint slash ssh.\nLet me save this and go back to Cursor Settings.\nEnable this again and you can see that it's green and it works well.\nThe tools are there.\nSo congrats.\nNow what you have done.\nYou created your own MCP and you published it on the internet so everyone can access it without installing\nany additional packages.",
            "dataPurpose": "item-8"
          }
        ]
      },
      {
        "title": "Section 12: MCP Security in Production - OAuth with Cloudflare Workers",
        "items": [
          {
            "title": "63. Section Introduction and Goals",
            "videoUrl": "https://epam.udemy.com/assets/65314241/files/2025-05-21_17-40-33-41c968a3c737ecab0498e298c0feedd4/2/aa00db91c666255ac32bc13b06a7460ee203.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yMV8xNy00MC0zMy00MWM5NjhhM2M3MzdlY2FiMDQ5OGUyOThjMGZlZWRkNC8yLyIsImV4cCI6MTc1NTc4Nzc1OH0.KgplpWbYbImiaKVqBrifKEVxZf-nbnZbdyGMP4LXYek&provider=cloudfront&v=1",
            "transcript": "In this section of the course, I would like to show you how you can create a production ready MCP and\ndeploy it on Cloudflare's infrastructure.\nCloudflare is one of the major infrastructure providers out there.\nI am personally a fan.\nI use Cloudflare for most of my projects where domains or infrastructure in general comes into play,\nand now you will see how you can create an MCP and simply just deploy it and expose it as a Cloudflare\nendpoint.\nBut the main point that I'd like to make in this section is the security issues that come with M.c.p.s.\nSo I'm going to show you how you can add an extra security layer on top of your MCP application, and\nthat will be an O based authentication.\nWe are going to take a GitHub, and we will require our users to sign in to GitHub and only then access\nour M.c.p.s.\nYou will see that this will be kind of a complex topic, and I'm doing my best to decompose this for\nyou into small, understandable pieces so that at the end of this section you can walk away a fully\nworking, robust, scalable and secure MCP server.\nLet's go.",
            "dataPurpose": "item-0"
          },
          {
            "title": "64. Setting Up Your Free Cloudflare Account",
            "videoUrl": "https://epam.udemy.com/assets/65314239/files/2025-05-21_17-40-27-e753049648267de0817befdf7f6594a2/2/aa008815b22624eda39b587ae4a887a50556.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yMV8xNy00MC0yNy1lNzUzMDQ5NjQ4MjY3ZGUwODE3YmVmZGY3ZjY1OTRhMi8yLyIsImV4cCI6MTc1NTc4Nzc2NX0.G_qy41bc4xe3IT7nXotQsjG6ot0smi1v5OVTc0ngU08&provider=cloudfront&v=1",
            "transcript": "Let's sign up on Cloudflare.\nLet's go to Cloudflare.\nCom.\nClick sign up.\nAnd here in the free plan you can say add a website.\nAnd then a very standard sign up process begins.\nPlease go through it.\nAnd once you're in you don't need to set up a domain.\nYou can just click the Cloudflare logo and it will take you to your dashboard.\nThat's pretty much it.",
            "dataPurpose": "item-1"
          },
          {
            "title": "65. Creating Cloudflare-Based Remote MCPs",
            "videoUrl": "https://epam.udemy.com/assets/65314245/files/2025-05-21_17-40-36-1cf7076d74f8afadec9101543cde9cb5/2/aa00504cd695ef83c73dacf42aa3fcab3fa8.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yMV8xNy00MC0zNi0xY2Y3MDc2ZDc0ZjhhZmFkZWM5MTAxNTQzY2RlOWNiNS8yLyIsImV4cCI6MTc1NTc4Nzc3M30.HTI3UZNbfgGI1ZfTE_pufg7jj_-ZhiS8Bn0r7Xp99vg&provider=cloudfront&v=1",
            "transcript": "As a first step, we are going to create a Cloudflare compatible SMTP server and deploy it locally so\nwe can inspect it with the MCP inspector.\nPlease come to Visual Studio Code and just open the course folder.\nDon't be bothered by that Cloudflare string here.\nIt is just the git branch that I use at the moment.\nYou probably will see something else here.\nAnd let's create a new folder.\nAnd we are going to start from Cloudflare MCP template.\nSo this is what we are going to do.\nWe tell npm to create a new folder called my Cloudflare MCP server public.\nAnd we also tell npm to use the template from the Cloudflare official repo.\nOkay.\nYou might need to install the package.\nIt might take a minute until this finishes.\nIt will also ask if you want to use git for version control.\nNow you might want to say yes.\nAnd also it asks if you want to deploy your application.\nFor now, let's say no.\nOnce you're done, you will see that you have a new folder, which is the my Cloudforms server public\nin src.\nYou will see an index.ts and if you take a look, this will be very, very similar to what we have already\nused.\nIt uses a library called agent.\nAnd agent is a library by Cloudflare right.\nSo this is Cloudflare agent and MCP library.\nIt uses the official model context protocol library and Zod for type checking.\nAnd the only significant difference between your previous JavaScript based implementation.\nAnd what you will see here is that now our services are wrapped into these MCP agent based class called\nmy MCP.\nLet me make this bigger for you.\nAs you will see, the example application defines two tools in its init function.\nOne is add for adding two numbers and the other one is calculate which introduces a bunch of operations.\nNow I would suggest that we keep add.\nSo we have something very, very simple.\nBut we go and get rid of the calculate function and replace it with our crypto price function.\nAll right.\nSo I can just go to my TypeScript Mcps-prs Binance MCP file which you're already familiar with and just\ncopy whatever I need from that.\nSo I will take the get symbol from name and just copy it here as a plain function.\nAnd then I will also go back and take the get price function.\nLet's just stick with the get price function.\nSo we don't need anything else.\nFor the demonstration I'm going to paste the implementation here, and all I need to do is to say that\nthis is now actually a disservice tool because we are inside a class.\nAnd also I just go and remove the activity log file related records.\nJust a bit of formatting and I'm ready to go.\nSo let's try if this works.\nOf course you will find the reference solution in the course materials.\nI will CD into my class for MCP server public and say npm start.\nAll right this is running on localhost so that's great.\nLet me just open a new terminal and start the MCP inspector.\nLet's open it and let's connect to our MCP server.\nNow the question is which protocol to use.\nRight.\nAnd let me just revisit the source code of the SMTP server.\nIf you scroll to the bottom, you will see that actually Cloudflare template implementation.\nIt supports both the SSH endpoint and also the Streamable HTTP endpoint.\nSo I can just go with the more modern solution, the string http.\nLet me come back to my terminal and copy the link and paste it into the MCP inspector and add the MCP\npostfix and click connect.\nAll right this is now connected.\nThat's great.\nI click this to us and I have add and get price.\nLet's see if it works.\nOkay.\nThat's working well.\nAmazing.\nSo now we are ready to deploy this into production on Cloudflare.\nAnd that's what we are going to do in our next video.",
            "dataPurpose": "item-2"
          },
          {
            "title": "66. Deploying MCPs to Cloudflare Workers",
            "videoUrl": "https://epam.udemy.com/assets/65314257/files/2025-05-21_17-40-42-8b74e55c3603fbb667b4262a12a357d1/2/aa0002242ad4f7c2c6c7b201108eb55eba40.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yMV8xNy00MC00Mi04Yjc0ZTU1YzM2MDNmYmI2NjdiNDI2MmExMmEzNTdkMS8yLyIsImV4cCI6MTc1NTc4Nzc4MH0.SwzfxUaqcaysdd3Tuo1qZQnIZAVsBWYDsfcxH7szoN0&provider=cloudfront&v=1",
            "transcript": "All right, let's go and put this to production.\nI just want to do two changes before we deploy this to Cloudflare.\nFirst of all, you can just go in and change the name.\nI can say like crypto price MCP for example.\nSo that's one.\nAnd there is another one which is a very important change.\nAnd that is to come to the URL and replace the URL with this specific string.\nSo that's something that I provide you with in the course resources.\nAnd here is the thing.\nFor some reason Binance blacklists Cloudflare IP range, most probably because there were some abuses\nof Binance from Cloudflare infrastructure.\nSo we won't be able to access the real time crypto data from Cloudflare Network.\nSo what we can do as a workaround is that I created a hardcoded price JSON for you.\nThat I host for you publicly.\nLet's take a look.\nIf you open it in a browser, you will see that it's a JSON value which says it's a 100,000 USD.\nAnd there is also a warning that this is just for instructional purposes.\nOkay.\nSo please do this change.\nAnd that's very much it.\nSo now we are ready to deploy.\nFirst of all let's log in to Cloudflare.\nLet's execute npm Wrangler login which will open a browser window and take you to your login page.\nOr if you're logged in, it might take you straight to the authorization page.\nClick allow and come back to your VSCode.\nAll right, we are logged in.\nThat's great.\nBefore we can do a deployment, we need to come back to Cloudflare and simply open the workers menu.\nYou will see compute workers and just click workers and pages.\nWorkers are the serverless components that will run your MPC.\nAnd before you can get started with deploying an MCP, you must come here and just open it for the first\ntime.\nSo this is like a one off action.\nOkay.\nAnd now we are ready to go back to our VS code and simply execute npm Wrangler deploy.\nAnd now the Cloudflare Wrangler utility will go on and deploy your MPC and host it publicly.\nYou see here is my URL.\nSo that should work well.\nSo let's see if it works.\nI can just come back to my MPC inspector in case you stubbed it.\nPlease re-execute it.\nIf you remember, we are supporting both protocols, so let's just go with http.\nPaste your URL and then add the endpoint and click connect.\nAll right.\nNow we are connected to our public Cloudflare endpoint.\nAnd I can list the tools and say get price and just add the symbol run tool.\nAnd here is the two result right.\nThis is the instruction on how to hardcoded value.\nSo that works very very well.\nAnd in the next sections you will see how we can turn this into an authenticated solution which restricts\nunauthorized access.",
            "dataPurpose": "item-3"
          },
          {
            "title": "67. OAuth and MCP Security: A Comprehensive Introduction",
            "videoUrl": "https://epam.udemy.com/assets/65314243/files/2025-05-21_17-40-35-31ca82fb65bcbb593fa70767ea139679/2/aa00862531d060bbcf1c70751bb97b6c9157.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yMV8xNy00MC0zNS0zMWNhODJmYjY1YmNiYjU5M2ZhNzA3NjdlYTEzOTY3OS8yLyIsImV4cCI6MTc1NTc4Nzc4OH0.JXWaPri5Nnjbxs9uSHiWzzY_jCvJy7jBJgrCHUJqeOU&provider=cloudfront&v=1",
            "transcript": "Have you ever used your Gmail account to sign in to somewhere or your GitHub account?\nIn case you did, then you used a so-called OAuth authentication.\nSo this authentication many times is also called an SSO means that you have a certain authorization\nprovider like Google, and you want to use Google to authenticate you to another application.\nNow I'll be frank with you.\nOAuth is super complex, and I think you are best off if you try to get your hands away from OAuth.\nNow let's take a look at how it is implemented in Google.\nFor example, here's the documentation.\nIf you just go through like what needs to be done just to, you know, set up everything to have a Google\nauthentication, that's already kind of cumbersome.\nIf you want to implement OAuth for your own use case, I would suggest you to go either with the OAuth\ntwo authorization framework of Auth0, or you can also try the Supabase OAuth, which is super simple.\nLet me give you a quick overview about how OAuth works without the unnecessary details.\nHere are the rules.\nThere is a user which is you and you interact with a client application.\nLet's say your browser and you want to access a so-called resource server.\nSo this is a place where you want to log in.\nFor example, you can use Google to log in to StackOverflow.\nSo the resource server can be StackOverflow because these are the resources that you want to access.\nAnd in this case the authorization server would be Google.\nRight.\nSo you the user, your browser, a resource server like StackOverflow and an authorization server like\nGoogle.\nSo these are the rules.\nLet's take a look at the use case.\nWe are going to implement here.\nWhat we want to do is that we will have our MCP server.\nAnd we want to protect it by authorization.\nIn order to do that, we are going to set up a GitHub based authorization.\nSo you will be able to use your GitHub credentials to access our MCP server.\nYou will initiate the authorization from cloud which will then communicate with your MCP client.\nSo the built in MCP client that accesses your MCP server.\nAnd once it has authenticated it will be able to access it.\nLet me guide you through the flow of this.\nIn cloud you will have our MCP server to the config.\nThen you will try to use it through the MCP client.\nThe MCP client will We say sorry.\nComputer says no.\nYou won't be able to use this service unless you're authenticated.\nSo it tells code to open an authentication flow.\nAnd it also disclosed that it wants to authenticate with GitHub.\nThen cloud will send an authenticate request to GitHub, which you will see as the GitHub web page popping\nup.\nAnd you will be able to log in and grant certain rights to cloud, like retrieving your username and\nemail.\nRight.\nOnce this is done and there is an authentication success, GitHub will send a temporary authentication\ncode back to the client, and the client will pass this temporary authentication code to the server.\nNow what's important for you to understand that you will see that in action, is that the MCP server\nis already authenticated to GitHub as a server, as like a general server, not as your user, but just\nlike as a service provider.\nSo the server will be able to tell GitHub that, hey, I have this authentication code and you already\nknow me, so can you just give me an access token that I will be able to use for subsequent communication?\nGitHub will do that.\nIt will provide the server with an access token and also a refresh token and many other things going\non behind the scenes.\nBut what matter for us is that at this point, our server is authenticated with our user on GitHub,\nso it can ensure that when your MCP client communicates with it, then it's actually you who executes\nthe command and makes the request.\nLet us take a look at a more elaborate example.\nSo here is what we are going to implement.\nThe good news is that Cloudflare will do most of this work.\nSo we will use a cloud to access our SMTP server, which is deployed on Cloudflare.\nAnd now it's deployed in a way that Cloudflare has kind of an authentication shield around it that uses\nGitHub authentication.\nSo the flow will go something like this.\nCloud will try to use the NCP client.\nThe NCP client will try to use the NCP server, the NCP server.\nSo our Binance server tells the NCP client, oh, sorry, you need to authenticate through GitHub.\nThen the NCP client will tell cloud that.\nCan you just start an authentication with GitHub.\nSo cloud will open the GitHub website.\nYou will do the authentication.\nYou will log in and authorize cloud to access your GitHub identity.\nAnd then GitHub will pass a temporary code back which will be then passed to the server.\nAnd then using this code and also the secrets.\nThe MCP server will be able to finish the authentication.\nNow the secrets here are a shared secret between GitHub and the MCP server.\nAnd this is how the MCP server can authenticate itself to GitHub.\nYou will see this in action.\nSo once the code and the secrets are sent to GitHub, GitHub will be able to identify the user.\nAnd then the MCP server will be able to tell the MCP client that okay, good.\nThe user has authenticated through GitHub and we are ready to go.\nAnd from this point on, it's just a very, very standard service call.\nAnd behind the scenes are MCP server.\nAnd GitHub will keep managing the authentication session with all of its complexities of managing the\naccess token and refreshing the tokens and everything that comes with session management.\nSo let's see how this works in action.",
            "dataPurpose": "item-4"
          },
          {
            "title": "68. Creating a GitHub OAuth App and Cloudflare Pages Secrets",
            "videoUrl": "https://epam.udemy.com/assets/65314247/files/2025-05-21_17-40-36-d3e85f77fb4e66019852b0751e068ce3/2/aa004fbb3fd3f0cee7984dc14deba7c0c54b.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yMV8xNy00MC0zNi1kM2U4NWY3N2ZiNGU2NjAxOTg1MmIwNzUxZTA2OGNlMy8yLyIsImV4cCI6MTc1NTc4Nzc5NX0.yrPBeeBlEuTLTV-lnd-F1u5WrxUEDOysogVVW19h2Vs&provider=cloudfront&v=1",
            "transcript": "Let's set up a new Cloudflare MCP project that supports authentication.\nYou want to create a new project and I call it my Cloudflare MCP Server Secure.\nAnd now we are changing the template.\nThe template is now from the I demos the remote MCP GitHub OAuth.\nLet me execute this first and then we can discuss what we did here.\nSo it's gonna install dependencies and clone the repo from the GitHub OAuth I demo.\nWe can say yes, we want to use git for version control and we don't want to deploy our application\nyet.\nNow let's take a look at what happened.\nLet me go to the I demo template repo.\nHere you will see that on GitHub.\nCloudflare has an I demos Moles.\nFurther, you will find this in the course resources and it has many templates.\nOne of the templates we use is remote MCP right.\nAnd now we are using the remote MCP GitHub.\nWant to take a deeper look?\nFeel free to read the readme file in this repo and it will explain you how it works behind the scenes.\nYou will also find a bunch of other authentication like authenticating with Google or authenticating\nwith Auth0.\nYou will also find a slack OAuth, but I found that creating an application that authenticates with\nGitHub is the easiest.\nSo this is what we are going to do.\nLet's open our GitHub settings and create a new OAuth app.\nClick settings in settings, scroll to the bottom and click Developer Settings.\nIn developer settings, go to OAuth apps and click new OAuth app.\nAt this point, we are creating an OAuth app for our MCP server, and we will also generate a shared\nsecret through which our MCP server will be able to use GitHub for authentication.\nThe application name can be Binance MCP.\nFor the home page URL you can just use localhost for now.\nWe will fix this later.\nAnd also the callback URL.\nYou can use localhost and then you can click Register application.\nOur OAuth app has been created.\nPlease copy the client ID and save it to somewhere.\nAnd also come back and generate a new client Clientsecret.\nCopy the secret and save it somewhere.\nAll right.\nNow I OAuth application has been configured and we are ready to integrate these OAuth credentials into\nour MCP server.\nCome back to VS code and step into your MCP folder.\nAnd let's pass the client ID and the secret to this worker.\nPlease execute Mpfs Wrangler secret output.\nAnd first the GitHub client ID and just copy your client ID's value.\nIf it asks if you want to create a new worker, click yes and it will create a new worker for you.\nAnd now let's do the same with the client secret.\nSo just say NP Wrangler secret.\nPut GitHub client secret.\nTake your GitHub secret.\nThere is a third secret I want you to add.\nAnd this is the so-called cookie encryption key.\nThat can be any random value.\nSo please execute NP Wrangler secret cookie encryption key and just, you know, just go crazy on the\nkeyboard and press enter.\nAnd now a cookie encryption key has been updated to.\nSo that's important on how OAuth encrypts your cookies.\nNow the last thing I would like you to do is to open the Wrangler JSON file.\nAnd here you will see a bunch of preset variables the GitHub client ID, the client secret, and the\nencryption key.\nPlease just delete these and just have an empty array.\nThat's actually might not be necessary, but I just want to be on the safe side ensuring that is the\nsecret that gonna be picked up and not some dummy values from wars.",
            "dataPurpose": "item-5"
          },
          {
            "title": "69. Deploying a Secure MCP on Cloudflare Workers",
            "videoUrl": "https://epam.udemy.com/assets/65314249/files/2025-05-21_17-40-39-552fcfbc9a029aa737b8be0305f2eb9d/2/aa00b198e0777700c9248ab339901d5fbf47.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yMV8xNy00MC0zOS01NTJmY2ZiYzlhMDI5YWE3MzdiOGJlMDMwNWYyZWI5ZC8yLyIsImV4cCI6MTc1NTc4NzgwM30.5rjnTuuPt-9Kc2jVVDxLYbu969gy8eMdq0SzoArO5cM&provider=cloudfront&v=1",
            "transcript": "Let's prepare our MCP for production use.\nFirst of all, what we need for an authenticated application on Cloudflare is to create a so-called\nkey value store in it.\nA key value store is Cloudflare, built in service, where you can register keys and values.\nRight?\nAnd in our case, Cloudflare is going to use this key value store for storing internal data about authentication.\nLet's create a new CVE by executing npm Wrangler cve namespace.\nCreate OAuth.\nSo OAuth CVE will be the name.\nAnd you will see that you receive an ID and it is important.\nPlease keep this ID and also open the Wrangler dot JSON file is the same file where you remove the variables\nand move to the part which says Durable Objects bindings.\nAnd then here.\nCDB namespaces.\nAnd you will see an OAuth KB binding.\nAnd let's just add this ID to that.\nWith this step we are now connecting our MCP to this kV to this key value store.\nSo our MCP will be able to store keys and values in a durable way.\nDurability here means that even if our worker goes shut down, the actual information will remain on\ncloud infrastructure.\nAll right.\nThat's great.\nSo we only need one more thing to do before we deploy this application.\nAnd that is updating our index dot file.\nOur index file is very much the same file as what you've seen with our public application.\nBut it has some extra features like authentication with GitHub.\nRight.\nSo for example, if you take a look that we still have an MCP agent, the name of which you can change.\nSo I can say this is a Binance or MCP.\nAnd then it has the init function with the add and also a new tool which is the user info Octokit which\ngets the user information from GitHub.\nOnce you're authenticated, let's ensure that it can also reach out to Binance.\nSo I would like to ask you to open your public MCP servers TS file and just copy and paste the Binance\nrelated tool here.\nHere is mine.\nSo I take get symbol from name.\nJust paste it up there.\nAnd then I'm also taking the get price function right as the last function.\nAll right.\nThat should cut it.\nAnd let's go and deploy our app.\nI can simply execute npm Wrangler deploy just in the earlier videos.\nAnd Wrangler is going to deploy our app to Cloudflare.\nNow I know the hostname of my MCP.\nSo let's copy that.\nFirst of all, let's try to access it from a browser.\nYou will see are not found which is okay.\nIf I add dot ssh then I will see an invalid token error, which is again great because it means that\nI would need to authenticate to access this resource.\nNow we are ready to add data or OAuth application on GitHub.\nSo once again please copy the URL and go to your GitHub OAuth application page.\nAnd now we will be good to change the homepage URL.\nJust simply copy the URL, the deployment URL here, and also the callback URL.\nAnd the callback URL is the same URL, but you add callback, then click update application.\nAnd we are good to go to integrate our application now into cloud.",
            "dataPurpose": "item-6"
          },
          {
            "title": "70. Accssing OAuth-Protected MCPs from Claude",
            "videoUrl": "https://epam.udemy.com/assets/65314253/files/2025-05-21_17-40-39-c4e0016b9f8b01ece912a31f8e6bf369/2/aa0095b51e276c0e1af6daa0a8adae303399.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yMV8xNy00MC0zOS1jNGUwMDE2YjlmOGIwMWVjZTkxMmEzMWY4ZTZiZjM2OS8yLyIsImV4cCI6MTc1NTc4NzgxMX0.VyhncpODSHCwGXY8Xa1bmT1xEChY651ZrQF_d257IpA&provider=cloudfront&v=1",
            "transcript": "In cloud.\nWe're going to go through the usual steps so we can go to Settings Developer Edit config.\nAnd here just add an Mctp remote to our endpoint.\nSo this will be I call this crypto price.\nThe command will be npm.\nWe are using an Mctp remote and we are connecting to your URL.\nYour account name.workers.dev slash.\nOkay, let's save this and restart cloud.\nYou will see right away that cloud tries to authenticate the Binance MCP.\nI will authorize this.\nAnd then it says authorization successful.\nYou may close this window.\nSo let me just close this window and go back to cloud.\nNow what you might find is that the tool is not showing up yet.\nIn this case, please go and restart cloud again.\nAnd here we go.\nOur three tools have popped up.\nSo I can ask for Are the current price of Bitcoin, for example.\nA tool called is made and then we get back with the instructional result.\nRight?\nThen I can also extract all the information cloud knows about me through GitHub.\nYou see it says my bio, my email address and all the public information through the tool.\nAnd of course I will be able to add two numbers together.\nAmazing.\nSo now we have been able to create a production ready app, deployed it on a very robust infrastructure,\nCloudflare, and put the whole thing behind an OAuth production ready authentication.\nCongrats.",
            "dataPurpose": "item-7"
          },
          {
            "title": "71. Secure MCP - Cloudflare Dashboard Deep Dive",
            "videoUrl": "https://epam.udemy.com/assets/65314251/files/2025-05-21_17-40-39-619b229325bc9f977bff87a35ea34936/2/aa005c9016b6e0ca95c3cdb10456308d9659.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yMV8xNy00MC0zOS02MTliMjI5MzI1YmM5Zjk3N2JmZjg3YTM1ZWEzNDkzNi8yLyIsImV4cCI6MTc1NTc4NzgxOH0.3afu7DKWTov0-Z3YWxTuIvJkhHmgcTHpgskB3OKu6QY&provider=cloudfront&v=1",
            "transcript": "I quickly wanted to show you my Cloudflare dashboard, so you can also go to your Cloudflare dashboard\nand just take a look at how our applications behave.\nSo if you come here already at your dashboard, you will probably see a secure and a public application.\nBut even if not, then at the Compute Workers page you will see them both.\nSo if you remember, we had the server public, which is without a GitHub authentication, and our MCP\nwith the GitHub authentication is called MCP Server Secure.\nNow, because I spent quite some time working on those, you will see that my MCP server is secure.\nIt does have some errors too, and it has quite a few requests.\nNow most probably you will see a smaller number of requests and hopefully zero errors.\nNow the errors come from some GitHub configurations.\nSo as I develop the courseware and work on the videos, I tend to delete stuff, change stuff, and\nof course then many things need to be adjusted until we come up with the final version.\nSo that's why you see a bunch of errors here.\nLet's take a look at what else we can see here.\nYou will be able to see all of the requests from different hosts and how many there is.\nAnd also errors by deployment version client disconnection problems.\nThe request distribution.\nYou can see here that so far all the requests came from Vienna Austria, Europe because that was me\nthe CPU time that these certain versions used and the request duration.\nSo you have a very deep dive analytics about your application.\nYou can also take a look at the deployments.\nProbably in your case you would only see one.\nYou see that I went on and made quite a few changes along the way.\nSo I have a bunch of deployment and here is the latest and this is what I have deployed.\nYou can also take a look at the logs like the HTTP logs if you want.\nIntegrations will probably be empty.\nWe haven't set up any integration here, but if you go to settings you will see many familiar things\nhere.\nSo the workers.dev.\nIf you remember when we created our first MCP on Cloudflare.\nWe had to come to compute workers.\nSo these workers are dev domain.\nThe subdomain was created for us.\nOkay.\nHere are my preview URLs.\nHere are the variables and the secrets.\nSo this is what we have set up right.\nYou can see that the value is encrypted.\nSo these are actually secrets.\nThere is also the kV namespace here right.\nSo this is the OAuth kV and a bunch of other metadata and data.\nNow maybe the last thing if I go to the kV then here you will see what class they're actually stores\ninternally.\nSo you see it's all about uh the GitHub integration.\nSo my MCP servers, rapper Cloudflare, it works with the access token and a bunch of other stuff that\nyou might be interested in.\nIf you want to go and deep dive into OAuth and how this specific MCP server is authenticated.\nFeel free to take a look in your environment.\nI think it's very educational to see what happened once we executed Wrangler Deploy.\nI'll see you in the next video.",
            "dataPurpose": "item-8"
          }
        ]
      },
      {
        "title": "Section 13: Welcome To the HERO Section of the Course",
        "items": [
          {
            "title": "72. Welcome to HERO",
            "videoUrl": "https://epam.udemy.com/assets/65338547/files/2025-05-22_13-49-00-00fe7bc0f30da69ddc8d4e0e77cd4ad7/2/aa0099031879fc48c8b87c9500ed906cd858.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yMl8xMy00OS0wMC0wMGZlN2JjMGYzMGRhNjlkZGM4ZDRlMGU3N2NkNGFkNy8yLyIsImV4cCI6MTc1NTc4NzgzMH0.jxQzHIKAZZggyGmcjlS4aPank4fTFD775nlC01zKtZ8&provider=cloudfront&v=1",
            "transcript": "Well, first of all, I would like to express my sincere congratulations for making it that far in the\ncourse.\nOnly a fraction of students make it more than halfway through in every e-learning course in the world.\nSo keep it up.\nNow, at this point, I consider you as a seasoned MCP expert, so to say, because you have completed\neverything that I think is essential to start working with MCP.\nNow we are starting with the hero section of the course, which means that I will set up additional\nmodules, and we are going to go and do deep dives into different technologies.\nYou can think about these as optional modules.\nSo I don't expect you to go through all of them, because it will be more like a breadth search of topics\nthat we want to pick.\nAnd you probably want to cherry pick the ones that you like from this point of the course.\nThe course will have more personal touch.\nSo if you don't mind, I will share more personal stories from my professional life and make more detours\nas long as they are relevant and useful for your MCP journey.\nAlso, as you made it this far, I believe you very well deserve a certificate of completion.\nSo if there are topics that you don't like, I would like to ask you to just come and check them in.\nAnd this way you will be able to get a certificate of completion from Udemy, even if you skip a few\nlectures.\nSo welcome again in the hero section and I see you in the next lecture.",
            "dataPurpose": "item-0"
          },
          {
            "title": "73. Module-Specific Dependency Management",
            "videoUrl": "https://epam.udemy.com/assets/65338561/files/2025-05-22_13-49-07-21a4eaf8e5a4a1effc2c9dc08f2326c0/2/aa0045821c3a0d7c21b8566da46d71493409.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yMl8xMy00OS0wNy0yMWE0ZWFmOGU1YTRhMWVmZmMyYzlkYzA4ZjIzMjZjMC8yLyIsImV4cCI6MTc1NTc4NzgzOH0.pOlUd_pz_LS8RH2XC3eE4N16VB1KeAromvjwysFb0fE&provider=cloudfront&v=1",
            "transcript": "As we covered the upcoming modules in the course.\nI want to separate dependencies because I don't want to force you to install all the dependencies for\nall of the packages that we touch on in the course, if you only need a few.\nAnd for this we are going to use UVs Dependency Groups feature, where you can define different dependency\ngroups and install those dependencies separately.\nLet me show you an example here.\nHere is my Pyproject.toml.\nNow by the time you watch this video, your pyproject.toml might look somewhat different, but here\nyou will see that we have dependency groups.\nAnd in the dependency groups.\nFor example, I have a dev, I have something called small agents and I also I have the regular dependencies.\nSo when you execute you will sink.\nThen you will use the regular dependency group and all the dependencies will be installed.\nAnd if you want to install the dependencies for a certain group, you can say UV sink group and the\ngroup name like OpenAI.\nAnd then all the packages for OpenAI will be installed.\nPlease always ensure to start off in the NCP course folder, and also ensure that you have a virtualenv\nactivated wherever you are required to install dependency group.\nI will be very explicit about it, so don't worry about it.\nI just wanted to show you a brief behind the scenes about what's happening when we install different\ndependency groups.",
            "dataPurpose": "item-1"
          },
          {
            "title": "74. Notebook Functionality in Python Files in VSCode",
            "videoUrl": "https://epam.udemy.com/assets/65338549/files/2025-05-22_13-49-00-044bfaff0548e425e88f93e154a9d479/2/aa00bc6b7eaac67e707507f95bffb721d3de.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yMl8xMy00OS0wMC0wNDRiZmFmZjA1NDhlNDI1ZTg4ZjkzZTE1NGE5ZDQ3OS8yLyIsImV4cCI6MTc1NTc4Nzg0NX0.rcOZez8hxoxI7KFiaY6ceGQ9te4AN-CX7ZAJHCkEODQ&provider=cloudfront&v=1",
            "transcript": "Another feature I would like to draw your attention to is the Python file based notebook functionalities\nin VSCode.\nYou're already very familiar with how to use notebooks, and we covered this earlier in the course.\nSo your VSCode environment should be set up both when it comes to the use of packages and the VSCode\nextensions.\nSo you can work with notebooks, but we have an issue with notebooks.\nAnd the issue with notebooks is that they are great for interactive data analytics and development,\nbut they are not.\nPython notebooks look great if you have the software or an extension to manage them.\nBut if you take a look at the underlying file, it is actually a monster JSON.\nLet's take a look.\nI open this notebook now with a text editor, and you see here is my JSON file.\nSo this is the actual notebook file.\nSo if you want to use for example git then it's very hard to compare changes that happen in a notebook,\nbecause on a git level you would compare these underlying JSON files.\nSo that is one issue with notebooks.\nThe other issue is that those are not Python files.\nSo if you want to execute like formatting or linting or whatever, then you are up to the mercy of the\nlinters developer.\nIf they implemented a notebook support in their package.\nThere is a good solution to that though.\nAnd this is the Python file based notebook functionality in VSCode.\nLet me just show you how that works.\nLet me create a new file.\nI will call it Notebook as Python.\nI'm gonna give this the py extension.\nAnd now I will start using it as a notebook.\nAnd here comes the trick.\nIf you start with a comment and then add two percentage signs, then your Python file will transform\ninto a Python based notebook.\nSo I can say, for example, print Hello World and you will already see that I have these run cell run\nbelow debug cells.\nSo the notebook functionalities right.\nAnd I can just add more and more so I can say print over two, for example, and I will be able to execute\nthese cells.\nSo to say, as if they were standard notebook cells.\nSo I can press for example ctrl enter and then a notebook interpreter is coming up.\nYou see it uses my virtual environment.\nIt executes hello world.\nI can execute the next one.\nThen it prints Hello World two.\nSo what I have here and this is the big thing, this is still a very, very standard Python file because\nthe notation is just a comment.\nRight.\nBut I have the notebook functionality here in VSCode.\nI love this feature, and I believe you should use it because it gives you the interactive advantages\nof notebooks.\nBut you can still work in a standard Python file that you can then execute as an application.\nYou can run eishort or black or rough or whatever on it, without any notebook extension or any issues.\nAs the course progresses, I'm going to use these Python based notebook files and also notebooks, whichever\nfits best.\nThe use case.",
            "dataPurpose": "item-2"
          }
        ]
      },
      {
        "title": "Section 14: MCPs in the OpenAI Agentic Framework and the OpenAI Respose API",
        "items": [
          {
            "title": "75. OpenAI MCP Support Introduction",
            "videoUrl": "https://epam.udemy.com/assets/65338541/files/2025-05-22_13-48-54-25257b4689685f5f02533e5a71f24f10/2/aa00dee80fd53f2db6d89de70a91b276e1ba.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yMl8xMy00OC01NC0yNTI1N2I0Njg5Njg1ZjVmMDI1MzNlNWE3MWYyNGYxMC8yLyIsImV4cCI6MTc1NTc4Nzg1N30.vEBtrZfxK5kv25FR7cXJe-Lk3V5d_rtege2ZSmVddCo&provider=cloudfront&v=1",
            "transcript": "In May 2025, OpenAI dropped the bomb and introduced MCP support in their responses API.\nThis very much means that MCP is now a first class citizen in OpenAI applications.\nAnd there's big news for the MCP because OpenAI supporting MCP as first class citizen throughout their\noffering, MCP has become now the de facto protocol for AI service communication.\nIn this module, I would like to show you how you can access MCC through the OpenAI API.\nAnd what are some of the caveats that you need to take into consideration when you work with MCC from\nOpenAI?\nPlease keep in mind that in order to code along, you will need to have your OpenAI API key set in your\ndot env file.\nIf you don't have an OpenAI API subscription, don't worry about that.\nJust watch along and you will still understand everything that we cover in this module.\nI'll see you in the next lecture.",
            "dataPurpose": "item-0"
          },
          {
            "title": "76. OpenAI Agents API Function Calling and Tracing Techniques",
            "videoUrl": "https://epam.udemy.com/assets/65338563/files/2025-05-22_13-49-09-22a80cbb891d55e8a0d1241f6a41461d/2/aa00dffa6ae1368efa869fb4f88f9027f5de.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yMl8xMy00OS0wOS0yMmE4MGNiYjg5MWQ1NWU4YTBkMTI0MWY2YTQxNDYxZC8yLyIsImV4cCI6MTc1NTc4Nzg2NX0.-lafuc4sSseG0xXNdNuLNTQSuxqJ5i5ueqyatOaEDUs&provider=cloudfront&v=1",
            "transcript": "As a first step for ramping up with remote MCP support in OpenAI and OpenAI agents.\nLet me show you how function calling works and how you can trace function calls in an agentic mode.\nIn OpenAI, please come to the VSCode and install the OpenAI dependency group.\nOnce you're done with that, ensure that you have OpenAI MCP folder.\nIf you don't have one, create one.\nAnd in this folder let's create a new file.\nAnd let's call this file function calling.\nWhat we want to do is to create an agent and also create a tool that for the sake of simplicity, let's\njust have a tool that multiplies two numbers.\nPass this tool to the agent and then create a runner that can execute this agent.\nAs a prerequisite, we will need to load our OpenAI API key.\nSo let me just go and first import dotenv.\nAnd load my env file which comes from the parent folder.\nRight.\nAlso from OpenAI agents I want to import the agent, the runner and the function tool.\nNow I am ready to create an OpenAI agent.\nA minimal implementation of a tool calling agent will have a name, an instruction about how to complete\na task, and the tool definitions.\nSo let's just give this a name.\nThis is the agent.\nThe instruction will be super simple.\nI will just say always use your tools to solve math problems.\nAnd I'm providing the tools to and for the moment we don't have any tools, right.\nSo it's just an empty array.\nNow that I have an agent, I just need a runner so I have something to execute it.\nNow that I have an agent, let's create a runner that runs this agent and manages its execution.\nIt will give us a response and it will be a simple runner.\nAnd I can say just run sync.\nSo I don't want to have any async behavior and just give it a math problem to solve.\nOnce the agent has executed, we are going to have a response object so we can take the response object.\nAnd actually what we want to take from the response object is the last output.\nSo the output of the last step of the whole agent execution because the agent will be able to, you\nknow, interact with the LM, call a bunch of tools whatsoever.\nBut at one point it will stop.\nAnd this is what we want to pick out the latest output in the whole agent execution chain.\nYou can reference this as the final output?\nAll right.\nSo far, so good.\nNow let's create a simple multiplication function.\nI just take x and y and return x multiplied by y.\nOkay.\nSo this is almost identical.\nI can add this to tool to my tools definition.\nAnd all I need to do is to convert this into a tool.\nAnd for that what I will need to do is first of all just annotate it with the function tool.\nSo this is what we have imported from here right.\nAnd then also if you remember the when you work with tools then annotations.\nAnd the actual docstring is super important.\nSo I can say x is a float y is a float.\nAnd this returns a float.\nI'm also adding a docstring which Leach says.\nMultiply two numbers.\nAll right.\nLet's try to execute this.\nOkay.\nAmazing.\nSo I now have the result, but I, I don't really know if this was now the multiplication function call\nor just OpenAI figuring out the result.\nRight.\nSo how can I debug this?\nIf you work with the agent tic API of OpenAI, then there is a quite easy way to debug this.\nAnd these are called traces, just like Lang Smith traces, but now on the OpenAI website.\nSo if you go to Openai.com and you login to the API platform, then you can go to your dashboard and\nyou will see a traces menu.\nSo click traces and here you see a bunch of agents workflows.\nYou see that I have a few and the top most will be the most recent.\nSo let me just click the agent workflow.\nAnd here I will be able to debug what happened.\nLet's take a look.\nSo first of all I send the prompt what is this and that.\nAnd the output was that hey I want to do a function call and I want to multiply these two numbers.\nThen the agent framework on my local machine did the function call and provided the output.\nAnd this output was then passed as an input for the last step.\nAnd then OpenAI said the result okay.\nSo this way you will be able to debug agent behavior and see if function calls.\nOr as you will see later, MCP calls has been happening or not.",
            "dataPurpose": "item-1"
          },
          {
            "title": "77. Using MCPs from the OpenAI Response API",
            "videoUrl": "https://epam.udemy.com/assets/65338555/files/2025-05-22_13-49-02-c231a3b557a88e91f64a6363f202fda6/2/aa00ae29705b14d997d52a8519cb97461146.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yMl8xMy00OS0wMi1jMjMxYTNiNTU3YTg4ZTkxZjY0YTYzNjNmMjAyZmRhNi8yLyIsImV4cCI6MTc1NTc4Nzg3Mn0.h-N2nZwLTtWrfEFegO2psAGbJu13W_g0tFio0Wf9DPU&provider=cloudfront&v=1",
            "transcript": "All right.\nNow that we have a good idea about how tool calling works and how you can debug it, let us integrate\nMCP into the OpenAI Response's API.\nAs a first step, this is not going to be an agentic behavior.\nI want to showcase how you can use the API, and how you can add an MCP and then implement automatic\ntool calling.\nLet's create a new file into OpenAI MCP folder, which is called MCP with responses api dot pi and import\nthe usual suspects.\nWe're going to need our dot env file right with the OpenAI key.\nAnd we need the OpenAI class.\nLet's create an OpenAI client until that point.\nThis is a very, very standard OpenAI code.\nAnd let's see how you can use the OpenAI API.\nI will go on and create a new response so you can simply just say client dot responses, dot create\nand then pass the model which is GPT 4.1 in our case.\nAnd we can also pass it to us where we don't have any tools yet.\nSo let's just pass an empty array.\nThen we can pass the prompt through the input parameter.\nSo we can say like say hello.\nAnd let's just print the response.\nNow if you want to investigate the response then you can go down to the pedantic level.\nSo extract the response object and put it to the screen.\nSo if you say response dot model JSON then you will actually see the response popping up on your screen\nin a formatted way, which I find as probably the best way to debug OpenAI responses.\nOnce I save this file, let me execute this script.\nAnd here you see I have the response.\nSo let's just spend some time on this one because I want you to understand the basic structure of the\nresponse, because it will be important as we approach our MCP calling phase.\nSo the response has an ID and it usually starts with resp underscore.\nIt has a bunch of metadata as you can see like for example the specific model ID.\nAnd then we also have an output.\nThe output itself it is an array.\nEach message has an ID and if it's a text message so like a proper response message then it will also\nhave a content attribute.\nHere you see that the contents text is.\nHello.\nHow can I help you today?\nSo that's great.\nYou will see a bunch of metadata that this message was sent by the assistant, and it considers the\nwhole conversation as completed.\nYou will also see some extra statistics about how many tokens are used for input and output whatsoever.\nAll right.\nLet's just go on and convert this into a notebook.\nSo I'll just come here and say.\nConvert this to a cell.\nThis will be my second cell after the import.\nAnd let me go and re-execute everything the import has completed.\nI can now hide the terminal.\nLet's execute the second cell.\nAnd now I have the output here.\nRight.\nOkay.\nSo that's much more convenient.\nKeep in mind that you can control enter a cell, but you can also shift enter a cell and then a new\ncommand will be automatically added to your file.\nLet's implement an MCP call for the call we are going to use Deep wiki.\nDeep wiki is a place which contains a bunch of repositories and you can talk with these repositories.\nYou can always check if a repository is indexed by passing the repository name.\nAnd for example, if I pass Model Context protocol as Python SDK, you see that this repository has\nbeen indexed by wiki.\nSo I can just go and ask anything about the code inside this repository through the wiki.\nAnd this wiki has an SMTP server and this is what we want to use.\nSo we want to add the functionality to OpenAI so that it can reach out and basically has full access\nto the most popular GitHub repositories.\nAnd it will be able to investigate the code for us and answer questions about the code.\nLet me go back to my editor and set up the MCP definitions.\nI'm going to copy this to a new cell and change it to us.\nNow I will work directly into the list here, which I define as the parameter.\nSo this is how you can define an MCP.\nYou need to give it a type.\nSo open I understand that this is an MCP.\nYou can give it an ID which is called a server label.\nLet me call this DB wiki.\nAnd because the responses API supports remote MCP, I can simply pass the MCP URL.\nNow as you will see, Openeye supports streamable http.\nHttps or the modern protocol for m.c.p.s.\nSo that was very much it.\nNow I added my MCP to the code and open AI is ready to use it.\nLet me let me just add the more sophisticated input.\nI'll extract this to a variable called prompt.\nWhat I want to know is what transport protocols are supported in the Mars 2025 version of the MCP spec.\nLet's also pinpoint the repository that we want to use, which shouldn't be necessary, but because\nthis is instructional material, I want to make sure that it's bulletproof for you.\nLet me go now and execute this cell.\nNow, this might run for a while depending on the load of the wiki, but here is the response.\nLet's investigate this.\nWe see that there is a response ID, as you've seen earlier, and there is an output, right.\nSo the output doesn't have a content attribute.\nAt least it has it but it's not.\nSo that means that it's not like a standard output that you want to put on the screen.\nIf you take a look that you will see that the type itself is an macp list to us.\nNow what does it mean?\nIt means that the first thing the responses API does is that after it sends the prompt to the LM.\nThe LM says, all right, can you just give me all the tools that are available so I can work with them?\nAnd here are the tools.\nYou will see that we have a bunch of them.\nHere is the name structure that gets a list of documentation topics for a GitHub repository.\nAnd there are a few others like read wiki contents and ask a question.\nSo this is what we have.\nAnd then let's take a look at the next message is output and is still not a content output, right?\nIt says, well, it's actually an macp approval request.\nSo it wants to call the MCP, specify the repo name with the one that we specified.\nAnd here is the question and this is the question that we specified.\nRight.\nSo it understood the question it understands.\nAnd this is the OpenAI backend.\nIt understands what to ask for and which tool to use to ask for this, but it doesn't have approval\nfor it.\nIs this okay?\nI think it is.\nBecause if you think about it, if you work with a certain endpoint, for example, you work through\nthe API with OpenAI, then you have specific guarantees about what OpenAI will do and will not do with\nyour data, but as soon as it wants to reach out to an MCP, it might leak your data to anywhere, right?\nYou don't have that guarantee.\nSo this is certainly not something enterprise ready.\nAnd because of this, the standard OpenAI behavior is that it won't use MCP without your explicit approval.\nSo let's just give it an explicit approval in the next cell if you want to approve MCP usage.\nWhat we need to give approval we are going to need the request ID which is this ID right here.\nAnd continue the conversation.\nSo not start a new conversation but continue the conversation.\nSo first let's extract the request ID.\nThe request ID here is the latest output ID.\nSo I can just say request ID is the latest output ID.\nNow let's create a new response.\nI'm going to copy and paste everything here and just modify it so that we continue the conversation.\nAnd we also pass our explicit approval.\nFor continuing the conversation.\nWe will need to send the previous response ID.\nWhich is simply the latest response ID right.\nSo I can just say response.id.\nAnd now the input will not be the prompt because we already have the prompt as referenced by the previous\nresponse ID, but it will be our approval.\nSo after a bit of formatting this is how it looks like.\nI'm adding a new input where the type is MCP approval response.\nI am approving this request.\nRight.\nAnd which request Am I approving is the one that I extracted from the previous output?\nLet me execute this cell.\nAnd let's put the output into a scrollable element.\nAnd now you will see that I have a proper response with a content in our output, which says as of the\nlatest updates in the Model Context protocol Python SDK repository.\nThe following protocols are supported.\nAll right.\nThis has worked.\nAnd you see that it's kind of cumbersome right.\nBut still it's super safe.\nSo if you put maps to production I think it's a good default setting to require explicit approval.\nAnd in the next section I will show you how you can enable automatic approval and how you can restrict\nthe mcps-prs for only allowing a certain tool cause.",
            "dataPurpose": "item-2"
          },
          {
            "title": "78. Auto-Approving MCP Requests and Regulating Tool use in OpenAI",
            "videoUrl": "https://epam.udemy.com/assets/65338551/files/2025-05-22_13-49-00-c817a547554851af309c3609d8206467/2/aa008de35a37e83b5b6ff79de0367566a7bf.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yMl8xMy00OS0wMC1jODE3YTU0NzU1NDg1MWFmMzA5YzM2MDlkODIwNjQ2Ny8yLyIsImV4cCI6MTc1NTc4Nzg4MH0.T4HkX5RBTCT6AMmK5EcYRxbJ_hh67NZG5skQ1mX6590&provider=cloudfront&v=1",
            "transcript": "So let's just make this whole workflow more streamlined.\nFirst of all, I'm gonna go and copy and paste the first MCP call.\nFirst of all, I'm going to go and copy and paste my first MCP interaction code as a new cell.\nAnd what I want to do is to avoid explicitly authorizing every MCP call.\nThis is actually quite simple.\nWe can simply add the required approval never parameter.\nLet's execute this cell.\nAnd you will see right away that.\nNow if I scroll up to the output, the last output item has a text parameter, which is the answer itself.\nSo the MCP call has gone through successfully.\nAnd if I just create now a new cell I can just print the responses output text.\nAnd here you will see.\nHere is the actual summary the actual output that I received from the LM.\nOkay.\nSo that's simple.\nAnd that was kind of straightforward.\nAnd now I just wanted to show you one more thing.\nAnd that is how you can restrict tours inside an MCP.\nIf you take a look at the output we see that there are a bunch of tools here.\nRight.\nAnd what I want to do is to restrict every MCP operation to the ask question tool.\nI want to avoid using any of the other tools this MCP provides.\nSo then I can just say a load to us.\nAnd then in a list, just specify the tools that I let these MCP explicitly approve the use of.\nLet me print the output text and let's re-execute this.\nAnd you'll see once it's done that the actual question was called because we have an answer here.\nAll right.\nSo in this video you've seen how to auto approve MCP calls and how to LM which tours it's allowed to\nuse when calling MCP.",
            "dataPurpose": "item-3"
          },
          {
            "title": "79. Using MCPs from the OpenAI Agents Framework",
            "videoUrl": "https://epam.udemy.com/assets/65338559/files/2025-05-22_13-49-05-48b5ddfc1c51aec90150559d291345b8/2/aa000ddb0e8bdd0fad4af58575941364b5c7.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yMl8xMy00OS0wNS00OGI1ZGRmYzFjNTFhZWM5MDE1MDU1OWQyOTEzNDViOC8yLyIsImV4cCI6MTc1NTc4Nzg4N30.6oP79C3HIU64N7f1n6xqv0Ky0NioQE4qnZqtK5qIrEk&provider=cloudfront&v=1",
            "transcript": "Let's see how you can use the OpenAI agents API to access MCC.\nThis will be somewhat more sophisticated as accessing a remote MCC through the responses API, simply\nbecause the OpenAI agents API doesn't support direct access to remote MCC yet.\nSo what can we do?\nI have the full code here because I don't want you to code along as it's like lots and lots of indentation\nand imports and everything.\nSo I will just go and explain what you see on my screen.\nNow, if you take a look at the whole code, then I think everything must be very much familiar.\nYou've already seen, of course, like how to read our dot env with the OpenAI API key and how to create\nan agent.\nSo here is an agent definition.\nRight right in the middle with the name and then instructions.\nAnd now we don't use tools because tools don't support MCP access.\nBut we use these explicit parameter called MCP servers.\nAnd I will pass an MCP server that we can discuss later.\nI also have the prompt and I also have the agent runner.\nBut now because our MCP server SSD is an asynchronous function, we are converting everything into async.\nAnd that will mean that for the runner we don't execute run async, but we execute the simple run which\nis an async execution.\nAnd we are awaiting the answer because we have async pieces.\nWe must wrap everything into an async function, which will be our main function, and we need to import\nasync IO and do an async IO run.\nMaybe you've seen this species before in the course, right?\nAnd let's take a look at our main function now.\nThe biggest change here is that we need to define our MVP server object.\nSo it's not enough to simply provide a remote MVP URL for the agent's API, but we will need to wrap\nit into an HTTP server src.\nThat also means that we won't be able to use the streamable HTTP endpoint of the MVP server, but we\nwill need to use the src endpoint of the server.\nIf you work with MVP server, which is an official class of the open AI agents framework.\nThen you can specify the server's name and the server's parameter.\nAnd please always be on the lookout for the last tag.\nSo in our case this must be ssh and not mocp right?\nAlso, by default amqp server's timeout after five seconds.\nBut the db wiki Mccp server is somewhat slower, so it requires easy like ten to 20s to do a search.\nSo we are also setting a timeout parameter and setting it to 30.\nSo with that we are defining our server object and this is what we are passing to our agent.\nThen once we run the agent we are printing the final output to the screen.\nKind of easy still right?\nIt's not that elegant.\nAs if we could use the new generation Operation remote MCP endpoint, but still it works.\nSo let's go and execute it.\nIt might take a second or two or 10 or 20 before this executes.\nAnd here you see.\nSo we have the answer right now.\nOkay.\nHere is the question.\nActually in the earlier video.\nIn the previous video you've seen a responses API call which was much, much simpler.\nWe didn't need to worry about this whole wrapping into an SSE.\nWe could use a remote MCP endpoint whatsoever.\nAnd now we have a more traditional approach for MSPs.\nSo what is the advantage of using an agent and not strange the responses API?\nNow maybe you have already figured this out.\nThe advantage is that if we go through the agent API, we have traces.\nSo let's open our OpenAI dashboard Here in the dashboard.\nYou will see right away that I have the deep wiki agent popping up.\nAnd remember, this was the name of our agent, right?\nHere it is.\nAnd if I click it, I can see the whole execution broken down by steps.\nAnd for each steps, I will be able to see how long a certain step has taken.\nYou see that?\nFor me, it took around eight seconds.\nAnd this is what our LLM did.\nWell, first of all, before doing anything, it listed the tools from the wiki.\nTheories are the tool that we want to use as a question.\nRight.\nThen we sent the instruction and the input.\nRight.\nAnd based on the list to us, it figured automatically that we need to call the ask question MCP tool.\nAnd it's called it also for some reason, it showed that it's important that it also checks what's the\nstructure of this repo.\nSo it's called the read wiki structure.\nHere are these two tool calls.\nSo the wiki structure it parse the repo name.\nAnd here is the actual pages that are available here on DB wiki.\nAbout this repo.\nAnd then it asks the question now what is very important that if you take a look now we can catch a\nbug in the working of this protocol.\nSo you see the output from the question call said invalid repo name format DB wiki expected an owner\nrepo format.\nThis is curious because we explicitly sent the model context protocol slash Python SDK repo, but for\nsome reason it hasn't been picked up by the protocol.\nNow, I believe if we wanted to deep dive into that, that would take a full new course.\nIt's about how you can evaluate alarms and how you can fine tune agents and tool calling.\nBut the bottom line would be that you would need to improve the instructions of the agent, the prompt,\nand also if you have access to the MCP.\nSo if you are the owner of the MCP, probably the two descriptions of the MCP.\nSo the LM has a better way to figure out which way to get the most useful information out from the MCP.\nSo what happened here is that we received this response, and the agent figured to give another go to\nthe read wiki structure because it couldn't figure out our answer based on the ask question tool call.\nSo it tried to do that, but that didn't work either.\nSo what it did finally, is that it realized that basically based on the wiki page structure, It is\nable to extract this information.\nSo it gave us the actual answer, but not through the ask question endpoint.\nNow what you see here is I think this is great because this is very much a real world scenario where\nthings don't happen exactly as expected.\nIf you're coding along, you can re-execute this Python script a few times, and you can see that sometimes\nit will be able to get the ask question parameters right and sometimes it won't.\nAnd once again, you can then go and fine tune the prompt.\nEnter instructions to ensure that in 100% of the cases, this tool call goes through with the correct\nparameters.\nAll right folks, so this is what I wanted to show you about how you can work with OpenAI function,\ncalling the responses API and the agents API, and how you can create a real world mchp product using\nthese tools.",
            "dataPurpose": "item-4"
          }
        ]
      },
      {
        "title": "Section 15: Productionizing MCPs with Docker",
        "items": [
          {
            "title": "80. A Short Introduction to this Module",
            "videoUrl": "https://epam.udemy.com/assets/65462687/files/2025-05-27_14-20-38-becfdc8c09eb263e610e75bc25691c37/2/aa00b8df04daefa656a7c500af0202a9e877.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yN18xNC0yMC0zOC1iZWNmZGM4YzA5ZWIyNjNlNjEwZTc1YmMyNTY5MWMzNy8yLyIsImV4cCI6MTc1NTc4Nzg5OX0.srXZypT6wJ6bp-tiqOC7GLcKZakuGHCD4di6lbbxpis&provider=cloudfront&v=1",
            "transcript": "In this module, I would like to show you how to dockerize an SMTP server.\nWe are going to start with an introduction to Docker.\nFor those of you who are not familiar with the concept.\nAnd then we are going to work our way through a production ready MCP server using Docker.\nDocker is an amazing technology and I personally love it and use it every time when I can.\nIt enables us to build something on our local computer and provides guarantees.\nAnd this is the big thing.\nIt provides guarantees that once it's running on our local computer, we can just send it to any deployment\ntarget.\nLet it be AWS or Azure or Google Cloud or Render and it will just work.\nYou don't need to worry about dependencies, network or anything else.\nAnd this is the real power of Docker.\nSo we are going on now and building a Docker based MCP server from scratch.",
            "dataPurpose": "item-0"
          },
          {
            "title": "81. Docker Intro - Concepts, Images & Containers (optional)",
            "videoUrl": "https://epam.udemy.com/assets/65462697/files/2025-05-27_14-20-44-fa3efc568d30dcf053f6da0e8336fd32/2/aa00275c1d6115758501db015085ef283752.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yN18xNC0yMC00NC1mYTNlZmM1NjhkMzBkY2YwNTNmNmRhMGU4MzM2ZmQzMi8yLyIsImV4cCI6MTc1NTc4NzkwN30.FQLoo9qytuWAYX22LJDhWfXHPkxL7MdRW868nb6Q4PM&provider=cloudfront&v=1",
            "transcript": "For starters, I would like to give you a brief introduction to Docker.\nIf you're already familiar with Docker concepts like images, containers, the Docker package registry,\nand you understand the basics of networking and port mapping, then feel free to skip this video and\nfast forward to our next video when we are starting building.\nAll right, for those of you who need to get an introduction to Docker, here we go.\nSo Docker is a containerization platform.\nThat means that if you want to develop an application and you want to deploy it as a self-contained\nentity, then Docker is here for you.\nNow what does a self-contained entity mean?\nIt means that you have your application.\nYour application might need some resources, for example files that you want to ship with it.\nIt also has dependencies.\nJust think about, for example, Python and the Python dependencies that you define in the file or in\nrequirements.txt that can also go into docker.\nAnd when you use Docker you just take all of this your application code, all the resources, all the\ndependencies.\nAnd you also define like what's the the base OS or the base package.\nSo for example, I can say I just want to have a Linux based package that is built on ubuntu and has\na certain version of Python.\nNow all of this can be compiled into a self-contained Docker container.\nDocker has this philosophy of build once run anywhere.\nThat means that.\nSo to say, the struggle of building a Docker container happens on your laptop.\nSo you can just go and work your way through a working Docker container.\nAnd once you have it done.\nAnd once you have a Docker image, it's not a container to advance.\nThen you can just push it to any deployment target, let it be AWS or render or anything else and then\nit will work.\nAnd there's like guaranteed that it will work.\nAnother great property of Docker is that it's lightweight.\nSo if you just think about this, how can you ensure that you have an application that has all the dependencies\nand also actually an OS that runs it?\nThen what comes to your mind is virtual machines, right?\nI'm sure you've seen virtual machines in your life, like the software called parallels or VMware.\nThe problem with virtual machines is that they are very, very heavy duty.\nSo imagine that you have, for example, a windows desktop and you want to execute Linux on it like\na full featured Linux box.\nThat would mean installing the whole Linux environment into a virtual machine and then installing all\nthe software you need.\nAnd that will take up lots and lots of space.\nAnd if you start it and run it, it will also take lots and lots of CPU and memory just to get it running.\nAnd Docker solves this too.\nSo Docker is very, very lightweight.\nJust a side note if you run Docker on windows then it will indeed need a virtual machine.\nBut then on top of it every Docker image.\nSo every application will be very, very lightweight.\nIf you work with a Linux based system or a mac OS, then Docker will be just lightweight.\nSo it will use a very, very low amount of resources.\nAnd that's the big thing.\nLet us go through the basic concepts of Docker.\nThere are two basic concepts, at least the two most important will be Docker images and containers.\nAnd there is lots and lots of confusion about what our images and containers and the whole tech terms\naround it.\nSo let's start with images.\nYou can think about Docker image as a read only package that contains your application code and the\nruntime.\nSo the OS that views your application code and all of the libraries and all of the dependencies and\nall of the supporting files.\nBut the Docker image doesn't run.\nIt is just an immutable snapshot for your application.\nIt means that it's like a definition of your application.\nImages can then be stored on your local file system or can be pushed to Docker registries, which is\na concept that we are going to cover later in this video.\nNow how do I create a Docker image?\nThe way to create a Docker image is to create a so-called Docker file, which is exactly what it is.\nIt is a file called Docker file, where you can just define what you want to have in your Docker image.\nLet's take a deeper look.\nHere is an example Docker file.\nSo let's just unpack this a little bit.\nDocker file starts with a from tag where you define the basic runtime.\nSo for example here you can see that in a Docker file that I create here which is a blueprint for an\nMacp server.\nIt uses a Python runtime for a certain Python version 3.12.\nAnd we also have this Dash slim dash bullseye notation, which is already a more advanced topic.\nBut the intuition of that is that it's a very much stripped down Docker file.\nSo it's not like a full fledged ubuntu application or ubuntu OS, which has Python installed, but it's\nlike a bare bone Linux that has Python on it.\nThen I can also define a verb there.\nSo think about this as a fully vanilla Linux installation.\nAnd I'm just saying that all the commands that I want to execute.\nSo my working there so should be slash app.\nOkay.\nAnd once I'm done with that I can start building my application.\nFor example I can create an instruction called copy which says just take the requirements.txt file from\nmy local folder and copy it into my working folder which is slash app.\nRight.\nSo this is like the first instruction I give in this specific Docker file.\nAnd then I can say once you copy that I also want you to install the requirements.txt.\nSo just use pip and install all the dependencies.\nAnd then that's a command that will not get executed on your laptop, but it will be executed in the\nDocker file.\nAt least it won't be executed on your local OS, but it will be executed inside Docker.\nSo at this point I copied a local requirements.txt file and I installed it already.\nLet's also assume that I created my Python based MCP application in the app folder.\nSo in the local app folder.\nAnd obviously I want to copy that to into the Docker image.\nRight.\nSo I can just say please go and copy now my local app folder under app.\nSo that will be done.\nAnd once it is done I will be able to define a command, which means that if I ever and when I want\nto execute this docker file, then you want to execute python server.py.\nSo let's assume I have a server.py File in my app folder.\nOkay, here the cmd itself is a little bit strange, so you don't specify the actual string, but you\nspecify each component.\nSo the command and the parameter in an array.\nAnd this is just how Docker works.\nAgain just a side note.\nYou can also go with the string value.\nBut this is like the canonical way of executing a command.\nSo up until this point up until the copy these are instructions on how to build the Docker file.\nAnd when I want to start this Docker image, then Docker will take a look at my Docker definition and\nsay, okay, I have the image that I built here, and now I want to execute these files in this image\nor this command.\nSo Python server.py a big power of Docker is that it has these This layered structure.\nSo when you define a new command in your Docker file, then it will create a new Docker layer, which\nmeans that basically very, very technically speaking, it means that as if at least intuitively, if\nif I create from Python, then I will just have kind of a Docker image that's Python only.\nAnd then when I say the word should be slash app, that won't actually create a new image.\nBut when I say copy, then it will just create a new again, just intuition wise, an image on top of\nit which already has Python but also has the requirements file.\nAnd then I can go on and say, hey, I want to run a pip install.\nSo it will run pip install and all the files that pip install, creates or changes will be.\nAgain, put on the top of this as an extra layer, and the same happens with the app copy in our case.\nAnd that's a quite important concept in Docker.\nAnd these are called layers.\nSo I take these layers and I just stack them on top of each other.\nAnd this is how my Docker image will be built.\nAll the layers are read only.\nAnd the big thing with layers are that once a layer has materialized, you can reuse it.\nThat means that if I already downloaded the base Python image or the base Python layer, then other\napplications that I also want to build on top of Python, they won't need to be rebuilt because I already\nhave it because I built it earlier.\nSo this is the layered architecture and here is a visual representation for it.\nSo I have the base layer and then I'm just stacking everything up on top.\nNow what are the advantages of layers.\nWell first of all which we've just discussed is caching.\nSo if you don't change a layer, it doesn't need to be rebuilt.\nYou can also share layers, as I told you.\nSo if we have a bunch of images that use the same base layer, then they won't need to be rebuilt again.\nAnd as you will see later, layers can be pulled from the internet and once you download the layer or\npull the layer, it won't need to be pulled again.\nThere is also an extra layer, so to say, which is the container layer or a veritable layer.\nSo let me just discuss a bit more about containers.\nDocker containers is our second super important concept.\nContainers are running instances of images, so you build your application and when you want to run\nyour application, then you don't run the image per se, but you run an instance of the image and this\nis called a container.\nAnd you can, of course, run multiple containers of the same image.\nAnd each of these containers will have completely isolated processes.\nThey will have their own network.\nThey will have their own file system and their own process space.\nSo they are completely self-contained running entities.\nAlso, containers are disposable, which means that you can just start a container, do whatever you\nwant, and then stop a container and it will be gone, but your image will still be there.\nSo the concept is that you have a bunch of images, like if you want to create two MCP servers, you\nwill build one MCP server docker image.\nYou will build another MCP server docker image.\nAnd once you want to run these images, then these images will be instantiated into containers and Docker\nwill execute these containers for you.\nNow again just a side note.\nBy default Whatever files you create in your Docker containers file system, those will be gone when\nyou stop the container.\nThere is a concept called volumes that we don't need to cover in this course, which solves this issue.\nSo you can actually have local folders on your server or laptop, which containers you use so you can\nhave a persistent storage even if you want.\nIf you want to code along in this module, you will need to have Docker installed on your computer.\nYou can come to the Docker website and here under products you will see Docker Desktop.\nNow there are again two concepts here.\nThere is Docker Engine which is open source.\nAnd this is like Docker itself.\nAnd there is a proprietary solution from the creators of Docker which is called the Docker desktop,\nwhich is like a very nice application for managing Docker on your PC See.\nFor personal use, it's for free.\nSo I would suggest you to go and download Docker Desktop right away.\nYou see that?\nI have it installed too.\nIt's this small logo up here.\nAnd if I open it, you will see that I have a bunch of images.\nAnd here is an image for example MCP test.\nThat is the image that you're also going to create in this module.\nAnd I also have a bunch of containers which are stubbed or running instances of different images.\nI also have my volumes here.\nSo if I want to persist any files then I can work with those.\nSo please go to docker.com and ensure that you have a working Docker desktop on your laptop.\nOr if you're a Linux user, you can find instructions on how to install the Docker engine without the\ndesktop if you want.\nThat will work too.\nAnd let's just move on to our next topic.",
            "dataPurpose": "item-1"
          },
          {
            "title": "82. Docker Intro - Package Registries (optional)",
            "videoUrl": "https://epam.udemy.com/assets/65462699/files/2025-05-27_14-20-45-0039e6467b1337ea69cc229a6c2df7b4/2/aa005147287a5f9d1af8bf5721e1a449a141.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yN18xNC0yMC00NS0wMDM5ZTY0NjdiMTMzN2VhNjljYzIyOWE2YzJkZjdiNC8yLyIsImV4cCI6MTc1NTc4NzkxNX0.zWUP2vvncifQOkj9Kkm4BqBQ3-wNoDyj-vbJtr9-fNU&provider=cloudfront&v=1",
            "transcript": "As long as you only want to build the Docker image on your local machine and then run a container based\non that image, you are very much done with just building and running images.\nBut if you want to use a third party image like the python that I showed you in the previous video,\nor if you want to build and push your image and share it with the world, then you will need to work\nwith Docker registries.\nDocker registries are just like registries everywhere.\nYou can think about it as the PyPI package index or NPM, or all the package registries that are up\nout for Linux, for example, the APT registry.\nAnd of course, there are several registries for Docker.\nSo registries provide this central storage of image definitions.\nAnd there is one registry that's more equal than the others.\nAnd it's called Docker Hub which is a registry created by the authors of the Docker technology.\nThere are, of course, a bunch of other registries out there that we are going to cover later.\nIf you want to download an image definition from the registry, then we are going to use the command\ndocker pull.\nAnd if you want to push your Docker image to registry, then we are going to use the docker command\ncalled Docker push.\nNow we can use a bunch of registries to work with.\nAs I said, there is the official Docker Hub and then there are registries for, for example, Amazon\nand Azure and Google.\nAmazon's Docker registry is called ECR, which is the Amazon Elastic Container Registry.\nAnd also GitHub has its own registry.\nSo when we talk about the workflows using package Registry, then actually we need to extend our chart\nhere with a registry part.\nSo we have our registry.\nLet's assume this is let's say the official Docker registry which hosts a bunch of layers or images.\nNow intuitively speaking, it doesn't matter for us.\nAnd let's assume that I build uh, I'm building an SMTP server.\nSo when I'm building an SMTP server and I'm adding this from definition and then I'm building it locally,\nthen Docker will reach out to Docker Hub and just pull the Python image that I want to build on top\nof.\nAnd if I want to publish my mocp docker image, then I will be able to push this Docker image back to\nDocker Hub, the official registry.\nThe next time I want to build an SMTP server, which depends on the same python which originates from\nthe same Python image, then we will do a pool, but the pool is cached.\nSo the second docker image building will not go to the docker registry, but it will use the local docker\ncache for using the python and only add the changes on top of it.\nAnd of course, if you want to push your image, then all your own layers on top of Python will be then\npushed to the Docker registry with the reference of the original image.\nSo this is how the whole ecosystem is put into one single piece.\nLet me show you a few commands that we are going to execute.\nSo when you have a Docker file and your application and you want to make an image out of that, then\nyou will use Docker build.\nSo we will say Docker build.\nWe provide the folder where the Docker file is.\nAnd then we can also give a name to this server.\nThis is because it's officially called a tag and not a name.\nWhen you want to download an image, you can use Docker pull.\nWhen you want to publish an image, you can use docker push.\nAnd if you want to run an image locally, you can use the docker run command.\nLet me showcase you a few registries here.\nSo if you go to Hub.docker.com, that is as I told you, the official Docker registry, and you see\nthat it will host like thousands, if not tens of thousands of Docker images.\nAnd if I just take a look, you can see that there are a bunch of images here.\nFor example, here is the official image for Lang chain.\nBut there is also the official image for Python.\nSo if you take a look at Python, then you will be able to see links to the documentation and also the\ndifferent images which are required.\nAgain, not names but tags.\nSo if I just go and take a closer look I will be able to find my three dot slim bullseye.\nHere it is right when I click it, I will be able to see the docker file that this image used for materializing.\nYou see that it has another layer that it references.\nAnd then there is some quite sophisticated code on how to install Python and all the dependencies there.\nSo that is the official Docker registry.\nAnd then on GitHub you will find a registry called packages.\nSo if you go to your GitHub profile then you can click packages.\nAnd here you will see your images.\nYou see that I have a bunch of images from earlier projects.\nAnd then all the big cloud providers like Amazon have of course their own registries hosted on their\nown infrastructure.",
            "dataPurpose": "item-2"
          },
          {
            "title": "83. Docker Intro - Networking (optional)",
            "videoUrl": "https://epam.udemy.com/assets/65462679/files/2025-05-27_14-20-31-cb8a1ef0791d3a733df87fe221a98c40/2/aa00075321b854f0a81f60163e56d8c0b4b5.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yN18xNC0yMC0zMS1jYjhhMWVmMDc5MWQzYTczM2RmODdmZTIyMWE5OGM0MC8yLyIsImV4cCI6MTc1NTc4NzkyMn0.YAXEEnzZCEbfQGw-0zz7zhz5vnAyKB9JBFnSlQ4yn2Q&provider=cloudfront&v=1",
            "transcript": "I want to introduce you briefly to Docker networking.\nDocker networking is quite sophisticated, and we don't want to go deep into the details because that's\nbeyond the scope of the course.\nBut I want you to understand the basics of port mapping, because if you understand how Docker networking\nworks, then you will have an easy time understanding how to access a network interface on your Docker\ncontainer.\nAnd of course, with MVP server, those will expose a network interface if we use the SSE or the HTTP\nprotocol, and we will need to expose those ports from the outside.\nSo what you need to understand is basically the concept of a bridge network.\nThat means that when you start a Docker, it creates a virtual network inside your laptop or PC and\nall the Docker images that get started.\nSo all the Docker containers, they will have their internal IP addresses, but you will not be able\nto access these containers through their internal addresses, the containers themselves will be able\nto each other will be able to access each other though, so you can think about it as like a completely\nsealed network for your Docker containers.\nIf you want to access containers from the outside, then Docker will use a technology called Nat to\nhandle your outside host network and Dockers internal network.\nNow this is how you can imagine this.\nYou have the host machine, and then there is the full subnet which is bridged through the Docker Bridge.\nAnd then here we have the the containers with their internal addresses.\nNow what can I do if I want to access my containers.\nWhen I want to access those then I can run a Docker container with an extra parameter where I define\nthe port mapping.\nSo let's just take a look at this example.\nSo let's assume that we have two servers.\nAnd the first MCP server exposes its services as HTTP on port 8000.\nAnd there is another MCP server that again exposes its services through port 8000.\nNow in this case, these containers will be able to access each other through their original ports.\nSo that's all good.\nBut remember this is a completely sealed subnet and you are here on your host machine or on your server.\nRight.\nAnd the bridge network is the component that helps you go and access the ports that your containers\nexpose from the outside world.\nAnd that goes through port mapping, which means that every time we execute a Docker container, we\ncan specify how to expose their internal ports to the outside world.\nSo for example, I can say that when I'm running the Docker container one, then I want it to expose\nport 8000.\nSo internal port 8002.\nPort 8000.\nSo to the same port on your local machine.\nBut I wouldn't be able to do that with my second container because in the second container port, 8000,\nif you wanted to expose it to port 8000, that will be already taken, right?\nSo I can set up a mapping which says, for example, that I want to take port 8010 and route it to the\ninternal container's port 8000.\nSo this is the British network and this is network mapping.\nAnd you will see that it's super easy to just do these network mappings when you execute Docker run.\nBut I still think that it's important for you to understand that there is this bridge interface that\nhandles all this communication.\nSo you can have a mental model about what's going on behind the scenes if you just cannot access container.",
            "dataPurpose": "item-3"
          },
          {
            "title": "84. Docker Intro - Tags and Image Name Expansion (optional)",
            "videoUrl": "https://epam.udemy.com/assets/65462683/files/2025-05-27_14-20-36-4c078028d3a3c6c4d79ef23b526d0b93/2/aa00299c6f2eec6d7e77f38b77a3b2bb4a0d.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yN18xNC0yMC0zNi00YzA3ODAyOGQzYTNjNmM0ZDc5ZWYyM2I1MjZkMGI5My8yLyIsImV4cCI6MTc1NTc4NzkzMH0.Z57c3vA6xiF-9hbOdK64ygmqKB9v6Of7Lp5oqx6dwVc&provider=cloudfront&v=1",
            "transcript": "I want you to understand the process of Docker name expansion here.\nIf I want to work with a canonical name of Docker image, then it has several components.\nYou start with a registry or a host name, and by default this is Docker Hub.\nSo I would say like my Docker image is called Docker IO now.\nAnd after the registry comes a so-called namespace, which in many cases is your username.\nSo you can think about it as your account.\nThen comes the repository which I call name sometimes.\nAnd then there comes the tag which is a version tag of this name.\nSo there is lots and lots of confusion of how people use these concepts like registries, namespaces,\nrepositories, tags, images, and containers.\nIf you just think about, for example, that the Amazon Container Registry is called the Container Registry,\nbut it's not a container registry, it is an image registry.\nSo it's like a package, some kind of a package registry, right?\nSo there is lots and lots of confusion here.\nI'm sure that you will also catch me like making mistakes along the way, but it's important that you\nunderstand what all of these are about.\nLet's talk a little bit about tags because we are going to use this later.\nIf I come to the official Docker Hub then you will see that I have the Python package.\nSo Python here is the repository name right.\nIt doesn't really have a namespace.\nThe namespace is like official images.\nI believe that here the URL gives it away that it's an underscore.\nSo that's like the namespace for official images.\nAnd then it has a bunch of tags.\nFor example we have these three dot web site which is a tag.\nSo it's a specific version of this image.\nYou can also have tag aliases.\nSo you can easily attach multiple tags to the same image.\nBut there is a special tag which is called latest.\nIf you take a look here, if you say I want the python Docker latest or 3 or 3 13 or 313 three, then\nit will they will point to the same image, which is the latest release of Python.\nEvery time you push a new image to a Docker registry, the latest tag will be automatically updated\nand pointing to your most recent push.\nNow that you understand text, let's just take a look at a full fledged name expansion.\nSo when you say that you want to build or push the Binance MCP server, then actually what's going to\nhappen is that Docker will add a default tag called latest, or it will say you actually want to push\nBinance MCP server latest.\nAnd Docker will also figure that you haven't specified a registry or a namespace.\nSo it will assume that you want to push to the default registry, which is Docker Hub.\nSo it will add Docker IO, right?\nAnd it will also add the default namespace which is your username.\nSo when you simply say Binance MCP server and you want to build or push the Binance MCP server, then\nwhat it will translate to is Docker.io slash your username, slash Binance server and then latest.",
            "dataPurpose": "item-4"
          },
          {
            "title": "85. Docker Intro - Build an Image and Run a Container - Hands On (optional)",
            "videoUrl": "https://epam.udemy.com/assets/65462669/files/2025-05-27_14-20-19-7c6f0a0d724cd273fcc989e7b7c96bdc/2/aa00211b9b5b7009c6233f7537d1e40c7d7d.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yN18xNC0yMC0xOS03YzZmMGEwZDcyNGNkMjczZmNjOTg5ZTdiN2M5NmJkYy8yLyIsImV4cCI6MTc1NTc4NzkzN30.Qt2tQhRjioqJ_kFBUFUUZWa_L0HJ7iUXlZtCicCwONE&provider=cloudfront&v=1",
            "transcript": "For those of you who are new to Docker, I want to guide you through building the simplest Docker image\nand executing it as a container.\nSo let's just create a new folder called Docker intro.\nOr you can use my reference folder if you want.\nSo obviously go from scratch.\nI will say Docker intro as a new folder and I will create a docker file into it.\nAnd our use case.\nLet it be that all I want to do is that I create a new file.\nI will call it my file dot txt I just print Hello world.\nI type in Hello World in there and the new line and save it and I can close it.\nAnd now I can work and create a docker image that just prints the contents of this file to the screen.\nFirst of all, let me define the base layer.\nThis will be the Python 3.5 ci.\nAnd then let's define the word there.\nI'm going to put in app just to already prepare for our MCP implementation.\nAnd what I want to do is I want to take the myfile.txt from my local folder and copy it to app.\nAnd then as a command, what I want to do is, well, it's actually this one.\nSo I just want to use Cat, which is a Linux command for putting files content to the screen.\nAnd I just take the myfile.txt to the screen.\nLet me save it.\nAnd now I can CD into this folder.\nAnd then I can say docker build the current folder and just give this a name.\nHello.\nAnd you will see right away that Docker is reaching out to docker IO.\nIt puts the slim bullseye.\nAnd then it creates all the layers.\nAnd then at the end it says and now it says.\nNow I have the helo with the latest tag built.\nLet's just go and run it.\nI can say docker run.\nHello.\nAnd there it was and just catch how fast it was.\nEven though it's a completely separate environment, right?\nSo that's the real power of Docker.\nOnce your container finished, it won't be deleted unless you explicitly specify this in the docker\nrun command.\nSo it's always a good idea to execute docker container prune which will delete all the stop containers.\nOkay, and now I can take a look at what images I have.\nSo I can say docker image lz.\nAnd you will see that I have a bunch of images here.\nBut here is my hello repository with the latest tag.\nAnd here is my image ID.\nSo I can just go.\nAnd if I want to delete it I can just say Docker image Aram and the image id.\nAnd now this image is deleted and I'm back to ground zero.",
            "dataPurpose": "item-5"
          },
          {
            "title": "86. Dockerizing your Binance MCP service",
            "videoUrl": "https://epam.udemy.com/assets/65462689/files/2025-05-27_14-20-39-f366efb6dcfa10d3e05295dc78535055/2/aa0012168399eef1cddda2d77cca0f4b874d.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yN18xNC0yMC0zOS1mMzY2ZWZiNmRjZmExMGQzZTA1Mjk1ZGM3ODUzNTA1NS8yLyIsImV4cCI6MTc1NTc4Nzk0NX0.BDBaHNDGHOykoBMa_RqN4PCYlFQKVt6PxVjdWwPKjsU&provider=cloudfront&v=1",
            "transcript": "Let's go ahead and dockerize our MCP.\nIf you don't want to code along, as always there is a reference solution in ref sample MCP in Docker,\nbut I will guide you through the whole code.\nLet's go ahead and create a new folder and call it simple MCP in Docker.\nAnd what I'd like you to do is to come to your Binance MCP folder and make a copy of the Binance mcp.py\nfile into the MCP and docker folder.\nSo this is what we are going to build on.\nAnd I will just try to keep it simple for instructional purposes.\nSo I will remove everything but the get price.\nAnd of course I will keep the get symbol from name function for you.\nIf you already have a well working MCP with references and prompts and multiple tools, us.\nFeel free to take the whole thing with you.\nFirst of all, let's make our MCP compatible with Streamable http.\nCome to the main function and change the transport to streamable http.\nThen we also need to define our ports and our host where our MCP server will listen on.\nBecause now it is not a standard I o based solution, but it will actually open a port and we are gonna\ncommunicate through that port.\nI'm going to use port 8000 and also I will specify the host.\nNow this will be important for the Docker implementation.\nIf you just execute this MCP just as is then you don't need to specify the host.\nIt will open a port on localhost and it will be able to serve MCC requests through port 8000, but if\nyou want to put it into Docker, then remember that we are accessing everything from the host machine.\nSo from from the Docker side of you, from an external machine, and not from inside localhost as we\nwould do if we just executed a Python Binance MCP on our computer.\nSo we need to specify that this MCP should also accept connection from external servers and clients.\nSo that's why we need this host 0000, which is just a special notation of listening on all interfaces,\nwhich means that we want our server to accept connections from any other host out there in the world,\nbecause this will be a standalone application.\nWe also need to pass our Python dependencies.\nRight now we are not going to use UV in this case simply because setting up UV in Docker is a more sophisticated\nprocess than setting up a standard requirements.txt based Python dependency file.\nSo this is what we are going to do.\nSo create a new file and call it requirements dot txt and let's see what we need here.\nWe actually need the NAACP library right.\nAnd we also need the request library.\nAs you already see from the autocomplete.\nWe know that because we wrote this software and we re-import request and we import NAACP, that's all\nwe need, right?\nIf you work with Docker, and I think generally when you develop a Python based package that you want\nto deploy, it is also a good idea and always a good idea to pin the versions of the dependencies that\nyou want to use so you can avoid unpleasant surprises of things changing overnight.\nAnd then the next time you build your Docker container, it just won't work because something has changed\nin the dependencies, right?\nSo our requests and all we need at this point is a Docker file.\nSo let's just create a new Docker file.\nWe will start from the Python CI.\nSo that's okay.\nAnd we will create a Workdir app that works.\nAnd actually this is a great completion.\nSo we are going to take the Binance MCP Pi and just copy it into app.\nRight.\nKeep in mind that everything must be inside the Docker files subfolder.\nAnd you can create subfolders, but you cannot reference any file that's outside of the Docker files\ndirectory.\nThat's a constraint in Docker.\nSo we have Binance MCP copied.\nWe also want to copy the requirements.txt.\nAnd then when we are building this image we want to install the dependencies.\nRight.\nAnd once we are done we just want to go on and execute Python Binance App.py.\nLet's save this file and let us go on and build a Docker image from it.\nStep into this folder and you can execute docker build dot minus d simple Binance MCP.\nLet's see what happens.\nYou can already see that Docker is pulling the Python dependency.\nAnd now it's installing the requirements file.\nAnd we are done.\nSo if I say docker image ls my simple Binance MCP should be there.\nAnd this it's here, you see that the tag is the latest because we haven't added any extra tag yet.\nSo let's go and execute it.\nI will say docker run and here comes the trick.\nNow I want to do the port mapping for the bridge network.\nSo I will say that I want to take the external port 8004.\nLet's say it's just a random port that's not taken on my laptop, and I want to route it into the containers\nport 8000.\nRight.\nBecause this is where my MCP server will listen.\nAnd what I want to do is now I just specify the Docker image name.\nSo this is simple Binance MCP.\nIt's up and running.\nSo it says that it's listening on port 8000.\nBut don't believe that because that's how it listens internally.\nWe want to access it through port 8004.\nLet me just open a new terminal and execute the model context protocols Inspector.\nOnce the inspector is up and running, click Streamable http.\nBecause this is the protocol we use and just pass in http at localhost at port 8004.\nAnd of course, don't forget the MCP tag.\nLet's click on next.\nAnd you see that it has connected.\nI can go to tours list tours.\nAnd I have the gas price tour here.\nAll right.\nAmazing.\nSo now we have a local Docker container running and we have a local Docker image build.\nAnd this image has all the dependencies that are required to put our MCP into production.\nSo in the next video we are going to push this to a global Docker registry.\nAnd then later we will be able to deploy it.",
            "dataPurpose": "item-6"
          },
          {
            "title": "87. Publishing the Service to the GitHub Package Registry",
            "videoUrl": "https://epam.udemy.com/assets/65462701/files/2025-05-27_14-20-45-7767709643ff35d90bed2daec84131da/2/aa00933154ebe98c5c162de44917eac62c66.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yN18xNC0yMC00NS03NzY3NzA5NjQzZmYzNWQ5MGJlZDJkYWVjODQxMzFkYS8yLyIsImV4cCI6MTc1NTc4Nzk1Mn0.i1OaMSjy7wV06gvy4O5vza0S9JsS4rY7wJlj0j3-OTk&provider=cloudfront&v=1",
            "transcript": "Let's go ahead and make this Docker image accessible to the whole world by uploading it to a registry\nand making it public.\nWe are going to use the GitHub package registry for that, and in order to work with that, the first\nthing we need to do is to create a GitHub token for you.\nSo please follow me closely.\nCome to your settings page.\nIn settings come to Developer Settings and here you will find Personal Access Tokens.\nClick tokens classic.\nAnd you might have an empty list here.\nThat's okay.\nAnd then click Generate new token and generate new token.\nClassic.\nThis is where we can generate a token through which we will be able to access GitHub packages.\nI give the name of this token MCP course.\nAnd what I'd like you to do is to give it full repo access.\nThat's actually not important for now, but maybe in later lectures we will use this token for other\nuse cases too.\nAnd I'm sure that it can write and read packages.\nAnd let's just go and also give the delete packages authorization to it too.\nOnce you're done, click Generate Token.\nAnd now you have a token here.\nPlease copy it and don't show it to anyone.\nAnd come back to your Visual Studio Code environment.\nAnd I will show you how you can do this in windows in a second.\nBut if you are on a mac or on Linux, then you can simply say export GitHub token and then pass the\nvalue.\nAnd now when you want to push your image to GitHub.\nGitHub will give you the authorization to do so.\nIt is important for you to know that you will need to execute this command for every new terminal session.\nIf you want to persist this, then just add this command to your bash, RC or zsh, RC or any startup\nscript that you have on your Mac.\nOn windows, you can simply use a set environment variable in PowerShell and pass your token here and\nthen it will be set for good.\nSo you won't need to re-execute it.\nOf course you will find these commands in our course resources.\nThere is one more consideration to take into account before we publish this image on GitHub.\nAnd that is the support of different platforms by the big infrastructure providers.\nMost of the infrastructure providers like render or AWS, can only work with or prefer to work with\nAmd64 based images.\nNow, if you're not familiar with this concept, the idea is that if you work with an Intel based laptop,\nthen your architecture is Amd64.\nIf you work with an ARM based laptop, for example, with a MacBook, a new generation MacBook, then\nyour architecture is ARM.\nAnd these two architectures are not compatible.\nAnd when you do Docker build as we did then the architecture of the image will follow the architecture\nof your laptop.\nBut now we are building this thing and sending it to a publicly hostage repo.\nAnd we want to deploy it later.\nSo we want to ensure that we work with an Amd64 architecture.\nSo it's compatible with every infrastructure provider.\nEither.\nYou will be able to publish this image to GitHub even if it's Arm64, but you won't be able to deploy\nit.\nTo fix that, we are going to use a new Docker feature which comes installed with your Docker desktop,\nand this is called Docker build.\nDocker build X is a new generation build engine for Docker, and what we are going to do is that we\nare saying, hey Docker, use build X for building our current folder, but build it for the platform\nLinux amd64.\nAnd also what we want to do is we want to keep the tag so the local tag.\nSo we can just then execute this by saying docker run simple Binance MCP.\nBut we want to add the GitHub tag to.\nAnd the GitHub repository tag follows a standard notation.\nSo first comes the registry Azw3, which is g I o.\nThen comes the namespace or user which is your username.\nSo please change this later to your username.\nAnd then comes the repository.\nWe don't need to specify a tag, so we can just leave the tag part here.\nBecause of Vedics.\nWe will also need to pass the dash dash load parameter.\nSo this way we are going to build an amd64 package which is already tagged with GitHub.\nAnd here is the thing.\nIf you want to push your Docker image to a remote registry, then the way to do that is simply first\ntagging your Docker image with the fully qualified name, including that registry address.\nOkay, so let's just go and do that.\nI'm executing Docker build build and it will take only a second to be ready.\nSo now this is weird but it hasn't been pushed to GitHub yet.\nOkay, so now let's go and push this to GitHub.\nYou want to scroll up and take the GitHub tag and then simply say Docker push and the GitHub tag.\nAnd now my application my image and all the layers as you can see are pushed to GitHub.\nOnce this is done let's go to GitHub and take a look at our packages tab to access packages.\nGo to your account site to your profile and then packages.\nAnd you will see that I already have a bunch of packages that I use for other projects.\nAnd now you will see that you will have a simple Binance MCP package too.\nAnd it is a private package, but you want to enable the whole world to work with our M.c.p.s.\nSo let's click Simple.\nBinance MCP and let's set it to public.\nYou can come to package settings and in the danger zone click Change Visibility and set it to public.\nCopy the package name and then set this to public.\nNow go back to the simple Binance MCP tab.\nAnd technically speaking, it doesn't matter if it's public.\nAt this point you can also deploy of course private images.\nBut just for the sake of simplicity, I want to spare the authentication for deployment.\nHere you're going to see how you can pull this image if you want to use it later, or if someone wants\nto use it later.\nAnd also you can see that we don't have any special tags.\nWe only have a latest tag available.\nAnd this package registry, which is completely okay.\nNow let's go ahead and deploy this service.",
            "dataPurpose": "item-7"
          },
          {
            "title": "88. Deploying the Docker MCP Image ot Production",
            "videoUrl": "https://epam.udemy.com/assets/65462691/files/2025-05-27_14-20-42-cda7cdb6d3fa01ed30c165d111747725/2/aa00bf9bbc2b8853f471ea90a8b71f7cb55d.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0yN18xNC0yMC00Mi1jZGE3Y2RiNmQzZmEwMWVkMzBjMTY1ZDExMTc0NzcyNS8yLyIsImV4cCI6MTc1NTc4Nzk2MH0.lgb40soWeDJeAMpYWRi7iguZ5xjBl4leJC14RC7X6as&provider=cloudfront&v=1",
            "transcript": "You want to copy the full Docker URL to your clipboard, because this is now the canonical, publicly\naccessible URL of your Docker image, right?\nNow, once you're done with that, please go to your render dashboard.\nSo just log in again if necessary and use the project that you created earlier in the course.\nAnd then click the plus button and say Create New Service.\nThis will be a web service.\nSo new web service.\nAnd here now we don't use a GitHub provider but we use an existing image.\nAnd all you need to do is to paste the Docker URL in there and then click connect.\nHere you can fill in the name, but that's okay as is.\nAnd just ensure that you use the free plan.\nAnd that's very much it.\nTake a note that we didn't need to change anything, because Docker already has the full code and the\ndependencies, and everything is just packaged into our image.\nSo we can simply say, deploy that service.\nAnd this might take a minute or two.\nBut in the meantime, let me just wrap up what we have done.\nSo for for the first side you can say this is just too cumbersome.\nWe have already had a GitHub based installation on render and it just worked right.\nBut if you ever want to take MCC into production and you want to ensure that they are robust and deployable\neverywhere, then Docker is the best way to go.\nBecause if you have a Docker image, you can forget about like 90% of your deployment problems.\nYou already have an image, it has all the dependencies it defines, like on what architecture, on\nwhat base runtime it wants to work.\nAnd you can just deploy this to render.\nBut if you want you can just go and use an AWS service, for example, Fargate, and just push your\nDocker image there, or use Azure or Google, and you won't need to make any changes to your original\ncode.\nAnd you don't need to worry about how these platforms handle Python package dependencies.\nEverything is there for you.\nReady to deploy.\nThe service is now live.\nSo let's just copy the public URL and start an inspector so we can take a closer look.\nAnd sure that you have streamable http selected.\nAnd now I can just paste the public URL together with the https tag.\nAnd don't forget to add Mocp because this is the endpoint for the HTTP protocol.\nAnd I can click connect and it is connected right away.\nAnd if I go to tours and click List tours then my Getprice tool is there.\nSo congrats!\nYou have just created a really production ready MCP.",
            "dataPurpose": "item-8"
          }
        ]
      },
      {
        "title": "Section 16: Deploying MCPs to Amazon Web Services (AWS) Using Docker and ECS Fargate",
        "items": [
          {
            "title": "89. AWS Lambda and Fargate Introduction",
            "videoUrl": "https://epam.udemy.com/assets/67529281/files/2025-08-19_13-04-49-a0db53dd66295edce0e0900f2f66fe60/2/aa00e5b185a2e92899811be75da2deff6bfe.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wOC0xOV8xMy0wNC00OS1hMGRiNTNkZDY2Mjk1ZWRjZTBlMDkwMGYyZjY2ZmU2MC8yLyIsImV4cCI6MTc1NTc4Nzk3NH0.5WDd6YwSdyeJk2NWCKBda-WoSp8D89zuuR9oTvFwX2g&provider=cloudfront&v=1",
            "transcript": "Once you are ready to take Dockerized Mkps into production, you got to choose a platform, right?\nAnd my experience is that Amazon Web Services, or AWS, is a great platform for building production\ngrade applications.\nIt just offers so much.\nIt can host your Docker images, run your Docker containers.\nIt can do it in a way that it's completely scalable.\nAnd also it can provide you with a web application firewall and all the infrastructure that you need\nto get up and running with a fully production ready Amazon application.\nAnd this is what I want to show you here in this section of the course, how you can get started with\nAmazon Web Services and how you can deploy your MCP as a managed Amazon Web Services service, which\nthen scales automatically.\nOne caveat here is that in order to code along in this session, you will need to sign up for Amazon\nWeb Services, and Amazon Web Services is not for free AWS.\nSo if you want to sign up, just come to AWS at Amazon.com and you can create an account there.\nBut even though AWS comes with a free tier, the services that we are going to use, actually some of\nthem are not part of the free tier.\nSo I will be very explicit later in this video about the price, that and the cost that you can expect\nif you want to, uh, move on and, and code along.\nIf you don't want to code along, I would suggest you just watch the videos.\nThey will be quite short and they highlight the whole architecture.\nSo you will be able to, uh, still learn a lot.\nSo I want to show you, uh, two Amazon services for hosting Docker containers.\nAnd one is the so-called Amazon Lambda, which is like the fully managed serverless, uh, cornerstone\nof Amazon, so to say.\nSo you have a Docker image.\nYou can just upload it as an Amazon Lambda service and forget about it.\nAnd when a request comes so you can expose an endpoint think about an MCP.\nSo when a request comes in then what happens is that Amazon Lambda will check if your container is running.\nIf it's not running it will take the image, start the container, then execute the request and respond.\nAnd then keep running the container for a while because other requests might come in.\nBut if there is no traffic, just shut down your container automatically.\nSo it can pop it up again when a new request arrives.\nSo this is like super serverless and you pay by processing time.\nYou don't pay us by like hosting your container and running it all the time because it's not running\nall the time.\nSo I would say lambda is maybe the perfect solution for for MSPs, at least it would be Because at the\nmoment, the way how MCP is manage HTTP state and connections, it is not compatible with Lambda.\nThere are a few workarounds.\nEven Amazon has its official workaround, but those are at the moment at least super, super hacky.\nSo I would suggest you avoid Amazon Lambda for now, unless after this recording you will see other\nMCP Lambda native solution coming from Amazon.\nSo we will go down another path and this will be the Amazon serverless container service called AWS\nFargate.\nAWS Fargate is a place where you can run your Docker containers and don't care about the infrastructure\nbehind it.\nSo Amazon will provide the infrastructure.\nSo it's serverless and it will scale it for you automatically.\nSo if there is lots and lots of requests, it might spin up and other instances of the same container\nso they can cope with the request.\nAnd once there is less traffic, it can just ring back to us to a smaller size.\nSo this is called Amazon Fargate.\nAnd here comes the pricing piece.\nSo if you take a look you'll see that the Fargate prices are around.\nLike let's say everything included like $0.05 per hour.\nAnd with everything we build around Fargate in the next lectures, I think you can expect with a cost\nof like maybe $0.10 per hour.\nSo please keep this in mind.\nIf you want to code along, I will show you how you can stop and delete all of these services once you\ndeploy an MCP and tested it out.\nOkay, so with that, let's take a look at the architecture of the AWS services that we're going to\nbuild.",
            "dataPurpose": "item-0"
          },
          {
            "title": "90. AWS MCP Serving Architecture Overview",
            "videoUrl": "https://epam.udemy.com/assets/67529269/files/2025-08-19_13-04-45-0baaf18fd3b526cdd11be81e9ed789a1/2/aa00b99330e36e07fa859d406ab6e13d8f63.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wOC0xOV8xMy0wNC00NS0wYmFhZjE4ZmQzYjUyNmNkZDExYmU4MWU5ZWQ3ODlhMS8yLyIsImV4cCI6MTc1NTc4Nzk4Mn0.jBZbAxfTaNe54ISSiQ3ENRTUW9RDKO0-5KcGGD3AOLY&provider=cloudfront&v=1",
            "transcript": "Here you can see a blueprint of the architecture that we are going to build.\nOne central component will be the ECR, which is Amazon's container registry.\nKeep in mind that this is not a container registry, but it's a place to store your images.\nIt's the same to what you've seen with GitHub.\nYou can take your Docker images and push it to Amazon.\nSo Amazon service is called ECR for that.\nSo once we have our MCP as a Docker container, we will be able to upload it to ECR and lay out the\narchitecture of the Fargate service.\nFor this we will use the service which is called the Elastic Container Service.\nAnd Fargate is like one way to run an ECS service.\nSo that's why you see ECS here.\nBy the way the other way.\nSo there is Fargate, the serverless component.\nThe other ECS component, uh, or the way of working would be to to launch a virtual machine and deploy\nyour Docker containers there.\nThen you would be responsible of of, uh, sizing and keeping this virtual machine running.\nWhereas with Fargate everything works automatically.\nSo we have our what we're going to do is to create an ECS task definition.\nThis task definition, it's like a blueprint for our image.\nSo we will be able to specify like which image we want to pull and how many resources we want to have,\nand so on.\nSo it's defining the, uh, the service that we want to run.\nThen we're going to create an ECS cluster, which is the actual infrastructure, the infrastructure\ndefinition, like what's the minimum number of computers to run on, like minimum number of virtual\nmachines or what's the maximum number of virtual machines.\nSo how scalable you want to make this.\nSo this is like the the cluster infrastructure.\nAnd then once we have this we will be able to create an ECS task which is a running instance of this\ntask definition which will actually pull the image from ECR, the image registry, and run it on the\nECS cluster.\nSo this will be our ECS task.\nAnd inside we run our container of course, and we will be able to connect with our MCP client to this\nrunning service with one additional piece that we need to set up.\nAnd this will be the so-called EC2 security Group.\nA security group is a simple firewall.\nSo we will be able to, uh, to define here, and we will need to define here that our MCP Docker container\nshould be able to accept incoming connections on a certain port, like for example port 8000.\nSo let's just go and do this.\nLet's build our Docker container for this specific service, push it to ECR, then set up our security\ngroup, our EC task definition our cluster and run our service inside this architecture.\nOkay.\nSo let's go hands on in the next video.",
            "dataPurpose": "item-1"
          },
          {
            "title": "91. Building and Publishing Docker-based MCP to AWS ECR (Elastic Container Registry)",
            "videoUrl": "https://epam.udemy.com/assets/67529273/files/2025-08-19_13-04-46-5e1abdd26a78e87b90bb3d29f193ec32/2/aa00ad49ef3bb2588454c900af8d09cdacb7.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wOC0xOV8xMy0wNC00Ni01ZTFhYmRkMjZhNzhlODdiOTBiYjNkMjlmMTkzZWMzMi8yLyIsImV4cCI6MTc1NTc4Nzk4OX0.RkKHqGjO7RShP5qLGIa82OkRRjK8vLQcM8XyohzVtn0&provider=cloudfront&v=1",
            "transcript": "Here we are.\nHere I am logged in into my AWS console.\nYou will probably see a little bit different dashboard, but as long as you're logged in you're good.\nFirst important thing let's ensure that we are in the Northern Virginia region, which is one of the\nlarger Amazon regions in the US.\nSo click Northern Virginia, and the first thing we will do is to create an Amazon container registry\nitem and then push our Docker image to ECR.\nSo if you look for ECR here in the search bar then you will see Elastic Container Registry.\nAnd then you will be able to create a repository.\nAnd here what you will need to do is to come up with a namespace and a repository name.\nSo I will say like my namespace will be MCP And the repository that we are gonna push is the Binance\nMCP.\nAll right.\nYou don't need to worry about anything else here.\nSo let's just go and create this repository.\nOkay.\nSo now this repository has been created.\nIf you select it, you will be able to view the push command.\nThis means that if once you build a Docker container, you will be able to log in to this Amazon service.\nAnd then after building our Docker container, tagging it with our ECR URL, and then pushing it to\nthe Amazon ECR registry.\nOkay.\nSo please keep this piece here handy for the login.\nYou will also need the AWS command line interface installed, and I will point you to a link in the\ncourse resources on how to install it.\nLet's go build and push our Docker container.\nYou can use the AWS Fargate repository, which is very much the same as the simple machine Docker.\nIf you take a look at the Binance MCP.\nThe only change is that there is a fallback procedure that I've implemented, which means that if Binance\nsays permission denied, then we get back with a fixed price.\nOkay.\nWe do this because from certain Amazon regions, if you're not logged in from Binance, Binance will\nrefuse the connection.\nSo it might happen to you too.\nLet's log into ECR.\nI will simply go copy this command and come back to my editor and then paste it here.\nOkay.\nPlease ensure that you are in the Fargate Repository in the meantime, because that's where we're gonna\nwork from.\nWe should be logged in in a second.\nAll right.\nLogin has succeeded.\nThat's great.\nLet's build that Docker image.\nThis is the command Amazon gives us.\nBut we want to make a few changes.\nSo if you take a look at the actual command we're going to use build.\nSo we can specify the platform as earlier.\nAnd also we need to specify the dash dash load.\nSo it loads it into the uh our local Docker okay.\nSo this has completed already.\nSo now what we can do is to come back and very much just copy paste everything.\nSo what the next command we will execute is we will take our local Docker image and tag it with the\nnew URL.\nSo with Amazon URL And once it's tagged, we will be able to push it.\nSo just copy the docker push command and paste it here.\nIt shouldn't take more than a few seconds.\nAnd then you will be able to see that our Docker image is on ECR.\nLet's take a look.\nSo now if you come back to ECR and click Mocp Binance MCP, you will see that the latest image tag has\nbeen landed here.\nSo that's great.\nSo now we have a Docker image that we will be able to deploy as a service before we progress to our\nnext lecture.\nI want to draw your attention again to the fact that this will run on port 8000.\nRight.\nSo this is the port that we will need to make available.\nAll right.\nSo let's build on.",
            "dataPurpose": "item-2"
          },
          {
            "title": "92. Setting up an EC2 Security Group for our MCP",
            "videoUrl": "https://epam.udemy.com/assets/67529277/files/2025-08-19_13-04-47-0c206dd93ae8810fca8dd76f9506e287/2/aa00a5cbf73509b7a3bbf76cdaa04b9b6db9.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wOC0xOV8xMy0wNC00Ny0wYzIwNmRkOTNhZTg4MTBmY2E4ZGQ3NmY5NTA2ZTI4Ny8yLyIsImV4cCI6MTc1NTc4Nzk5N30.dlj-TYuof_VdLCmY576IE86DiXKO20d0Xn4FkUt6eEY&provider=cloudfront&v=1",
            "transcript": "All right, so easier is done.\nOur next step will be to set up a security group.\nThis will be super easy.\nAnd the purpose of this will be to allow this whole system to accept connections on port 8000.\nSo let's come to our AWS and look for EC2.\nEC2 stands for Elastic Compute Cloud, which is Amazon's infrastructure layer, at least parts of it.\nAnd on the left panel you will find security groups.\nEnsure that you're still in Northern Virginia.\nOkay.\nThat's important that we do everything in the same region.\nSo security groups you might have one or more security groups listed.\nDon't worry about those.\nLet's just create a new security group here.\nAnd what we will need to do is add the name.\nSo this will be let's say MCP Access Security Group.\nAnd we can also copy the same name to the description.\nAnd here is what matters is basically the inbound rules.\nSo how we are.\nThese services using the security group accept connections.\nSo let's add a rule.\nIt will be a custom TCP rule.\nThat's okay.\nThe port range is a single port 8000.\nBecause remember if I go to my editor that our MCP is going to listen on port 8000, and we also need\nto specify from which host this port should be accessible.\nAnd I will say anywhere IPv4.\nSo that would very much mean that it's a public port or a public, uh, channel out on the internet.\nSo these are the inbound rules.\nWe also have a set of outbound rules, which means like what services can these, uh services or X access.\nLet's just keep it very relaxed so it has full access to the internet.\nSo let's click Create Security Group.\nAnd that's very much it.\nLet's go on and set up our ACS infrastructure.",
            "dataPurpose": "item-3"
          },
          {
            "title": "93. Creating a Fargate Task Definition",
            "videoUrl": "https://epam.udemy.com/assets/67529271/files/2025-08-19_13-04-45-2c11cf9d06ce42d350674259150e9c82/2/aa003ba4d6a7a19d32a333ae3f9d792380a5.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wOC0xOV8xMy0wNC00NS0yYzExY2Y5ZDA2Y2U0MmQzNTA2NzQyNTkxNTBlOWM4Mi8yLyIsImV4cCI6MTc1NTc4ODAwNX0.05x_VNlPza1FMS6EZAWjp4nQLj3DzVijG8Ha2i7w7ng&provider=cloudfront&v=1",
            "transcript": "Now we are done with both the security group and the ACR.\nSo let's focus on our ECS definition.\nLet's go back to Amazon and look for ACS.\nThis is the Elastic Container Service.\nLet's click it again.\nEnsure that you're in the Northern Virginia region.\nThe first thing we want to create is an ECS task definition.\nSo let's click task definitions.\nLet's create a new task definition.\nAnd from this one this will be fairly easy.\nSo I will be able to say this is the Binance MCP task death.\nAnd here I can specify that I want to launch based on AWS Fargate.\nSo on a completely serverless managed solution and not on my own virtual machines.\nThe architecture should be Linux x86, which is the architecture we built our Docker container for.\nAnd we basically need like maybe a half of a CPU with, let's say two gigabytes of Ram.\nThat's that should be like more than enough.\nOkay.\nYou don't need to specify the task role and the placement whatsoever.\nBut what you will need to do is to get the container name, which will be the Binance MCP.\nAnd also you will need to paste here the repository URL and the image and the tag.\nNow for this I would like to ask you to comment, click or shift click the AWS logo so you have a new\ntab coming up.\nAnd go again to your ECR.\nAnd copy where not even this URL going to the image.\nAnd here copy the image URL which has the the tag tool right.\nSo now I will be able to paste this here.\nYou see.\nSo here is the actual registry and the namespace and my image name and also the tag.\nThis is what we need to have here.\nIt is an essential container.\nIn a task definition you would be able to define like multiple containers.\nBut we only have like one essential.\nOur ports that we want to use will be port 8000.\nOkay.\nSo please keep this, uh, update this to port 8000.\nWe have a single CPU limit or good logging.\nWe don't need to do log collection.\nAmazon has advanced log collection capabilities, but we don't need that.\nWe can go with the default storage, and this will be very much it.\nLet's click create.\nOkay.\nSo our task definition has been successfully created.\nSo let's go on and create our cluster and start our task.",
            "dataPurpose": "item-4"
          },
          {
            "title": "94. Creating a Fargate Cluster and Launching our MCP ECS Task",
            "videoUrl": "https://epam.udemy.com/assets/67529283/files/2025-08-19_13-04-49-125c120b60a72a22635c0f5127558219/2/aa00e4cac51a3e71d9a209a2f50be343b05f.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wOC0xOV8xMy0wNC00OS0xMjVjMTIwYjYwYTcyYTIyNjM1YzBmNTEyNzU1ODIxOS8yLyIsImV4cCI6MTc1NTc4ODAxMn0.8ROtKJgqkxjAH-sY_c25Upkp-nHrGqatQFXgJaW3la8&provider=cloudfront&v=1",
            "transcript": "This here is done.\nSecurity group done.\nThat's definition done.\nLet's create a cluster and start our MCP task inside.\nWe can come back to the Elastic Container Service and click clusters.\nAnd let's create a new cluster.\nSo the cluster will be the basically the serving infrastructure right.\nWe will have a cluster name I don't mind this name.\nWe can specify that the infrastructure is still AWS Fargate right.\nSo we don't need to do anything here and click create.\nSo the cluster might take a little bit to start.\nYou can take a look at this in CloudFormation, which is the place where you can take a look at the\ndifferent resources and what's happening on AWS.\nAnd it seems that the cluster creation has been already completed.\nSo let me go back.\nOkay, here we go.\nMy cluster is up and running.\nSo now let's launch our task on this cluster.\nSo launch task select the task definition family Binance MCP task definition.\nWe only have a single revision.\nHere is the compute configuration.\nSo that's all good.\nIt's Fargate.\nEverything is going to happen automatically.\nAnd here in networking I would like to ask you to set up the security group.\nSo go and find the security group that you created.\nHere is my MCP Access Security group.\nAnd I will just remove the other one.\nAnd the public IP must be turned on because we want to access this task on the public internet.\nSo once you set the security group and kept public IP turned on, you can click create.\nIt will say it's provisioning.\nSo let's give it a minute or two.\nAnd then we're gonna grab the public IP of this task.\nAfter a minute you can click refresh and you will see that it's running.\nAnd if you go into the task and then click networking, then you will find the public IP.\nNow don't open the address because it won't work, but you can copy the public IP and open a new tab\nand just say, I want to connect to this public IP on pay on port 8000 and I want to access the MCP\nendpoint here.\nIt's slash MCP because we are using HTTP right.\nSo here is the protocol.\nOkay.\nSo when I click enter it says some error which is great.\nThis is exactly what we wanted to have right.\nSo our MCP servers is up and running it.\nJust one serve standard HTTP request up there.\nSo keep your public IP in the clipboard.\nAnd then we can go and run the MCP inspector and connect to this endpoint.",
            "dataPurpose": "item-5"
          },
          {
            "title": "95. Testing the AWS Deployment with the MCP Inspector",
            "videoUrl": "https://epam.udemy.com/assets/67529275/files/2025-08-19_13-04-47-b2f895d9ee9081765b1b3d54eda3a73a/2/aa004d63ef3845fc0a775a3a89e09c697fed.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wOC0xOV8xMy0wNC00Ny1iMmY4OTVkOWVlOTA4MTc2NWIxYjNkNTRlZGEzYTczYS8yLyIsImV4cCI6MTc1NTc4ODAyMH0.qy_gASqWJ46PdWNyY6NtMKkOIebEom4-M70hyz_Yy5s&provider=cloudfront&v=1",
            "transcript": "Come back to your editor or terminal and execute NP model context protocol inspector so we can run the\ninspector.\nHere we go.\nSo now what we want to do is importantly keep everything at HTTP.\nSo it won't be a secure connection that we want to have.\nThe reason for that is that if you want to build a secure a secured MCP, then you would need to set\nup a certificate for secure connection and many other services that that play together to make your\nconnection secure.\nSo we've just taken the simple approach here.\nLet's go and add your IP like ensure first of all that the Streamable HTTP is set to streamable HTTP.\nI have added my IP port 8000 should work and MCP should work.\nSo I will be able to connect and it has connected.\nAmazing.\nSo if I go to tours I can list the tours and here is my get price super.\nSo if I say like BTC and run the tool, it says that it's 100,000 for instructional purposes only,\nwhich means that my Fargate won't be able to use Binance without authentication.\nBut you get the point, right?\nSo congrats!\nThere were a lot of things that need to be glued together, but here we are with a working SAP server\non Amazon.\nThe skills automatically.",
            "dataPurpose": "item-6"
          },
          {
            "title": "96. Deleting AWS Resources",
            "videoUrl": "https://epam.udemy.com/assets/67529285/files/2025-08-19_13-04-49-096cf5a89b12eb74e4667f4900ce0aa8/2/aa00843ec86ccf11832db8fc372fdfab1a48.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wOC0xOV8xMy0wNC00OS0wOTZjZjVhODliMTJlYjc0ZTQ2NjdmNDkwMGNlMGFhOC8yLyIsImV4cCI6MTc1NTc4ODAyOH0.gQWauVN3jgQuyyia2SvKRBg5tO8T9fwovW55h8kdanE&provider=cloudfront&v=1",
            "transcript": "The last thing I want to show you is how you can terminate and delete all of these resources.\nFirst of all, come to your cluster and stop the tasks.\nSo select the first task and just say stop.\nOr you can also say stop.\nAll you need to type in stop all tasks.\nSo we're just stopping all of the tasks.\nThen I can go back to my cluster and delete the cluster right.\nI will need to type in delete cluster name.\nMy cluster has been deleted.\nSo that's good.\nI can come back to the container service and delete the task definition.\nI will actually click into the task definition and they register the task definition.\nSo now this has been de-registered.\nEven though I still see my task definition here is gonna go away in a minute.\nSo on the x we are good.\nIf I go to ECR.\nI can go and take my repository and delete the repository.\nGood.\nAnd the last step I can just go and create my security group.\nOkay.\nSecurity groups.\nLet's select the MCP access security group.\nActions.\nDavid.\nSecurity groups.\nAll right.\nSo once you are done with that, then you shouldn't expect any more costs with Amazon.\nBut take a second look once you've deleted everything.\nOkay.\nSo congrats again for putting this all together.",
            "dataPurpose": "item-7"
          }
        ]
      },
      {
        "title": "Section 17: Industry Expert Interviews",
        "items": [
          {
            "title": "97. Introduction",
            "videoUrl": "https://epam.udemy.com/assets/65546067/files/2025-05-30_11-00-53-b28c1543901dfadff71c532d843a56b3/2/aa0022354b57c3961e6118efe27eef3d3ab6.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0zMF8xMS0wMC01My1iMjhjMTU0MzkwMWRmYWRmZjcxYzUzMmQ4NDNhNTZiMy8yLyIsImV4cCI6MTc1NTc4ODA0MH0.6aj3J8_19c6H0wZkhL4OOkIyhhM6KtjQwLUMjdMfMig&provider=cloudfront&v=1",
            "transcript": "Hi.\nIn the next video, you will see a longer interview with Guillaume Roy, who is an expert on RMC.\nHe is the original author of MCP adept, which is a super successful open source MCP framework.\nAnd this framework got integrated into Huggingface.\nSo now his framework official Huggingface MDP framework in small agents hugging faces agent library.\nHe also worked quite a bit with real world MCP applications.\nSo I asked him to join us in this course and just share his story where first about MCP adapt and how\nto make a successful MCP based open source piece and what challenges there are.\nAnd then from around I say like the second part of uh, of the video, like his suggestions about what\ncan go wrong with MCP, how to manage prompts, uh, tools versus the different functionalities, the\nstate of the Union of MCC, and what to pay attention to if you want to build your own production.\nReady MCP.\nSo I'm super excited to have him here and you see the whole interview in the next video.",
            "dataPurpose": "item-0"
          },
          {
            "title": "98. An Interview with Guillaume Raille, the person behind MCPAdapt/HF Smolagents MCP",
            "videoUrl": "https://epam.udemy.com/assets/65546511/files/2025-05-30_11-12-32-d56c8f61a1ca707b35d0ef82b4d8f1e1/2/aa003947495e5e8c204f46fac1db2da1ac2c.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0zMF8xMS0xMi0zMi1kNTZjOGY2MWExY2E3MDdiMzVkMGVmODJiNGQ4ZjFlMS8yLyIsImV4cCI6MTc1NTc4ODA0N30.jeLXXcRH7Vl0Nh8eSCh7TZlJczDTXROt8jIjV8Ki9rc&provider=cloudfront&v=1",
            "transcript": "So welcome everyone.\nI'm here with my co-founder of substance AI and the original authors of the open source project MCP\nadept, and also a contributor to many open source projects such as Hugging Faces, Small Agents and\nCrew AI and Anthropic Python SDK.\nWelcome to the course.\nHi.\nThank you.\nPleasure for being here.\nLet's just start with a few personal questions and questions about your professional past.\nSo can you just start by telling us a little bit about yourself and your company?\nYeah.\nFor sure.\nSo I'm Guillaume, I'm a data scientist by training.\nUm, I have worked for the past five years, uh, developing solutions in data science and data engineering\nfor banks and insurance in Switzerland.\nUm, and I also have a small background in NLP research.\nUh, I did a bit of a thesis around Transformers, uh, when it just came out around 2017.\nUm, I am also so as you mentioned, the CTO and co-founder of AI, where we help consultants manage\ntheir business, relationships and otherwise.\nSo yes, I've been active around the MCP protocol to develop open source solution since the very beginning\nin November 2024, and I created MCP adapt, which I hope we will have a bit more time to talk about\nin this in this interview.\nYeah, we will definitely.\nUm, yeah.\nThanks.\nSo you've been, uh, on this highway for quite a while.\nCan you tell us a little bit how your experience with working with LMS and agents shaped your perspective\nof the challenges with LMS and agents?\nYes.\nSo I've been able through this, this past five years, you know, to see, um, a few use cases in\nproduction and one of the most preeminent experience I have, probably with the LMS in production,\nis that this use case I developed in, in insurance company where we work.\nWe work closely with contracts.\nSo insurance contracts.\nAnd the goal was to extract a graph representation of that contract.\nIn order to understand in the case of a claim, if the customer is covered or not covered based on the\ncontent of the contract, and to quickly make a decision about that.\nUm, and so like developing this solution, I saw like a lot of like, uh, so the, the help that LMS\ncan bring, uh, in making this, uh, faster process.\nBut at the same time, I also saw, like, a bit of other drawbacks and the dangers of having this solution\nin production, such as the fact that, you know, it's not a completely reliable it's not like a fully\ndeterministic, um, so, like running several times the same, for example, will give you different\nresults.\nAnd I think it's really shaped also like the way I'm now developing my, my startup.\nAnd I really like this philosophy of keeping things really simple and probably also like maybe use agents\nmore as a last resort and focus more on like AI workflows as much as I can where like, I would more\nlike program the pipeline of what I want to do and then bring AI pieces in the middle of it to support\nthem before resorting to agents that would sort of like magically give an answer to everything.\nUm, it's a bit following as well, like probably the guidelines from and the process that anthropic\nmakes about like best use of, of agents in production that they've seen.\nThat's a great reference.\nSo I ensure that we, uh, we put this to the course resources, the resources to talk about.\nSo, so yes, you you had quite some experience with, uh, with these topics.\nUh, can you remember what the specific moment or project was when you thought that there has to be\na better way to do this and started working on MCP adept.\nSo like, what was your aha moment here.\nYes.\nSo to come back to adapt a bit like the inception.\nUm, I think so.\nAt the beginning of MCP, I saw the potential, you know, of like having MCP servers that could be\nused across in different places.\nUm, and at the same time I saw something else.\nRight.\nWhich is like the, the, the, the rise of, like, so many agentic frameworks, uh, you had, you\nknow, like, uh, of course, hugging face agents.\nBut also I also, uh, had one also had one, I mean, and today there are so many of those.\nUm, and, um, I was like, seeing that each of them implemented in a different way the, the tools\nand the tools.\nUh, that was, uh, a bit similar to what MCP server were providing, you know, like at least part\nof it is tools.\nUm, but it was not immediately compatible.\nSo all of those frameworks that were not supporting MCP, um, and since they had all their own implementation,\nI thought, okay, maybe we could do something here.\nWe could have like some sort of adapters that would bring these tools into this different framework.\nAnd that's where I started to work on adapt.\nActually, it was not a very long work.\nI just spent the weekend on it, um, and uh, and reading it on read it, I suppose, like the committee\nwas very happy to, to see this project and to see that they could use Nmcp, uh, MCP servers because\nthere was already like hundreds of MCP servers available out there into their favorite agency framework.\nAnd they were very happy to jump on the project and start to have developing it, but also like putting\nstyles on it, I guess.\nAnd that's how it all started.\nYeah, yeah.\nAnd then and as you just said, it became a very successful.\nBut before we discussed the successes, uh, just for those of, uh, those of the students who are\nnot familiar with MCP adapt or didn't, uh, check that part of the course where we had hands on experience\nwith MCP, adapt.\nUm, can you can you explain what MCP adapt solves and and how just on the high level.\nSo it's really just it's very similar to what I said, but essentially like so we create adapters that\nconverts the definition of um, the MCP server tools.\nSo uh, you know, like MCP use JSON to communicate as part of the protocol.\nAnd so this JSON coming in and coming out is usually not directly compatible with the particular agent\nframework, but we work only with Python in MCP adapter.\nIt's only like a Python agent framework.\nUm, but so it's not directly compatible.\nAnd also like each agent framework that define their own tool class.\nAnd because they define their own tool class, um, and also like specificity on how to use them within\nthat framework, um, you need to sort of like adapt a bit the so where the MCP, adapt it, adapt a\nbit the MCP tool to work with that framework.\nAnd, and so we make it very easy to create adapters for each of those different frameworks such that\nit's seamless for the end user to use MCP tools for, for for the given for any given agent.\nYeah.\nMakes sense.\nAnd and it seems that, uh, it was a good idea because MCP had gained traction incredibly quickly.\nAnd you have many contributors.\nWhat?\nWhy do you think it it resonated so quickly and so strongly right after release.\nSo, um, I think so.\nA few things.\nRight.\nLike, I think it brought really some things to, to the community that didn't exist before.\nSo like people were very happy, for example, to start using it, uh, with, uh, I don't know, like\nlong chain or with or with small agents where before they could not even use MCP.\nSo, you know, there was this, this gap between the agent framework capabilities and all the tools,\nthe hundreds of tools available on GitHub.\nSo, so people were very happy to, you know, just be able to use MCP.\nI guess that that brings a bit of interest.\nUm, but also like, uh, sorry, I lost a bit track of the question Yeah.\nThe question was, uh, that like, why?\nWhy do you think it became so successful?\nBut you were actually answering the question.\nSo so you said that, uh, people were happy that there were, like, already a bunch of, uh, tools\nand offerings out there, and and it needed a bridge, if I understand correctly, to, to plug them\ninto these frameworks.\nYeah.\nYes.\nAnd also like maybe some, some other point on this, like what made it also very successful is of course,\nthe integration into the various, uh, frameworks that got integrated to like small agents and um,\nand I so this really brought a lot of people, you know, having for example, small issues with MCP\nadapt or with MCP in general that would start to post issues on the original framework.\nBut then they realized actually the implementation is done through MCP.\nSo they would come to MCP, adapt as well.\nEither they help quickly with with proposals or also to.\nSo that also brings a lot of uh, of popularity as well, um, as, as a framework.\nAnd of course, I mean the general MCP sort of hype and general media exposure, but also a lot of attention\nto this project as well.\nYeah.\nAnd then and then the Hugging Face legends, uh, collaboration.\nWhen did even that far that, uh, that now in Small legends MCP adapt is the official way to uh, to\nuse MCP to us, which is a massive validation, uh, just as an inspiration for everyone who who is\nconsidering to, to, uh, set up an open source project.\nCan you share a little bit about how did that partnership come about?\nWhat Hugging Face wanted to build, if they wanted to build your own?\nAnd, um, how you convince them if they needed to be convinced that MCP adapt is the right approach\nto go?\nYes.\nSo so again, the MCP adapt is really about the fact that there was no support for MCP inside of agents.\nSo like, um, I looked around like of the different, insurance implementation that were there of the\ndifferent agency frameworks that were available.\nAnd then I saw that the hugging face seems to be seem to be quite a popular framework.\nI mean, it was getting traction at the time, maybe 5000 or maybe a bit more stars.\nUm, and uh, and it didn't support MCP, so I created an issue there.\nI asked, you know, like, uh, what about adding support for MCP?\nI thought actually there was already maybe an existing issue about needing MCP there.\nUm, and so then I commented, you know, I'm building this this solution, MCP, adapt.\nUm, we have some code that already works with more regions outside of the framework.\nUm, I would be very happy to contribute to make it work directly within the framework.\nUm, and so we started to discuss with, uh, you know, the common theme of, uh, of hugging face\non this particular issue, uh, on, on how we could implement that and how we could integrate it,\nuh, inside of the, of the framework.\nUh, and then, yes, it simply went as a as a simple question like, can I would it be okay to have\nit as an extra dependency?\nSo at Mcpp as a dependency to smart agents.\nAnd the answer was just yes.\nNo problem for him because I mean you have to think as well that for them it's quite good because it's\njust a very low effort for them to integrate Mcpp because I was there, I would do all the work.\nThey would just have to review and make sure that I'm not doing, uh, something too bad.\nAnd they would just, just merge it.\nSo, uh, so yeah, it went, it went quite smoothly, actually.\nOh, nice.\nYeah.\nBut it still requires some trust, right.\nThat what you're what you're pushing in or what they're merging.\nIs that that legit code.\nSo so so they reviewed they reviewed for sure.\nNow.\nLet me add this as well.\nI mean usual uh, usual open source collaborations.\nNice, nice.\nThat's that's uh.\nYeah, that's very that's very, very inspiring.\nUm, so let's just go down to the, nasty details.\nSo when as you worked and implemented and worked with MCP adapter, integrated it into hugging face.\nWhat, uh, what you would what would you say was the nastiest incompatibility you've had to solve between\nMCP servers and and agent frameworks, for example, what assumption do these frameworks make that just\ndon't work with the reality of MCP servers?\nUh, I think the most difficult part and maybe like where we, we spent a bit more time to, uh, to\nwork on, on the, on MCP adapt is the, the fact that, uh, some of the frameworks that don't support\nthe async, uh, API of Python that I think, um, and this, this and on the other side, the Python\nSDK, uh, of anthropic, uh, the MCP official Python SDK only supports async.\nSo, um, we have to.\nYeah, juggle around a bit this, uh, this These limitations and make sure that still working seamlessly\nin a sink environment, we could make the async calls separately and make sure that Mcpp works even\nin this environment.\nAnd some other like I think like complexity we've seen, but it's smaller issues.\nSo all of the things that are about making sure the input and the input outputs match between the JSON\nrepresentation and then the tools in Python, I would say it's lesser of a challenge, but still something\nthat needs to be done on a case by case basis for each of the agents.\nUm, and then also one of the one of the issues we've seen as well is, for example, like, uh, Agent\nFramework not supporting the full, uh, JSON specification implementation.\nUm, so like, uh, you know, there was some issue with JSON references, for example, which is like\nsomething where you can reference different parts of your JSON within the same JSON.\nSo this we had also like some smaller issues I would say, but still something to uh, to resolve for\nfor all of the different frameworks.\nSo you have resolved quite a few issues when, when, uh, agent frameworks want to work with MSPs,\nbut also today, like now, MCP support is more widely and widely adopted.\nWhat would you say?\nLike what makes MCP adopt different?\nOr if I, if I, uh, consider using MCP adapt, then obviously on one hand it might add an extra layer\nof complexity on on the top of my code.\nUh, but it also solves a bunch of incompatible issues and problems that you, you just discussed.\nSo why would someone choose MCP adapter?\nWhen would someone choose MCP adapt over, for example, a long chains MCP integration or just just\ngoing natively through the LMS API?\nYeah.\nSo I mean, I think um, and I think today more and more the answer is probably like go directly through\nthe, the agent framework if you can.\nUm, one of the the advantages of SMTP, I believe, is that you can quickly.\nSo using the same MCP code.\nQuickly go through many different implementations.\nSo for example if you want to compare the performance of your MCP server with many different agent frameworks\nthat quite simply and establish, for example, some sort of benchmark, because there are some differences,\nyou know, like if you look at small agents, for example, one of the favorite way to use agent is\nwith this, what they call this code agent, which is actually writing Python and then running it instead\nof, um, you know, directly, directly using the tool use as it is in the other frameworks.\nSo there are differences that you might want to try with different frameworks.\nAnd uh, and that way you can quickly see.\nBut otherwise, uh, I would say like uh, it's probably always better to use integrated solutions.\nMCP might be the solution in the background.\nThat actually makes sense if it works for that framework.\nBut but as an end user, you might not really, um, be, uh, seeing it.\nI see, I see.\nAnd, um.\nSo now you are your current venture, is I.\nWhat you do is, uh, you build AI powered Googlers to keep track of business relationships.\nAnd, uh, can you share a little bit about how your experience with MCP adapt, have your company or\nhow MCP adapt fits into the whole vision or the product itself?\nYes.\nAt the moment it's more like in the vision.\nWe did not get to the MCP part of our product.\nUm, so we are developing the product.\nBut as I was saying at bit at the beginning, like my philosophy right now is to always try to focus\non keeping things simple.\nUm, so I didn't introduce like the agent part yet or the MCP part.\nWe have like plans for it and we want to integrate it, but so far it's mostly like workflow of AI.\nSo like we have the different steps that we run in the pipeline and some of them are using LMS, but\nit's just the LLM course.\nAnd then we we get it and we use mostly like structured output to make sure everything works correctly\nin production.\nUm, that being said.\nSo we have plans for MCP.\nUh, one of the ideas that we are doing with the startup.\nSo, you know, like since it's a system similar to AWS, we want to capture the context, the business\ncontext of people and create this, uh, memory for them and, and expose this memory through MCP.\nSo as an MCP server that would be available for you to bring into the MCP client that you want, including\na cloud app or the different places to to bring the best, uh, of, uh, of, of your business data\nand business context there.\nUm, so that's, that's a bit like where we are.\nAnd so MCP adapt as a solution would probably not be something that we use directly, but definitely\nan Agentic framework around MCP is something that that we could use to help, for example, to find\nthe relevant business context based on some queries, um, and things like that.\nBut it's more part of, of our vision than, um, our execution today, Okay.\nOkay.\nUm, so now you mentioned, uh, like that you would definitely, uh, use an agent and maybe we can\ngo down to, to, uh, to that place where things can go wrong using Mcb's.\nUh, can you share one integration either with MCP, adapt or just in general with MCP?\nIs that look simple on paper but turned into a nightmare?\nHave you encountered such um, so I mean, simple on paper and nightmare?\nI think so, maybe not really, because MCP really makes, uh, makes it very, very easy.\nAnd I think, you know, like so you have, of course, like the tutorials where everything works and\neverything is simple.\nUh, you have then the reality.\nBut, um, I found with MCP, like at least having something working locally is quite simple, like\nthere is nothing and especially if you use like a fast MCP API that is now in the Python SDK.\nUm, it makes, it makes it quite easy to quickly develop an SMTP server.\nI think where it gets tricky is when you talk about like production, usage, production, deployments,\nmaybe nowadays a bit if you talk about authentication, which are newer topics, I think like that's\nwhere things becomes really tricky.\nUm, it was actually very tricky at scale because like that's also why the even the specification of\nMCP changed, you know, like uh, having like stateful, uh, MCP servers that needs to keep a state\nabout every users, uh, for, for large scale application is very costly.\nAnd so providers were really not happy about that.\nStarted to talk uh, on the, on the MCP protocol, uh, GitHub repository.\nAnd then they made this change where like, you know, there is now this HTTP, which makes it possible\nto have stateless MCP servers as well.\nUm, so I think that's where it becomes tricky.\nLike on the deployment part, on the authentication cards.\nHaving a simple MCP running anything is also still quite simple, and also something that can become\ndifficult over time is managing a large amount of tools that you have.\nIf your application is quite big, the application you are trying to wrap with MCP is quite big, and\nI think this can also become become tricky over time.\nAnd that's where I recommend again to start.\nSimple.\nSo maybe like just a few tools at the beginning and try to see like if also like also quite simple even\non description of the tools because it's also an element that is quite key to um, to make sure that\nthe LM is using your tools in the right way.\nYeah, yeah.\nLike really, as always, I would say in computer science, that simple is sort of like the the way\nto go.\nYeah, yeah, yeah.\nIt's, uh, it's never simple in production.\nUm, okay.\nA last word about MCP.\nAdapt.\nSo where, uh, if you look at your roadmap, what what do you see?\nWhat's next for MCP adapt.\nUh, yes.\nSo the on the roadmap, we so we wanted to integrate a bit like the most recent, uh, feature that\nwere developed by the protocol.\nSo like one is the authentication app is a big topic on this.\nI did a bit of research as well on how we could do that, and I think it's something we would be able\nto bring soon.\nWe've just released the HTTP support, so this one is quite seamless, uh, I would say, and was quite\neasy to add.\nUm, then so there are a lot of discussions that we had with the various agency framework on supporting\nmore than just the tools, because at the moment it's just about tools.\nBut you probably know also from the class, the protocol is not only about tools, also about resources,\nuh, sampling and prompts.\nAnd um, um, so we are having long discussions on the framework side, but also on how resources could\nbe used.\nAnd there are some maybe we're going to come back to this in another question.\nBut about resources is a tricky.\nTricky, tricky way because it's not always very clear how to use them in the end applications or how\nto leverage them.\nUm, and uh, yes.\nSo maybe also like finally on that vision, like maybe what we wanted to do is the, um, maybe to convert\nit more towards like an MVP client, uh, because this is where the direction it's taking in a few of\nthe frameworks that we have integrated with.\nAnd this is a case for Korea and small agents, they want something more that looks like an MVP client\nto them.\nAnd not only do those tools, but also like, uh, leverage all the other features of MSK.\nYeah, yeah.\nAnd this is.\nYeah, that's um, that's exactly what I wanted to, uh, ask, uh, ask you next is that, uh, also\nhere in the course, students know that usually we use tools because tools are like, it's the easiest\nto understand and and also probably the most useful.\nBut as you, as you said, the MCP protocol expands beyond tools, so we covered here in the course.\nAt the time of recording the covered resources and also prompts.\nAnd we discussed quickly, uh, sampling capabilities.\nSo from your perspective, how important are these, uh, features compared to, to us and how how well\nadapted are these?\nYeah.\nSo, so, so I think there are great features.\nUm, and um, of course, tools is probably like the most preeminent at the moment, but it's also like\nthere's also a history to that because like only a very few few amounts of clients support, uh, other\nthing than tools.\nSo if you want an MCP server developer and, you know, like there is only like a desktop app that supports\nthe the prompts or only supports the, the resources, then there is very limited use case where actually\nyour resources would be useful for others, you know.\nAnd that's the case if you look MCP implementation for example, I think today in VSCode, in cursor\nin and in many.\nI'd just import tools so all of the rest is not going to be used.\nSo that's that's the first thing.\nEven though of course they can be useful.\nUm, so in terms of importance I would place tools probably first because just because of that then\nso in terms of the use of the other ones.\nSo like resources I think can be um, can be useful.\nUm, it's, it's actually used in some of the implementation, I think, around managing, you know,\nlike, um, uh, files or context that's too big to fit into the LM itself.\nLike, if you think about the file, you know, like sometimes you just want to manage the file itself,\nbut you don't want to really send the content of the file here.\nIf I give you an example, like to reference maybe some part of the file or something like that.\nSo that's where I think resources are uh, are, are useful.\nUm, but if we come back a bit to like why resources are tricky for MCP.\nAdapt is because resources, the way they were designed by anthropic and how it is done today in the\ncloud desktop app.\nIf you use resources as an MCP server, what you will get is a list of things to select from as end\nuser, and then you would put them inside of the of the of the context manually.\nSo you would say my my MCP server provide like file a file B file.\nSee you as a user can select file A and put it in the prompt.\nAnd then the prompt will be able to use a to answer a question.\nYeah.\nUm where it's tricky with MCP adapt is, you know, we don't integrate directly with an end application.\nSo we don't directly integrate with the.\nEnd user.\nWe work with an agent an agent.\nSo there is like the the agent and there is MCP adapt.\nAnd the agent integrates and works with MCP adapt to figure out answers for the user.\nRight.\nAnd in this um, architecture, it's not clear how the agent should be using the resource, right?\nShould.\nFor example, should we ask the end user to select resources?\nOr should we let the agent make a decision on which resources to take by itself?\nSo this creates some discussions like that that we are having.\nAnd that's why like at the moment we we do not support resource as well because like there is no clear\nguidelines on how an agent would actually interact with those resources.\nAnd it's not a standard way defined by the protocol.\nYeah.\nSo you're saying that yes, that's certainly a limitation in uh, in cloud Desktop.\nI encountered that too, that you, you need to select resources one by one on the UI.\nAnd, but you gave a good example of like, uh, what resources can be used for.\nNow what about prompts have you like we had a kind of, uh, some confusion in the course.\nUh, and I had a hard time explaining why prompts are useful.\nAnd what's a good use case for for prompts I've been able to to find a few, but I would just like to\npick your brain about like, what were some of the good use cases you encountered when prompts came\ninto play?\nSo good use cases.\nI'm not sure really.\nI've seen so far.\nI know that, uh, so MCP protocol was really developed together with the the Z editor in mind, the\nz ID in mind.\nYeah.\nYeah.\nIn the course.\nBut so, um, how they use it there and also like, it's a bit like the rules maybe, you know, like,\nyou know, like there is this list of, um, rules are more like guidelines for the LLM, I guess.\nBut in Z they really have a prompt library, right?\nLike where you provide some prompts for your user to be able to perform other tasks, uh, quicker and\nnot have to redefine the prompt from the beginning.\nYeah.\nSo that was I think that's really the idea of prompts.\nAnd as an MCP server provider, maybe you have found some ways of, uh, working better with your particular\ntools or way that's prompting in a different way would make your, um, your, your set of tools works\nbetter with the, uh, and they wanted to provide this opportunity for people on the server side to\nbe able to recommend, uh, some way of prompting their, uh, their server.\nAnd so you get a prompt as an end user and you can even provide like a template template it prompts.\nRight.\nSo like you, you can put values so the end user will just have to put values.\nAnd maybe this would do like uh, something uh, great on its own for the given MCP server.\nSo that's, that's really the, the point of, of the prompt.\nThanks.\nThat's uh, that's a great aspect.\nAnd it's very much in line, uh, of what we cover here in the course.\nI'm happy about that.\nUm, and talking about providers.\nSo you if you, if you take a look at your, uh, A GitHub page.\nYou you say that, uh, there is a warning which says like, be cautious because there are like a dozen\nplus MCP servers out there.\nAnd you, you want to ensure that you only use MCP servers that you can, uh, you can trust.\nAnd they are, like, production ready.\nSo do you have a guess that if you take like a random sample of 1000 MCP servers, like what proportion\nof them is production ready versus only tech demos or just sandbox projects?\nOh, probably.\nWell, uh, I would say, yeah, probably 90% is not production ready.\nI would say, um, but also like I think the longer you wait, the longer the server becomes a bit,\nuh, even less reliable because, um, it's often like, you know, weekend projects or like, uh,\nquick, uh, MCP server done, uh, on the side.\nUm, and when that's the case or like, maybe it works like on the same day it's released, but there\nis like sometimes 15 between the, for example, the, the product it's wrapping and the server itself.\nSo like it starts to work less and less over time.\nUm, now I would say overall, from what I've seen here, probably 90% is not production ready.\nIt doesn't mean you cannot use them, but it means that probably you need to be a bit careful when you\njust, uh, bring something from GitHub.\nUm, you know, in particular because and that's also why we had this warning, because it's, uh,\nso in the case of a, of a local server, you're already giving the permission of the server to run\na process on your computer.\nRight?\nSo you have to be mindful of that.\nAnd it's really like, uh, do a lot of harm on your computer if you're not careful.\nBut also like, we actually we had a bit of a, uh, an issue in that at some point that we solved by\nby now.\nBut, uh, where we were enabling, uh, through the way we, we wrap the tool, uh, to have the SSC,\nMCP server.\nSo like a remote MCP server executes some code within the MCP adapter.\nAnd so we we solved we solved that issue right now.\nBut we added that warning at that time because, um, you might not be expecting from a remote server\nto run some code on your laptop.\nYes, certainly.\nYeah.\nSo so we added that warning at the time.\nI would still be very careful about that.\nUh, adding NCP, MCP servers without really watching, you know, like, so there are the official\nimplementation, which are usually great.\nLike if you look, for example, the GitHub MCP, you know, like some of those that are really, uh,\nof great quality and maintained and they have a team behind them.\nSo like it's really great.\nBut um, but also like there are a lot of just, uh, single single developer MCP server that were just\npushed one night.\nAnd actually I have some of those, so, so I know what I'm talking about.\nBut yeah.\nSo like it's just like slowly drifting on, on, on GitHub and the are probably not super reliable.\nOkay, so you need to be cautious.\nUm, yeah.\nAnd we are adding to this statistics because like, uh, students of of this course are publishing MCP\nservers and deploying MCP products, uh, by the minute.\nSo I mean, I mean, it's great, it's all very great.\nAnd uh, and they can be used and I'm not saying you should not use them, but I'm just saying that,\nuh, you know, like, it's not a production.\nReally think that it's also in production for, for my startup.\nRight.\nSo yeah.\nYeah.\nAll good, all good.\nUh, I think we are on the same page here.\nUm, so let's talk about, um, let's talk about a little bit about how, what problems come up when\nyou want to put MCP to production because, um, in an online course, usually everything is like nice\nand shiny.\nBut can you talk a little bit about the caveats and the failure modes that that you wouldn't expect\nan online course like a standard online course, uh, warn people about when developing mttps?\nSo the deployment, I think, and the hosting is fairly new in the environment of, of MCP, like the\nstandard way of developing MCP for, let's say, six months after launch of MCP was just to push something\non GitHub.\nUm, and or maybe like if you are using a Python would be push on PyPI as well, so people can quickly\ninstall them with UX or with a similar pip commands or like on as an npm package so that they can do\nnpx as well.\nBut, but this was like more like the standard way of deploying MCP servers.\nBut nowadays I think it's going more and more toward like hosting MCP server and in particular, if\nyou're a company or if you want to run like MCP productions, you don't want people to start having\nto, Do you have the right dependencies installed on their site?\nHaving you've installed or having npm installed all those kind of things?\nYeah, yeah.\nYeah, exactly.\nUm, so that's where it's going to work.\nAnd for that, like there are a few now companies that are starting to provide some easy way of hosting\nSMTP servers.\nSo I've seen some of them, um, which makes it the whole thing easier.\nUm, but otherwise.\nSo like if you don't use those providers then it's still quite tricky, I think, to host reliably MCP\nservers for, for for your, um, for your customers at scale at least.\nSo if you, if you remain in small scale, I don't think you would have much issues.\nOr having an FTP server working in uh, with SSE is not that complicated.\nStill, I think one of the big challenges that there was was authentication.\nAnd now it's starting to become more and more solved.\nThere are examples, for example, on the on the on the Python SDK.\nNow that shows a bit how it works.\nI don't know if you covered the class, but authentication is usually Really quite essential for an\nSMTP server in production, because most of the tools that you want to use, they have some kind of\nconnection with either the person and the permission you want to give are always more or less dependent\non the user.\nSo.\nSo here we have other things.\nSo that's kind of like also one of the things tricky.\nBut that will become a thing in the future.\nUm and yes and if you want to to, to scale it I think yeah, it becomes tricky as soon as you want\nto start to like, distribute it over, maybe a cluster of machines or this kind of things.\nBecause because of the stateful nature of the stateful nature of the, of the server having like some,\nyou know, like for example, you cannot just put it in a lambda function and, and having it's running\nat scale for all of your users.\nBut you would need to maybe have a machine that runs for a longer time to cover, like the full extent\nof the session, because a lot of the SMTP servers, they take time to run the the tool command and\nthis kind of things.\nthink so, yeah.\nUm, so that's maybe that's a challenge, but I think they are they are coming more and more, uh,\neasy and uh, and they will they will simplify in the future for sure.\nMaybe also like I think one of the questions maybe you will have later, but like around like monitor\nmonitoring as well as the others.\nYeah.\nOkay.\nLet me reflect to to your answer first.\nIt's um definitely I think authentication is at the moment tricky.\nAnd I'm saying it from a point of view that I, I need to explain it, uh, to people and, uh, and\nit's like, that's, that's, I think the most sophisticated piece of the course at the moment to,\nto set up authentication.\nBut fortunately, uh, of course, it, um, it works.\nAnd, and what you just said is that basically, uh, the challenge is like most of the challenges that\nwe have with Mick is, is very similar to, to the challenges that we have with, uh, with any stateful\nweb services like so, scalability and maintaining state and ensuring that the client always is the\nyes.\nThe difference is that the stateful issues and like with web servers where like something so common\nthat, you know, like we grew into a lot of solutions today that we have for those, but it's very\nnew.\nSo there is not like a so much like hands.\nHands on as you would get for or like a.\nYeah.\nUm, you are not helped as much as you would get for like a developing a web server.\nYeah.\nOkay.\nAnd what if we go to the, uh, to the client side?\nSo even if I'm a cloud user or if I, if I use, for example, MCP adept or any, any framework, and\nI want to integrate like I come up with a use case to let's say I want to build my personal assistant\nand I'm just, I'm just gluing in my Gmail and to do list and calendar and notion and whatever.\nAnd I come up end up with like 20 Mbps connected to my client.\nUh, what challenges do you see there?\nYeah.\nSo, I mean, there are some obvious challenges that I've already seen is like in a lot of the MCP client\nimplementation, there was like some, um, you know, like even name conflicts between the tools,\nyou know, like, if you name the tool the same in the different, uh, in different MCP servers, uh,\nthen you can have the issue that the name clash and then you don't know which tool is going to be invoked,\nuh, like for a given for a given name.\nSo that that's one of the obvious, I guess, that you could get um, apart from that, I think as the\nnumber of tools starts to scale, I think the LMS itself try to struggle.\nAnd this really depends on the LMS that you are using on the client side.\nUh, so I think with cloud, you can probably like cloud being one of the best, probably at two usage\ntoday.\nYou can you can still manage with quite a few tools, but maybe some like Maybe it gets to a lower limit\nif you if you go with open source, uh, LMS.\nUm, this I must say, I don't have so much experience myself with.\nBut, uh, but it seems to be like that.\nThat code is a bit like the the winner on tool usage and that, uh, that it will scale better.\nSo and that's where like starting simple is always good.\nSo like start with only a few tools and then start to increase them so that you can see a bit like where\nis the limit on this.\nUm, uh is important because uh, because at some point I imagine the element just gets confused about\nwhat to use, not to use and, uh, start to just making calls a bit randomly.\nSo.\nAlso, I guess when you start to have like thousands of tools on your, on your, on your arm, you\nknow, like even just asking a simple questions where you might not expect that it would be used.\nWe still trigger some kind of tool that you were not expecting.\nOh, no.\nOkay.\nThat's, uh.\nYeah.\nI mean, if you have a few tools, it's still quite easy to have this mapping in your head.\nAs I will ask this question, it's going to use this tool.\nI know, you know, but uh, but as soon as you start to add a lot of different tools, it becomes a\nbit more complicated.\nYeah, yeah, I can imagine.\nAnd and how would you go about it if, uh, even again, either closed or, uh, client framework,\nif you have a bunch of integrations and you, uh, you want to debug like something goes wrong and you\nwant to debug it, how would you monitor or, you know, like, go with the moment.\nI don't know if there is some great monitoring solution.\nUh, early on on the MCP, uh, protocol, my early works were also like, um, uh, trying to monitor\nwhat's, what's going on.\nAnd I've, I've actually also another open source project, which is quite small.\nUm, I think it's called open MCP proxy, Well, it was like almost six months old or maybe right now.\nBut, um, so the idea was that this MCP proxy would sit in between the client and the server and would\nbasically be able to listen.\nWhat are all the so the client calls that comes in and what are their answers from the server?\nUm, and um, in one of the solution I built at some point, I used that as a way to log.\nSo all of the different calls, and especially if there are errors, you know, like and I would use\nthem then I quite like the log fire.\nI don't know if you know of the Atlantic team.\nThey have a monitoring tool that they, they created.\nIt's called Log Fire.\nBut you could use any log system that you want there to basically, you know, be able to monitor a\nbit like what's going on between the the NTP client and NTP server in production.\nI found it quite useful, uh, to do that.\nUm, but otherwise, uh, that's probably how I would go about it, I guess.\nNow if, uh, if I had to, because that's what I did at the time.\nbut.\nYeah.\nAnd if you work with a, you try an MCP in cloud, for example, then uh, you have the cloud logs,\nright?\nLike the SAP specific logs and the, the standard logs.\nWhat like, do you use any other tools for just taking a look at what's what's going on?\nOh, yeah.\nSo something that I really love about, um, so, so as a tool to monitor a specific MCP server.\nRight.\nSo not like a, so not directly the usage of MCP client and server, but the MCP protocol inspector,\nuh, is really great for, for, for monitoring like and checking that server is doing what, what you\nwant it to do.\nUh, but for individual MCP server, I guess, uh, I'm not sure or I guess I've never used it in the\ncontext of MCP server connected to the MCP inspector.\nUh, I think this is quite, uh, quite great.\nAnd then in terms of logs and monitoring, I mean, for me, there is always one part of the picture\nthat's a bit missing.\nBut it's also by design is that, you know, like by monitoring, for example, MCP client and server\ncommunications, you are missing a bit the picture of all what happens in the host on the, on the LM\nand the LM calls.\nAnd like what did he, for example, why did it call this tool or this kind of thing, this object,\nwhich can also be sometimes important to to understand a bit like why uh, your, your, your MCP client\nor SMTP server is failing.\nUm, but with that, I think it's.\nYeah, it's quite tricky because by design, they of course don't want, uh, the MCP protocol to be\nhaving the conversation that's going on.\nYeah.\nYeah, sure.\nOkay.\nThank you.\nUh, that's very useful.\nSo just just a few more questions, maybe about, uh, again, like putting MCP into production in the\nfuture of MCC.\nWhere do you see now this whole MCP space going at the time of, uh, June 2025.\nYeah.\nSo I think it's me.\nI see it as a growing quite quickly.\nUh, you know, there was a few announcements from, um, Google, OpenAI from a while that were saying,\nlike, you know, this would be integrated into their stack.\nWe are seeing it right now, like being integrated mostly on the API side of their stack.\nSo like if you look at now, I think like last week or maybe two weeks ago, um, Google announced that\nit would be integrated into their API.\nSo like now you can make API call with MCP.\nUm, also like similar things happened with, with OpenAI.\nUm, and there is also like rumors that this would be integrated in ChatGPT.\nSo this I don't know, but, uh, it looks like it's also something that's, uh, that can happen.\nAnd it was also announced by Sam Altman that it would happen.\nSo.\nSo I think that MCP is probably going to be even more prominent in the future and usable in more places.\nUm, also like in terms of immediate future development on the MCP protocol itself.\nSo this is a bit like what we discussed.\nSo authentication is kind of a new thing um through HTTP.\nSo a bit of a change on how remote MCP works.\nI expect to have more work on this part because this is how you, you can actually spread the adoption\nto have good reliable, uh, authentication and NTP servers developed, um, to work remotely.\nI think this is how you, uh, you can go further with MCP.\nSo maybe, um, like, I can see and obviously you're a believer in MCP, and I'm a believer in, uh,\nin MCP two.\nUm, but if what's your brutally honest assessment, like what part of MCP is you think is, uh, just\nthe hype and there is this whole hype going around.\nMCP is, uh, justified.\nYeah.\nWhere would you be?\nI think there is definitely a hybrid.\nI'm not, uh.\nI'm not blind to that.\nI think really like, uh.\nSo part of it is, uh, is overhyped as well, you know, thinking that you can do everything with MCP\nas well is probably a bit too much, but, um, but I think it has still some positive, uh, it brings\nsome positive things.\nUm, even if it's hyped, you know, because, um, it forced I think people that and even like API\ndevelopers to rethink a bit, uh, their API for LLM consumption.\nAnd it forced a bit everybody to start, start to rethink a bit of how their application or their API,\num, uh, can be consumed by Llms and maybe it could have API, but then you would need to, you know,\nthink about, uh, good descriptions for the LLM to be calling the API in the right way, you know,\nthis kind of things.\nSo it's really, I think, for people to, to work on, on that problem and, and um, and you see the\nresults, right?\nLike, thousands of servers are on GitHub.\nSo you can really like plug and play a lot of those.\nI think that's for me like I'm more focusing on the on the results you bring than on the, you know,\non the hype.\nIt's a, it created because the hype, it's like such a, I think positive impact in the end even though\nit doesn't solve all the challenges of course.\nBut yeah yeah, yeah.\nMakes sense.\nUm, so let me just think.\nI still wanted to, uh, ask you about your, your advice to to students who are now very much seasoned\nat this point of the course with MCP.\nSo they they got their feet wet and they might want to, uh, implement their own MCP.\nSo what would be your suggestion on what what are maybe the blind spots?\nWhat are the most important aspects to cover if they want to come up with a A minimum viable architecture\nthat they can already put into production.\nYeah.\nSo I mean, we always say that, but like start simple.\nUh, I would first like.\nAnd that's also how I work today.\nLike I start with a very quick, fast MVP implementation of the MVP.\nJust a few tools at the beginning.\nThe minimum I can do then I would probably try them with the inspector.\nAs I said before, I think the inspector is really great.\nLike you can really quickly see, um, just coding the tools, if it's if it's working or if it's not\nworking, you know.\nUm, and probably I would also start mostly with tools, as I said before, like because mostly tools\nand maybe then expand, you know, try.\nSo okay, this was a tool before, but maybe it could be sort of changed or refactored into a resource\nlater, you know.\nUm, yeah.\nYeah.\nBut I would like keep that simple in that sense.\nUm, and then maybe so when it comes to deployments, um, Uh, we've been working with this data plot\non Google Cloud.\nUm, so, so these these days, I'm thinking like, um, having an Google Cloud run, they support Streamable\nand streaming streaming right now.\nSo what you could do is you could start like to have like this as a, even as a not too expensive way\nto, to distribute to your users as a streamable, uh, HTTP solution on top of Google Cloud.\nIt could it could work quite well.\nUm, from my, my early tests.\nSo it's not production ready yet, but, uh, that's where I'm thinking, uh, to go for myself as well.\nSo that would be the place where you would like, try to put it into.\nI'm thinking.\nI'm thinking of it.\nYes, probably.\nSo we have this, uh, I think that's where I will go in the end, because it looks like a right fit,\nlike Google.\nGoogle Cloud Run makes it quite simple to have, like, Docker based, uh, solution running as, uh,\nsome sort of endpoints.\nPoints, then it's just like a web application.\nBut it runs as a serverless application.\nAnd I think just having the MCP defined and maybe in a Docker container can.\nI think it would work.\nSo I've tested already the part up to like SSH streaming and it was working fine.\nSo I don't I don't see why it would not work also via the NCP part as well.\nBut I'm revealing all my tricks now.\nAll right.\nUm, yeah.\nBefore before you, uh, before you give away all of your, uh, business secrets, I think, uh, we\ncan we can we can we can, um, wrap it.\nSo.\nSo.\nYeah.\nSo thanks so much for this discussion.\nUh, I believe this was, like, super, super useful.\nAnd it will our students will benefit a lot from that.\nAnd I'm wishing you all the best in your work advancing the field of AI.\nThank you.\nJordan.\nIt was really a pleasure.",
            "dataPurpose": "item-1"
          },
          {
            "title": "99. Building Production AI Agents with (MCP) Model Context Protocol | Sarmad Qadri",
            "videoUrl": "https://epam.udemy.com/assets/66094557/files/2025-06-20_11-54-52-7b274b6c4ce8bfb4bbf3aecc87705eeb/2/aa00c80dc5464ee83ce7194bca6916c0a40b.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNi0yMF8xMS01NC01Mi03YjI3NGI2YzRjZThiZmI0YmJmM2FlY2M4NzcwNWVlYi8yLyIsImV4cCI6MTc1NTc4ODA1NX0.BIquDdPQEvRtJ3NfQTUWgLt2jLAF1XLGUQHjJeSPVaA&provider=cloudfront&v=1",
            "transcript": "I'm here with Ahmed Quadri, co-founder and CEO of Last Mile AI, an expert on model, context, protocol\nand building AI systems.\nSarmad, thank you for joining us today.\nThanks so much for having me.\nZoltan, it's very nice to be here.\nSo I'm very much looking forward to pick your brain about your expertise on MCX.\nAnd I'm sure that all of the students are quite excited about what you can share with us.\nSo let's just start a little bit with your background.\nCan you share a bit about yourself and your background?\nYeah.\nUm, I've been working on developer tools pretty much my entire career.\nI started off at Microsoft, worked on compilers, built systems, Ides like VSCode, um, and probably\nthe most relevant part was actually working on language servers from with language server protocol,\nuh, back in the day.\nAnd I'll explain a little bit on how that's related to MCP.\nUm, and then, uh, over the last few years, I also worked at Facebook building some of the MLOps\ninfrastructure.\nSo the Jupyter Notebooks platform model management and experimentation platforms, kind of the developer\ntools for ML engineers and data scientists.\nUm, and then about two years ago, uh, what we saw with generative AI is everybody was starting to\nuse ChatGPT.\nAnd actually developers were starting to build with AI systems.\nWas that the people who were actually building AI applications, who we now call AI engineers, they're\nnot the same group of people who are building ML models in the past.\nYou know, like they're not ML researchers generally.\nThey're not data scientists.\nThey're regular web developers, software engineers, folks like us, you know, who have been, uh,\nkind of on the, on the, on the fringes of the ML space and now are at the forefront of it.\nAnd our intuition at last mile was, uh, what is the developer platform look like for this new, much\nlarger group of people to be able to successfully build AI applications?\nHow do you get them into production?\nWhat's those last mile problems that you face, uh, in that path to productionizing an AI feature or\nAI application.\nAnd that's really what we've been trying to solve.\nAnd so I'm very passionate about developer tools.\nMCP fits right into that bucket as well as I'm sure we'll talk about later today.\nUm, and uh, we're just like a developer tools and a developer first company.\nExciting.\nOkay, so, um, you very much answered your my my second question already.\nSo what I wanted to ask is, uh, like, from your experience building ML platforms at scale, what\nwere the biggest gaps that you, that you've seen or what you see between research and experimentation\nand actually, uh, production deployments, putting things into production?\nYeah.\nI think, um, the simplest way I can answer that is it's it's never been easier to put up a prototype\ntoday.\nYou know, you can code your way to something that works, maybe even 50, 60, 70% of the way.\nAnd it's really easy to get to very impressive demos.\nAnd that's especially true with these AI systems that are increasingly sophisticated and have a lot\nof, uh, like error, redundancy kind of built into them because they can reason about what you're\ntrying to say.\nUm, but the real challenges happen when you, your brand is on the line, when, you know, real dollars\nare on the line, when these systems are trying to make decisions on your behalf, take actions on your\nbehalf.\nAnd so really, the difference between scale versus demo is similar to how it has been always with distributed\nsystems, but with the added expectation of non-deterministic systems that are inherently like the case\nin AI models and AI systems.\nUh, adding an additional layer of complexity.\nUh, and so a lot of the challenges we see customers face, uh, include things like, how do I know\nif my application is working well or not?\nAnd that's such a simple question, but at scale, when it's real users interacting with it, that's\ndeceptively hard.\nAnd so there are evals and things like that that, you know, people often talk about.\nThen there's the question of how do I, like systematically give access to AI models, AI systems,\nto data, to tools, to APIs?\nAnd how do I do that in a way where I can kind of control, um, the behavior patterns of these systems,\nbecause otherwise unbounded, they can have a compounding error rates, they can go off the rails,\nthey can do things that weren't intended.\nUh, security is another big issue, right?\nLike, how do I kind of constrain the security?\nAnd what are these tools able to accomplish on your behalf?\nUh, and a lot of these patterns are still emerging, but you can think of them as close, uh, siblings\nof the kind of things that we had to face when we're scaling out distributed systems in the past as\nwell.\nAnd so I often try to, like, look back at what are the parallels to the previous world, like software\n2.0 to kind of understand where things are headed now.\nAll right.\nSo we are I will ask you a few more questions about evils and the, uh, the security.\nBut just to ensure that, uh, that all of the students have, uh, have context of, uh, what you\ndo, there is an open source project called MCP agent, which became, uh, quite popular on GitHub.\nCan you share a little bit about, uh, what MCP agent is and why you started this project?\nYeah.\nHappy to.\nActually, I'm very passionate about MCP and MCP agent.\nUm, so a little bit of background I mentioned earlier, I worked on language servers at Microsoft as\nwell.\nAnd uh, really the the thing about LSP language server protocol is, uh, for folks who are not familiar,\nit's basically the way that Ides give language features, uh, to different programming languages.\nSo if you're coding in Python, you get auto complete or you get go to definition or find all references.\nThe way that's implemented is based on an implementation of a protocol called Language Server Protocol.\nAnd so there's a language server running in your IDE client that basically knows how to do Python,\nuh, you know, language features.\nUh, and before LSP, the protocol came about every different I'd like eclipse, VSCode, Visual Studio,\nuh, you name it had its own esoteric way of enabling language features.\nAnd so you can imagine that like a Python language server developer would have to re-implement their,\nuh, capabilities and different times, because every IDE has its own unique way of doing it.\nUh, and so then they couldn't focus on, like, just one really solid implementation.\nAnd so Microsoft created this protocol that standardized all of that.\nIt completely flattened, uh, how you enable language features.\nAnd today, every major IDE kind of implements LSP.\nUh, and you can also see how that's revolutionized how you don't even think about language features\nanymore, the same way people did, you know, ten years ago, uh, when I was growing up on college,\nlike, notepad plus.\nPlus was a thing, you know, there was all these, like, different Ides.\nThere were some people at Microsoft who still use notepad to like code because, like, Ides were not\ngiving them as much value, which blew my mind even then.\nUm, and so it's like if you think of Ides as giving, like, you know, these, um, developers context\nabout their programs, the, the thing that I, the intuition I had, uh, at the very beginning of\nthis AI revolution was how do you translate those, uh, similar patterns into giving llms context about\nthe world around them?\nUh, and this is before, like, ChatGPT had plug ins or Llms could make tool calls, but I had this\nintuition of thinking about, like, um, basically connecting llms to the world around them and the\nworld around them includes APIs they can call data or resources.\nThey can, uh, interact with or read, uh, and then also like prompts that they can use.\nUm, and then when the MCP came out towards the end of last year, I was so excited because it was finally\nthe culmination of, you know, aha moment for me that, oh, finally, a big AI lab has tried to like,\nuh, actually encode those principles into a protocol.\nUm, and the only reason this protocol is valuable is in building agents, because what is MCP effectively?\nAnd we'll probably talk about this in much more detail in a bit.\nAnd I know you've done a great, like, set of, uh, kind of educational content around helping people\nunderstand this protocol.\nBut in its fundamental level, it's basically connecting llms to the world around them, uh, in a systematic\nway.\nAnd the only reason you do that is to build agents, to give these llms agency to do actions on your\nbehalf.\nUm, and so what I built was basically this way of, uh, building agents with MCP, with the expectation\nthat MCP is going to be a big standard that will take over the world.\nAnd this is before it was popular.\nThere was like a bunch of hackers who were really excited by it, but not many people outside of that.\nBut we were convinced that, you know, it was going to be a big thing.\nAnd so how do you build agents in a world where MCP is the the defacto standard interaction model?\nUm, that's really like the essence of MCP agent.\nAnd then it gives you a couple of simple patterns for being able to quickly spin up like production\ngrade agents in an easy way, and gets like the hard part of connection management of MCP servers and\nthe configuration and all of that.\nKind of like out of the way.\nSo you can just think about building your application and not about all of those, like semantics of,\nuh, of of MCP specifically.\nUh, so, yeah, in a nutshell, that's what MCP agent is, and we have a lot more plans for it.\nBut the cool thing is we're building on the base protocol, and the protocol is becoming a standard\nalready within a few short months, so it's very cool to see the growth of the ecosystem.\nAll right.\nThat's that's super exciting.\nAnd you know, I've seen one of your, uh, talks earlier.\nAnd then you said that the project was inspired by Anthropic's blog post.\nIt's a very influential blog post, which is in the course resources for the students, uh, which is\ncalled Building Effective Agents.\nCan you briefly introduce the main concepts presented in this paper and how MCP agent implements these\nconcepts?\nYeah, that's a great question.\nUh, so building effective agents for folks who haven't read it was a very popular post that Anthropic's,\nuh, engineering team made, uh, that basically outlined the patterns for building agents that Anthropic's,\nuh, applied AI team had found really effective in production, great agents.\nAnd the essence of the post was that you don't need to, like, overcomplicate the agent architectures\nto get along a lot.\nUh, like, pretty far.\nSo the simplest genetic pattern is what they call the augmented LM, which is basically an LM that has\naccess to tools and resources.\nAnd you can run it in a loop and the LM decides what to do next.\nLike it might call a tool, it might fetch some data, it might, uh, you know, analyze or reason\nsomething.\nAnd so that's like the simplest base pattern.\nAnd then you have they outlined a couple of like patterns that are pretty familiar to people who build\ndistributed systems.\nThere is a router pattern where a request comes in and an LM kind or some kind of like, uh, reasoning\nengine decides which module to route it to.\nAnd so then it's basically a router.\nUh, then there's a fan out and a fan in one where, uh, you give the same request to n different augmented\nLMS.\nThey do their thing.\nThey might call their tools fetch data, reason, whatever, and then they aggregate the responses and\nproduce a single response at the, at the end, uh, which is like a fan out fan in kind of like pattern\nthat exists for any parallel workflow in distributed systems.\nThen there's orchestrator where you have a much more arbitrary kind of task that comes in, and there's\na planner that first breaks it down into a series of steps.\nIt has some agents, maybe to execute those different subtasks.\nIt parallelizes the workload as it needs, uh, manages.\nIts almost like a task manager effectively.\nAnd once all the subtasks are done, it will synthesize a response and produce that to the user.\nAnd so really the the insight I had was these are all composable patterns that build from one to the\nnext.\nAnd so, uh, I just implemented all of them in my agent.\nSo if you use MVP agent, you can kind of like get all of these patterns that anthropic outlined for\nfree, uh, and depending on your use case or how you want to design your agent, you can kind of like\nuse these patterns.\nBut the cool thing is you can compose them together so you can like, have a router that's being used\nby an orchestrator or some substep of the workflow is fanning out and then fanning back in.\nAnd it just like works nicely and it's just programming at that point.\nThere's no fancy primitives around, you know, graphs or, uh, like visualizations of it.\nIt's just like writing your application script, similar to how you would for a Streamlit app or, or\nany other kind of like program.\nUm, all right.\nSo just to make this very specific to ensure everyone understands, uh, can you give a specific pain\npoint which MCP agent solves a pain point that developers face when they, they would work with MCP\nversus your framework?\nYeah, that's a really good question.\nSo the thing I would say is MCP, uh, is uh, is still pretty low level.\nRight.\nLike at the, at the protocol layer, it has a thing concepts like tools, resources, prompts, uh,\nthere's auth at it being added now as well.\nThere are a few other things like notifications, logging, etc. but you in order to build an agent\nyou need to like use these in systematic ways and in higher order constructs.\nSo I would say it's a very lightweight abstraction.\nAgent is a lightweight abstraction on top of MCP.\nAnd it so that you can kind of focus on, um, you know, building your agent workflow instead of trying\nto, you know, reason over these low level pieces specifically.\nSo a concrete example is, let's say you want to build like an agent that, uh, sources, uh, LinkedIn,\nuh, kind of like you want to run a LinkedIn email campaign or something.\nAnd so you maybe use Sales Navigator to find some, uh, leads that you want to email, and then you\nwant to export that to Google Sheets, like a very simple thing.\nBut maybe you want, like the search to be, uh, done by an agent.\nUh, and then at the end, the agent should, like, export the data to Google Sheets and maybe also\nnotify you on slack that it's done its job.\nSo that's like a you can like already start to think of like the big pieces of the workflow, the steps\nthat it would need to do.\nBut how do you do that with MCP.\nRight.\nAnd so MCP would you can have in LinkedIn MCP server that can let you interact with Sales Navigator.\nYou could have an MCP server for Google Drive to create and edit sheets.\nYou can have a link, an MCP server for slack to be able to send and receive messages.\nAnd then and you can use MCP agent to just like change these servers together.\nAnd for each different workflow you have, you define an agent that does its step and then hands off\nthe task to the next agent in the in line to do the next step of the workflow and so forth.\nAnd so you're able to think about the agent workflow in these higher order ways.\nAnd you let the framework just handle the how to interact with MCP servers.\nUh, for, for so you don't have to really, like, think about it too much.\nThat's really like the big value of of MCP agent is it basically simplifies the agent development aspect\nof it.\nThe last thing I'll say on that is actually, once you have an agent developed, you do need to deploy\nit somewhere for the agent to execute.\nAnd we can talk about this a little bit more in detail.\nBut at a high level, uh, agents are asynchronous workflows, right?\nSo maybe this is a cron job that would run every night, where I query a Salesforce or LinkedIn to get\nmy sales navigator data and then export things to Google Drive.\nAnd I have a new sheet that I can look at every morning or something.\nUm, and so that like, where does that where does the compute of that happen?\nIt's not just running on my laptop.\nI might want to deploy this, uh, into some infrastructure.\nAnd so we think of agents as workflows.\nAnd so you can use traditional like workflow orchestration engines to kind of, um, have the execution\nenvironment be similar to a distributed systems like data pipeline kind of infrastructure.\nSo an agent already implements temporal for managing your agent execution and agent orchestration.\nAnd you get that for free.\nYou don't have to like really think about it.\nYou can just deploy that into like a cloud environment.\nAnd you have an agent that has an HTTP endpoint that you can invoke as a webhook, as a cron job, even\nwithin from like another AI system actually.\nAnd we can talk about this in much more detail in a bit.\nBut really like those are things that you need to think about consciously when you're building.\nAnd then deploying an agent, that MCP agent kind of just takes off your plate and handles seamlessly\nfor you.\nSo that's that's already a quite impressive set of features.\nAnd what you said was that MCP agent is a lightweight framework.\nAnd I think if we ask around and we ask people like, which is a not lightweight framework for for AI\ndevelopment.\nAnd people will say like, so, uh, what would you say was the trade off in this design philosophy?\nWhen in which cases should people use macpaint and not go for a for a super major role like gig and\ngigantic framework like LinkedIn?\nYeah, that's a very important question.\nAnd I'll give a quick background.\nUh, and uh, maybe it's not even about specific frameworks.\nA lot of the time the question comes, should I just use the APIs directly for from the model providers\nto build my agent applications from scratch?\nAnd really what people are saying is what are the value adds that a framework provides to me, uh,\nthat I can't do on my own, uh, or that I can't really like, handle, uh, seamlessly or more simply\nwithout all the abstractions that a framework adds, uh, in between.\nUh, and so I'll point to a couple of trends that I've seen in the last couple of months that I think\nare fundamentally changing how frameworks should be developed.\nOne is models are getting really good, and so you have reasoning models that are doing things like\nchain of thought, reasoning, kind of the patterns that react had, uh, all of these pieces that initially\nwere done in the framework layer are now being done at the model inference layer.\nAnd so you can just call a model and uh, kind of do reasoning, which was not possible before.\nAnd so a model may take several minutes to respond in a way that was not an interaction model we were\nused to.\nUh, so that's a huge thing that's changing in, uh, model capabilities.\nUh, what that means is that there's less burden on the application developer and less burden on the\napplication framework to do these things, because you can rely on the model for some of those capabilities.\nThe second thing is MCP.\nIt completely collapses.\nHow?\nUh llms get access to tools and resources.\nSources.\nAnd so you don't need those hundreds of data connectors that a framework like Lang Chain implemented\nin the past.\nBecause each of those is if it doesn't already, is going to have an MC server for it.\nSo now you the framework, all it needs to do is connect to MC servers to kind of get the job done.\nAnd so what that both of those things really mean is that the application framework can be basically\na very lightweight orchestration library that lets you connect really good models to MCP and build agentic\nworkflows out of that.\nAnd so I'm very opinionated about that in terms of, uh, keeping MCP agent very lightweight and only\ndoing the things that you can't really, uh, like that, that still take a lot of effort.\nSo the orchestration and deployment aspect is one where that is effort to set up and do.\nRight.\nSo that's something that the framework helps you do.\nHuman in the loop is something that's really important.\nAgents should be able to be paused and resumed retried, uh, if they fail all of those kind of primitives\nyou can kind of build in, you get for free from MCP agent that otherwise you'd have to like think through\nyourself.\nSo those are the kind of things that a framework should do.\nAnd then beyond that, it should just like get out of the developer's way.\nIt shouldn't have tons of abstractions that hide how the behavior is happening that like kind of limit\nthe developer's control over this.\nAnd then the last thing I'll say is, you know, because of LMS, vibe coding and all of this, it's\nnever been code generation is no longer the hard part.\nSo developers are able to build applications very quickly now.\nAnd so the framework, um, like even application frameworks should be optimized and not just human\ndeveloper optimized.\nSo you can build more quickly with LMS because that's how we're building software now.\nSo those are the principles I think about when I think of like what a framework like MCP should provide\nto a developer and to a developer empowered with LMS for for vibe coding versus some of the V1 frameworks,\nAI frameworks that came in the past before these trends became a thing.\nAha, okay.\nYeah.\nThis makes complete sense.\nAnd what you're saying is, is that, uh, SMTP agent is a lightweight framework, but there is an extra\nfeature that you, uh, that you mentioned and also, uh, you also write about in the doc that MCP\nagent can be used as an MCP server.\nRight.\nCan you share a little bit about this functionality and maybe give us an example of where this can be\nuseful?\nAbsolutely.\nSo, um, this is a little bit of a trippy, uh, thing, like a little meta.\nSo let me try to break it down a little bit more.\nUh, today, if you think of how you use MCP servers, let's say I connect it to cloud code like Gmail\nserver or LinkedIn server or something like that.\nThen cloud code gets access to the tools implemented by that server.\nAnd then I give an instruction like I prompt Claude and it figures out like how to use the tools.\nSo really the agent in this case is the Claude code application, the client side.\nUh, so what I'm trying to say is so far, Agentic behavior with MCP has been, uh, the client applications\nthat implement MCP.\nSo that's cursor, that's Claude, that's VSCode, all of the agent modes that are built into those\napplications.\nUh, what we're proposing is an extension of that, which is a new agent pattern where you actually\nexpose the agent as an MCP server itself.\nSo let's say I built this LinkedIn to Google Sheets, uh, kind of like exporter agent.\nAnd I could I want to use this agent both from like, you know, I trigger it through an HTTP endpoint.\nBut maybe I also want to like just prompt my Claude code instance to run this workflow.\nIt's how would I do that today?\nRight.\nWhat what I know for sure is that MCP, because it's becoming a standard, more and more client applications\nare MCP clients.\nAnd so the way to connect over MCP to MCP clients is by exposing things as MCP servers.\nAnd so what we enable for free in MCP agent is this idea that you can wrap your agent as an MCP server\nitself, and so then you can have this agent be available in any MCP client.\nSo you can have it be in like cloud and cursor and VSCode and maybe in the future Google Sheets or any\nother like line of business application that becomes an MCP client.\nAnd then you have this separation where you define your agent, you have your agent logic and agent\nworkflow encapsulated as an MCP agent, and then you expose it as a server, which then makes it available\nin any MCP compatible client.\nUh, and really like that, I think is a huge thing because then you can actually think of multi-agent\nworkflows all happening over model context protocol, because this agent may be calling other MCP servers,\nbut those servers may be agents themselves.\nAnd that's where it gets really meta, because you have this network proliferation of, uh, of agents\nthat are able to communicate with each other, uh, over MCP via tool calling.\nUm, and so that's really cool.\nI think that the possibilities are really unlimited with that kind of perspective.\nAnd there's a couple of other like, protocols out there, and people are still thinking about agent\nto agent communication in different ways.\nBut I actually am of the opinion that you can do a lot of that on MCP itself, uh, even as it exists\ntoday.\nAnd the protocol is evolving pretty quickly to, to enable even more agent interactions.\nUh, right through MCP itself.\nI love this idea, and I think that's that's such an original and great idea.\nUm, let me drill down a bit on on that because, uh, one thing that you mentioned is that you might\nhave multiple mic connected to an MCP client.\nRight?\nAnd now you talked about it in in that context, MCP agent being an MCP.\nAnd what um, what I see is that what students struggle with is what happens if you plug in or connect\nmultiple MCP is, let's say, ten MCP into an MCP client.\nHow can you ensure that, uh, you end up with a robust tool calling, uh, environment or robust tool\ncalling patterns?\nIs there something you can share about that from your industry experience?\nLike what patterns consistently lead to reliable agent behavior when you have a number of MCP connected\nto a client?\nThat's a really, really important thing actually.\nUm, so thank you for bringing that up.\nUm, I'll actually break it down very concretely.\nWhat we have found is, um, Llms do start struggling when you give them more than 30 plus tools to\nchoose from.\nAnd so that may be a limitation that slowly goes away.\nBut even so you should really think consciously about at every step of an agent workflow.\nWhat are the relevant tools that the agent should have access to to do its job?\nAnd so one of the things that the way we've solved that in MCP agent is every agent, you can actually\nfilter which servers it should have access to.\nBecause let's say like the LinkedIn server agent should maybe only have access to the LinkedIn server,\nit doesn't need access to the slack server or something like that.\nAnd so that's one really important thing of breaking down your workflow into a set of sub steps, where\neach step you kind of define what are the capabilities that that agent needs access to.\nAnd that's an automatic filtering that you that you apply there.\nThe second thing that you can do, which is a little bit more sophisticated, we're adding this soon,\nis dynamic filtering.\nSo at every step of the agent workflow think of it almost like rag, but where you can like take an\nembedding of like the conversation or the history of interactions so far.\nAnd you take an embedding of all the each of the tools that are exposed by the MCP servers.\nAnd you basically find the top 20 or 30, uh, tools that are closely aligned, and you can just add\nthose to that LMS context at every so that at every step in the workflow, you're only giving an LLM\nlike 30 choices or something to pick from.\nUm, and so there are a couple of MCP servers that, uh, are already like really large that have many,\nmany tools.\nAnd they really do start struggling in production environments.\nUh, unless you implement some kind of filtering yourself, the filtering can be done statically as\nwell.\nIf you're really confident of like, these are the only tools that, uh, you could like this agent\nneeds from this server.\nBut I think you're totally right that as MCP adoption continues to grow.\nAnd as you have more production grade servers, you know, like these web services, Google Drive,\nfor example, if you look at its API spec, it's hundreds of APIs.\nAnd so if there's an FTP server for that, that's going to be really hard to reason about.\nYou can't give an LLM access to every single API that Google Drive or some like massive server like\nweb service exposes.\nIt will need to be a little bit more thought through than that.\nSo that's like the most concrete thing I would recommend is just limit the number of tools that an LLM\nhas access to at any given time, and that'll get you like a long way.\nThanks.\nAnd you you mentioned here briefly security.\nCan you share your thoughts on security because uh, now in the news we had, uh, like poisoning attacks\nand there was an incident with GitHub.\nAnd what's your what's your take on that?\nWhat's the status of MCP security and where is it heading?\nIt's a very important question, and we get this question a lot when we talk to enterprises and enterprise\ncustomers looking to adopt MCP.\nUm, so there are a couple of things.\nOne is this model context protocol spec is unlike other protocols actually pretty rapidly evolving.\nAnd so that's a good thing because there are a couple of these really important things that we need\nto figure out as an AI community.\nUh, the good news is there's already an off spec that is part of the latest versions of the protocol,\nand it basically enables authentication over OAuth, uh, similar to how, uh, you know, IDPs and\nauth, uh, authentication servers work in distributed systems world before before MCP.\nSo it's very consistent with patterns that, uh, security practices that developers are already familiar\nwith.\nAt the same time there, you mentioned prompt injection.\nThere are a couple of other ways that you can still jailbreak or hack through The these AI systems and,\num, those problems have not gone away.\nThey are they we've carried them forward from you know, those prompt injection attacks were always\na thing with Llms.\nAnd we need to protect against them.\nBut it's not an MCP specific problem.\nUh, what I would recommend folks think about is, uh, what are the things that MCP specifically needs\nto be protected against?\nAnd what are the things that, like your AI application, with or without MCP, has a threat model,\nuh, risk tool that you need to think through, uh, in general and kind of separate those out because,\nuh, it's, uh, otherwise it becomes very difficult to kind of like, make forward progress.\nUh, one concrete thing again, I'll suggest on this is, uh, we've seen patterns emerge for, uh,\nsending over, uh, off tokens alongside requests to agents.\nAnd think of these tokens as, like, scopes, uh, that give them access to IAM permissions or credentials\nthat the agent needs, and the agent should never be able to, like, do more than what that token allows\nit to do.\nThis is standard practice, and like I worked on windows back at Microsoft, you pass through credentials\nlike through tokens and there's this Ssid, security ID that kind of like manages what, uh, that,\nuh, that process has access to performing and, uh, it's designed in such a way that you can never,\nlike, get more permission than what that ID gives you.\nSimilarly, at Facebook, there's this concept of like a viewer context, uh, which is basically,\nuh, every object is protected by this, uh, viewer context object, which, uh, basically controls\nwhat data is available at that point in time.\nSo by design, you can kind of prevent data that may be belonging to another user that you shouldn't\nhave access to from ever even being possible to be queried.\nUh, similarly, I think agents are going to need that same kind of scoping mechanism because agents\nare acting on your behalf.\nAnd let's say, like you and I are collaborating with the same agent.\nBut when I invoke the agent, there should be a like token that the agent receives.\nAnd when Zoltan interacts with it, there's a Zoltan token that it receives.\nAnd that should, by design, prevent it from like you accessing my data or me accessing yours.\nUh, so I think the good news is, uh, that these patterns have existed in the past for other purposes\nthat we can now take and apply it to agents.\nUh, but there are obviously, like, other kinds of challenges, like you mentioned, prompt injection.\nAnd there are many others that we also need to think through because the dangers could be higher when\nan actor is acting on our behalf.\nYeah.\nOkay.\nThat's very insightful.\nSo you're saying that basically, uh, everyone should follow standard industry practices because many\nof these problems have been already solved, have been already solved in, uh, in other frameworks.\nAnd some of them are now solved, uh, with MCP, like OAuth, if, um, if I want to set up a production\nMCP and I want to implement, uh, let's say a rate limiting, do you have a standard framework you\nwould use, let's say, for a Python based MCP to, uh, to integrate my MCP server with.\nSo you can do parts of that with MCP agent already.\nActually, uh, one of the things I always recommend, folks, is there's, uh, obviously like, uh,\ntoken, uh, counting is an important thing.\nYou but just for cost purposes, you may want to like, limit the amount of tokens agent workflow consumes\nto some max level.\nUh, after which you cancel the workflow.\nUh, for example, uh, or you request the user, like, is it okay to continue going?\nUh, then there is, uh, things like Max turns is another way that I've seen it, where you can kind\nof like see how how many loops and LM can run in, uh, until it accomplishes a task which is a very\ncrude but effective way of kind of limiting, uh, a Cambrian explosion of, uh, like, uh, turns\nwhere an agent may go off the rails and continue going forever or something.\nYeah.\nUm, then there's prompt caching, which is also pretty important.\nUh, that's turned on by default for the model providers that support it, which I think is pretty critical\nas well for agent workflows.\nUh, so there are I think the the answer actually lies in a combination of all of these.\nI would start simple.\nI would start with like max turns being set to some, uh, a definite number that's less than infinity.\nUh, and then there should be something that like counts tokens, which MCP agent and other, uh, things\nprovide.\nUh, and then I think you can get into rate limiting and some of the more sophisticated approaches from\nthere.\nRate limiting in general for I would say like MCP servers are web servers.\nAnd so if you're a server developer, you should definitely like set up your system in such a way that\nit wouldn't fall over from DDoS attacks or from high like request rates or things like that.\nBut then if you're an agent developer, you also want to be cognizant of like, uh, not spamming the\nGitHub MCP server because that's going to get you rate limited the same way the GitHub API gets rate\nlimited.\nYeah.\nAnd so you just need to think about those things a little bit the same.\nBut the good news my consistent message is the good news is it is consistent with how you've had to\nthink about those for standard web development.\nIt's not fundamentally new, except that the there is a reasoning engine now, and your program that's\nable to dynamically decide if it wants to make an API call, if it wants to, like, fetch data, and\nthen you just want to give it some controls on like, hey, don't you know, spam the system?\nUh, or don't go crazy out of turn or, uh, on some wrong direction that leads you down a rabbit hole.\nOkay.\nOkay.\nIt all makes sense.\nSo basically the same we we already have.\nWe already have the answers for for most of these, uh, problems.\nUh, there is one thing you mentioned.\nIt's the token efficiency.\nUh, can you maybe share some of your recommendations on how to, uh, what strategies have you found\nfor for managing token usage?\nI'm not sure if that's like a question that's tightly, uh, put to mic or just like in general, but\nwhat would you suggest for people implementing?\nIt's really, uh, really, really important, uh, thing to think about because any production grade\nagent workflow will run into the ceiling of context windows if you try to, uh, stuff everything into,\nuh, you know, like, uh, a single LM call.\nAnd so the biggest thing I'd actually recommend is breaking down your agent workflow or your application\ninto sub steps, and each of them is its own LM invocation.\nUh, there's prompt caching enabled so that you should ideally be able to, you know, have token efficiency\nthrough the model.\nProviders provided prompt caching.\nBut even so, like if you, uh, limit specific workflow steps where a subtask or a sub agent is just\nresponsible for a discrete part of the pipeline, then what it has to do is already limited.\nUh, and so then you can like, have much more token efficiency in aggregate because, uh, there's\nno single LM call that's getting tons of context and tons of you're not overwhelming.\nUh, each LM call.\nAnd the other nice thing about this is not just efficiency perspective, but also performance improves\nbecause you're not confusing the LM with a lot of complexity.\nYou're consciously thinking about what do I want in this step for an LM to be able to do?\nAnd then you're just asking it usually to do like 1 or 2 things, uh, for at that step.\nAnd a concrete example would be like, maybe you're asking the LM to fetch a data from a website, and\nthat's all that that step does.\nAnd then maybe summarizing that data is a next LMS job and so forth.\nAnd that way, like the context that's being retrieved or what each LM is trying to do is kind of like\nconstrained to its job, basically.\nOkay.\nUm, thanks.\nAnother topic, uh, that you you already brought up at the beginning is like, let's assume now we\ntalk through all of that, like how to create an LM, how to.\nHow to create an MCP.\nHow to put it in a context where it can work reliably.\nSo what happens when I want to evaluate my MCC?\nI think at this point, uh, in the course, students don't have too much context about how auto eval\nworks.\nAnd that's also a service that you provide with last mile.\nAnd like the general auto evaluation, um, philosophy.\nCan you share a little bit with about like what that is, what are the best practices.\nMaybe what are the best metrics?\nAnd uh, how can you use.\nWell last mile or MCC for that.\nYeah, that's a really important question and something that a lot of customers are starting to ask\nus, as well as more MCC, uh, go to production.\nThe big question is, is is this a good MCP.\nAnd even for like an agent developer, you know, there are so many MCC out there.\nSo how do you like know if this MCP is good or not?\nyou're either trusting that the provider of that service did a good job, or you're maybe doing some\nrudimentary tests.\nSo suffice it to say, evals for MCC are really, really important kind of subject.\nUm, what I'll actually describe, we're actually launching an open source project around this called\nMCC eval, uh, very soon.\nSo, uh, I would love to share that more.\nBut the essence of it that I would say, is the way you evaluate an MCC server is the the only reason\nto build an MCC server is to use it in an authentic workflow.\nSo to to evaluate an MCC server, you actually connect it to an agent and ask the agent to perform some\ntasks and then see if, uh, it, if the server does a good job.\nAnd what what by by that what I mean is let's say that the agent tries to call a tool on the server.\nUh, was that the right tool to call that the tool call succeed?\nDid it fail?\nWas the steps that the agent went through efficient at achieving the objective was the objective achieved\nor or not.\nAnd so you can already think of this as almost like py test style integration tests, where each test\nis like an agent objective that you're giving it and you're connecting it to an MCP server, and then\nyou're collecting metrics like tool call coverage tool call success, objective success, uh agent reasoning\nefficiency, uh, planning efficiency, etc..\nUh, and then you have a test report at the end, which is basically not just the agent's test report,\nbut actually your server's test report.\nAnd once you have these metrics, the really cool thing is, um, you can actually use them to optimize\nyour MCP server.\nUh, and if you think about like what an MCP server is, it's a collection of tools and maybe resources\nare exposed as well.\nAnd each of the docstrings for these tools are like prompts for the LM, uh, you know, like you're\ndescribing what these tools are supposed to do, how to use them, all of that.\nAnd so you can actually optimize the prompts in your MCP server.\nIf you had a test suite of of data and metrics as that to use as your optimization function, that's\na whole other subject.\nBut that's like what we're doing in MCP.\nEval is enabling like a Pi test extension module to be able to write, uh, MCP evals using MCP agent,\nactually, because the agent that you use to connect to the server is an agent.\nUh, so that's the cool part of, like, using our existing project to build this, like, more, uh,\ninteresting.\nLike, uh, evaluation suite.\nUh, the other thing that you mentioned, auto eval, that's actually a product that we've had for a\nwhile now, which is a fine tuning and inference service, uh, for, uh, creating custom evaluation\nmodels.\nAnd so what we do is we have these small language models, these are 400 million parameter Bert based\nmodels.\nAnd we're able to, like, teach them, uh, through fine tuning your eval criteria.\nAnd so you can get a very specific custom kind of evaluation criteria if you care about a specific kind\nof on a metric.\nThe example is a couple of customers of ours.\nThey really care about brand tone.\nThey want to like, make sure that the LM agent is answering questions for their customers in adherence\nto their marketing guidelines, etc..\nHow do you evaluate that?\nRight.\nSo we taught we have evaluated our models that have been fine tuned to learn that criteria through good\nand bad examples.\nAnd then you can basically like have a score that you get on how adherent the response of a model is\nto brand tone.\nAnd that's just a completely custom metric, which is kind of cool, but you can think of many other\nmetrics that that can exist that are very serious ones as well, where like, uh, there is a company\nthat has a nuclear division and they don't want to, like, have any questions that answer anything\nabout nuclear for, uh, like from their chatbot or anything.\nAnd so they've trained like a classifier model using auto eval to be able to like, prevent that from\nhappening.\nUh, and so that's pretty cool right?\nLike these models, because they're small, they can be used at runtime because they take only 300 milliseconds\nper inference request.\nSo you can actually use them as guardrails as well as, um, evals.\nUh, and so you can catch these things before they hit, uh, an actual user, which is kind of cool\nto see.\nUh, so that's like actually an enterprise grade platform that we've already had and now we're working\non is kind of tying all of that back through this build, test and deploy phase of the agent development\necosystem so that it's like a one consistent product, uh, suite.\nUh, that's super exciting.\nAnd I can't wait to see it on GitHub.\nYeah.\nUm, so and here is another thing.\nUm, when it comes to evaluations, what, uh, what again, students run into is that they, um, usually\nfind it hard debugging.\nSo when you have again, a bunch of maps connected to an MCP client, you execute some kind of a query\nand then something goes wrong.\nThen they might find it hard to to like, figure it out from the logs.\nHow to what specifically went wrong?\nDo you have from your experience?\nWhat are the patterns that are effective for tracing these issues?\nIssues when it comes to MCP servers, alarm calls, or any external API interaction?\nYeah, I think the I would recommend doing the basics right first.\nSo standard like open telemetry style tracing should be a de facto standard for any application, especially\nan AI application.\nAnd being able to like trace the individual steps so you can kind of at least have observability over\nthe call stack of how an input turned into an a response from an LM system.\nBecause oftentimes these systems are no longer just like you call an LLM, and you get a response and\nyou return that to the user.\nThey're complex, multi-step pipelines and workflows.\nAnd so effectively they're distributed systems.\nUm, so that's like really important I think, to just have off the bat.\nAnd then the question is like, okay, let's say that like the response was incorrect or bad in some\ncategory that you care about, how do you debug what went wrong in that call stack?\nAnd what what we recommend in that case is actually, uh, it's laborious, but it's actually helpful\nto think about those substeps as individual, uh, kind of steps in the workflow that you can have eval\nmetrics for as well.\nAnd so not only should you have end to end metrics, but you can actually have sub metrics within that\nworkflow.\nAn example is like um planning quality is really important.\nSo let's say that like an agent you give an agent an arbitrary task.\nIt has to create a plan and then execute on the plan.\nUh, the plan quality really matters on what the end result is going to be.\nAnd so having a metric for the plan quality is and that could be an LLM judge metric, even you give\nit to a reasoning LLM.\nAnd pretty important another one is tool call correctness or efficiency.\nUh sometimes what we see is like an LLM tried to make a tool call.\nIt failed, the tool call failed.\nAnd then instead of either retrying or uh, like returning the error to the user, it just hallucinates\nsomething and from its own like understanding of the world, uh, and uh, returns a response.\nAnd unless you kind of, like, catch that as an error, it's really hard to know that that happened.\nAnd then that might introduce a hallucination at the end that is either subtle or hard to track or hard\nto debug.\nWhy that what what went wrong.\nSo having these metrics and that's like a simple metric.\nYou just have to like check if tool calls succeeded or failed.\nUh, and you can use those as like ways of at least understanding what part of where in your system\ndid things go wrong that led to downstream issues?\nUh, so I would recommend again starting simple get tracing setup.\nThen next step is figuring out like metrics that you can introduce at each substep.\nUh, and then like going from there until you feel like you're able to confidently iterate on your application.\nUm, it's it requires good engineering practices.\nUh, that's the bottom line.\nOkay.\nSo we, um, you very much covered what happens if you if you use a bunch of LMS and you want to kind\nof productionize it with evaluation and debugging and tracing?\nNow, what happens if I want to implement, uh, my own MCP?\nUh, what are those architectural choices that I should make if I want to take it beyond the sandbox\nand make a, you know, a scalable, robust, secure, reliable MCP that I can and release.\nThat's a really important thing, actually, because, um, I think the community is just on the verge\nof that inflection point of going from MCP as a, you know, interesting thing to MCP as a robust production\ngrade, uh, kind of thing.\nYou mentioned GitHub earlier, right?\nLike, we already saw that there are some security vulnerabilities found even in like a very good engineering\nculture, tech companies, uh, implementation.\nAnd so I think there are like learning, uh, kind of things that need to happen before we get to like,\nrobust practices.\nBut at the end of the day, I think like auth really matters.\nLike make sure you implement the auth spec for MCP for user authentication.\nI would argue like uh, HTTP endpoints like Streamable HTTP servers is going to be the, the predominant\nway that MCP really takes off.\nSo investing in that is important.\nUh, and that the good news is with that, you also get like the expectations of how a web service generally\noperates because servers are still web services at the end of the day for streamable HTTP endpoints.\nUm, and then I think, like really thinking about, um, um, like agent authorization and authentication\nis important.\nSo, uh, there's a new draft of a in the spec at MCP called elicitation.\nUh, and what that means is human in the loop style workflows.\nSo it basically lets a server, uh, request a client, uh, for, like, uh, permissions, for example.\nAnd it's like structured data.\nSo you can kind of structure the permissions how you need.\nBut if you've used cloud code with MCP, you would find this familiar where, you know, the first time\nyou connect an MCP server to cloud, uh, and you it needs to make a tool call, it will actually prompt\nyou in the client to say allow once, allow always for this tool call.\nAnd now think of that.\nThat was a client side implementation that Claude team, anthropic team built into the client.\nBut you want to expose that for every kind of like as a server developer, you want to make sure that,\nlike that pattern is available to a server, uh, for to a client that uses the server.\nIf the client implements that, the elicitations part of the protocol.\nAnd so thinking about those things is really important because again, going back to the idea that MCPs\nare MCP servers can be agentic themselves.\nThat's the next step that we're headed to, because so far the trajectory has been people saw that they\nhad like Rest APIs, open API specs, and they just did a 1 to 1 conversion of those into MCP tools.\nUm, but the next step is these these MCP servers should be able to do agentic things, uh, behavior\nwithin themselves as well.\nUh, so then you could expose like even in the GitHub server, maybe there's in the future there's like,\nuh, an analyzer tool that can analyze your, uh, repo for recent, like, trends or something.\nUh, I'm just thinking off the top of my head, but, like, the idea being that then there's an agentic\nworkflow that the server does that isn't just an API call that you make, like a Rest endpoint.\nUh, so that's like those are the things I would think about.\nAnd the last thing I'll say is, uh, and this is actually I think you're doing a great job of, uh,\nenabling this.\nReally understanding the MCP spec is important because it's so much more than tools as well.\nUh, there's resources which are, like, not as well understood yet.\nI just mentioned elicitation, which is a draft.\nUh, there's also prompts like a server can expose high quality prompts that are, like, engineered\nto work well with this server.\nAnd exposing that can help users get started with the server and use it more effectively than they otherwise\ncould.\nSo I would recommend like server developers to really understand the spec beyond just the tools side\nof things, because there's like a lot of interesting stuff there.\nYeah, exactly.\nUm, I also saw when, uh, when I started working with MCP, that tools are kind of easy to understand,\nbut then when it comes to resources and especially prompts, then, uh, then you need to find a good,\na few good examples.\nSo you really grasp like how they can be useful.\nBut they are they are super important.\nAbsolutely.\nSo yeah.\nThanks, Ahmad.\nMaybe just, uh, just a few final questions.\nUm, what's your take on the future of MCP?\nSo where is this ecosystem heading?\nWhat, uh, what standards are missing?\nWhat's coming?\nWhat would you expect in the next few years?\nOh, I think, uh, one of the the really surprising things, even for me, I got started on MCP pretty\nearly, but even for me, it's kind of amazing to see how quickly it's gained adoption.\nSo it's had, like, product market fit in some way where clearly like the industry really needed a\nstandard way of, uh, having llms interact with tools and data and prompts and resources and whatnot.\nUh, and so I think what I foresee is MCP is going to evolve pretty quickly as well to kind of we covered\na lot of challenges that you mentioned that you brought up, that I think the protocol is going to need\nto evolve to kind of solve for.\nSo I expect MCP itself to be a living, breathing organism, not something that's fixed, that stays\nexactly the way it is today.\nUm, the other thing I foresee is people, uh, building more sophisticated agentic experiences, uh,\nas MCP servers and more sophisticated infrastructure that makes it easy to deploy these agents and these\nservers, uh, because, like, I think ultimately, the real test and success of the protocol will\nbe if we see agents being more ubiquitous out there, you know, like, uh, that inflection point hasn't\nquite happened yet.\nIf we think of who are the people building agents, it's still like the startups and the high tech companies\nand the the usual suspects, you know, that you would expect to be at the forefront of this, but can\nwe democratize this even further?\nThat's kind of the mission of my company and that what I want to accomplish, and also I'm very passionate\nabout, like figuring out if MCP can, uh, how MCP can help make that a reality.\nUh, so that's the one thing I would say.\nThe other one is I'm very convinced that MCP has, like, critical mass already.\nSo I think we'll see a lot more enterprise adoption in the next year or so.\nUh, from like the large, uh, companies that are like startups that are already adopting it all the\nway to the large fortune 500 companies that are just starting to, like, realize its full potential.\nUm, and then the maybe the last thing I'll add is I think we'll actually get to a much better state\nof, uh, much, well, more well defined patterns of how to build AI applications, whereas today it\nstill feels a little bit like the Wild West, you know, like you kind of pick your religion almost\nwhere you're like, okay, I'm going to like go into this ecosystem and this way of doing things and\nmaybe I'll get some way there.\nThere's just so much noise in the system to know what are the best practices available.\nAnd I think the combination of MCP and, um, really good models and simplified AI frameworks, evals,\nall of these together, I think are going to give us really good patterns for how to actually build\nand deploy production grade applications.\nAnd so I'm just hoping for like 100 x increase in the agents that I interact with in my daily life,\nbecause I haven't seen that yet.\nYou know, I can't wait to like offload stuff to to AI systems more and more and trust that they'll\ndo the right thing.\nSo I'm hoping that that's the next two years for for the ecosystem.\nExciting.\nAnd, uh, yeah, you're saying that this today is still kind of the wild, wild West and also that\nyou you got into that quite early.\nUm, if if I'm an MCP newbie now and I want to, you know, just kind of understand this whole ecosystem\nand get started with MCC, what would be the resources or the communities that you would, uh, suggest\nI join or or I read or what do you suggest your employees when you onboard them?\nWell, uh, first I'll suggest they check out your content.\nUh, actually, I think you're doing a great job.\nUh, and that's, like, jokes aside, I think that's really important to have, like, educators out\nthere who are really trying to simplify these really sophisticated patterns that are emerging.\nUh, the other thing I would say is really do spend a little bit of time understanding the base protocol.\nUh, I think it's important, uh, especially when there's so much noise in the system, you kind of\nlike may get gravitate towards the simple surface level things, but it's important to just The protocol\nis not that big.\nSo you can actually just read it or ask Claude to summarize it and try to understand the, you know,\nthe best, uh, kind of like the high level ideas there.\nUm, and then what I recommend actually people to do is build agents, because really, that's what\nis the reason, uh, for MCP to exist is to enable agent development.\nUh, I think there are just so many possibilities, even in my daily workflow.\nI think in every person I talk to, uh, even at my company elsewhere, there's just like, have tons\nof ideas for automation of some kind that Llms can help them with.\nAnd I recommend that they actually build that out either with MCP agent or just like whatever they want\nto choose to to do that with, but like really try just building that.\nThere's no alternative.\nThere's no shortcut for from like actually trying stuff out and building it yourself to get a deep intuition\nof how it works.\nUm, and uh, lastly, I would say, I think there are all these challenges and problems that we pointed\nout today, but I would recommend folks not get pessimistic and use that as a reason not to build or\nnot to try things out, because I'm very optimistic and confident that we're actually going to like,\nas an industry, going to solve and work through these problems because we have no other choice.\nWe have to, uh, and those are all solvable problems because we've solved them before for other kinds\nof systems.\nUh, so, uh, yeah, just like get started, learn about the intrinsic details and try to bring the\nbest practices from distributed systems in the past to this world, because, uh, that will demystify\na lot of things for for a lot of folks.\nI think that's a that's a great closing sentence.\nSo thanks.\nThis has been extremely useful for me.\nAnd I'm, I'm sure that, uh, it's the same for everyone who who is watching this video.\nSo thanks again for joining us today.\nThank you so much for having me, Zoltan.\nI had a great time.\nThank you.",
            "dataPurpose": "item-2"
          }
        ]
      },
      {
        "title": "Section 18: Wrapping Up",
        "items": [
          {
            "title": "100. How to Requests Topics and Provide Feedback",
            "videoUrl": "https://epam.udemy.com/assets/65239447/files/2025-05-19_13-24-40-682e8f9b59e78c4c4624f3c958975d91/2/aa00e37e7e3b98b31624f9e4ffe423208676.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC00MC02ODJlOGY5YjU5ZTc4YzRjNDYyNGYzYzk1ODk3NWQ5MS8yLyIsImV4cCI6MTc1NTc4ODA2N30.eSuagwNyeW2fEn41PuM-0jLQDddg9WnXgxnRBmhOfYE&provider=cloudfront&v=1",
            "transcript": "I would love to hear from you even more beyond the feedback you can give me here on Udemy.\nSo I would again encourage you to come to our Community Discord channel, which I link to in one of\nthe first resources and invite you for a discussion.\nPlease share what you liked.\nPlease share what other topics you would like to cover or any other feedback that you have.\nAnd let's join and chat.",
            "dataPurpose": "item-0"
          },
          {
            "title": "101. The Future of MCPs - Anthropic's Roadmap",
            "videoUrl": "https://epam.udemy.com/assets/65239449/files/2025-05-19_13-24-40-d437d548cead3d2239d8c0ae42acb580/2/aa00863d9a3856655a6c3488242829fe5faf.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC00MC1kNDM3ZDU0OGNlYWQzZDIyMzlkOGMwYWU0MmFjYjU4MC8yLyIsImV4cCI6MTc1NTc4ODA3MH0.3mU5N3YsLmJbHD0HIxFsXjnPSUjCFP32UsSLu-w-0BY&provider=cloudfront&v=1",
            "transcript": "If you are excited about what's coming up with M.c.p.s.\nYou've just gotten lucky because anthropic publishes its roadmap on the Model Context Protocol website.\nI added the link to this roadmap section to the class resources, but here is a quick list about the\nfeatures that I find either the most pressing or the most exciting.\nNow, first of all, we have security.\nMany of the critics of MCP are about how insecure it is, by which I mean like how much it lacks security\nfeatures when it comes to comes to encrypted communication or authentication whatsoever.\nSo I'm sure that there will be lots and lots of work on the security layer.\nAnother exciting thing that anthropic is working on is creating test suites for you.\nSo if you implement your MCP layer or your MCP module, you will be able to automatically test it.\nI think that's a great feature and we will definitely cover that in the course once entropic realizes\nthat a third one is multi-modality so that you.\nNot only will be able to work through text, but you can also work with videos and images and so on,\nand this will be a native feature in Mcbbs.\nThen there is interactive workflows, which I think is is very important in agentic workflows.\nThat means that entropy wants to improve and develop the human in the loop feature of MCP.\nSo somehow they want to standardize how they can get you in when you work with an LMS.\nSo for example, an MCP doesn't only give you a response, but it wants to reach out to you to ask some\nabout about some properties or to ask for confirmation whatsoever.\nOkay.\nSo interactive workflows I think that's an essential piece about agent interaction.\nSo we are definitely gonna cover that here in this course.\nAnother one is streaming so that MPs can actually stream the results, not only return them as a JSON\nfile or, you know, as a as a blob, so you can have a more streamlined experience.\nAnd the last one which I'm most excited about is the MCP registry, which is like, as you've seen,\nSmithery or the reference implementations or the cursor directory.\nSo entropic develops a central MCP registry that you can go to to explore and install MCP modules.\nSo this is what they have on their roadmap and also a few other technical features.\nSo if you're interested go to the course resources, check out the roadmap link and take a deeper look.\nAnd with that, we are wrapping up the course for now.\nPlease come back from time to time, or take a look at my educational emails, because we are going\nto have regular updates for this course as MCP has been developing super, super fast and I'm sure that\nit will be developing super, super fast.\nI'll see you in the next video.",
            "dataPurpose": "item-1"
          },
          {
            "title": "102. Course Completion Certificate and Next Steps",
            "videoUrl": "https://epam.udemy.com/assets/65239469/files/2025-05-19_13-24-41-69e3679f607fe0d084dfb018baa05e9d/2/aa00d93316f00c0c9904af5b953457cc2e6d.m3u8?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiMjAyNS0wNS0xOV8xMy0yNC00MS02OWUzNjc5ZjYwN2ZlMGQwODRkZmIwMThiYWEwNWU5ZC8yLyIsImV4cCI6MTc1NTc4Njk1OH0.nut9y4bsz427cm3COo1leKavpmKGETqkvU_cYeP5ZZk&provider=cloudfront&v=1",
            "transcript": "Congratulations for completing this course on MCC.\nI hope that you found it useful.\nAnd keep in mind that I update this course regularly, so ensure that you check back from time to time,\nbecause you have lifetime access.\nAnd the whole field of MCC and I agent communications develop very, very rapidly.\nIf you want to move on, I would again suggest you to use our community discord where we can exchange\ninformation and news with each other.\nAnd in the last message in the course, I will send you a link where you can see how you can download\nyour certification and share it if you want.\nSo thank you for coming to this course again and I hope to see you soon.\nBye bye.",
            "dataPurpose": "item-2"
          }
        ]
      }
    ],
    "extractedAt": "2025-08-21T10:07:42.321Z"
  }