#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ü–µ–Ω –∏–∑ –≤–∏–¥–µ–æ
–®–∞–≥ 2: –î–µ—Ç–µ–∫—Ç–æ—Ä —Å—Ü–µ–Ω —Å PySceneDetect
"""

import os
import sys
import argparse
from pathlib import Path
from typing import List, Tuple, Optional
import json

try:
    from scenedetect import detect, ContentDetector, AdaptiveDetector
    from scenedetect.video_manager import VideoManager
    from scenedetect.scene_manager import SceneManager
    from scenedetect.frame_timecode import FrameTimecode
    from scenedetect.stats_manager import StatsManager
except ImportError:
    print("‚ùå PySceneDetect –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
    print("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install scenedetect[opencv]")
    sys.exit(1)

try:
    import cv2
except ImportError:
    print("‚ùå OpenCV –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
    print("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install opencv-python")
    sys.exit(1)


class SceneExtractor:
    def __init__(self, video_path: str, output_dir: str = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ —Å—Ü–µ–Ω
        
        :param video_path: –ü—É—Ç—å –∫ –≤–∏–¥–µ–æ —Ñ–∞–π–ª—É
        :param output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """
        self.video_path = Path(video_path)
        if not self.video_path.exists():
            raise FileNotFoundError(f"–í–∏–¥–µ–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {video_path}")
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if output_dir:
            self.output_dir = Path(output_dir)
        else:
            self.output_dir = self.video_path.parent / f"{self.video_path.stem}_scenes"
        
        self.output_dir.mkdir(exist_ok=True)
        
        # –ü–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –≤—ã–≤–æ–¥–∞
        self.frames_dir = self.output_dir / "frames"
        self.clips_dir = self.output_dir / "clips"
        self.frames_dir.mkdir(exist_ok=True)
        self.clips_dir.mkdir(exist_ok=True)
        
        self.scenes = []
        self.scene_list = []
        
    def detect_scenes(self, 
                     threshold: float = 30.0,
                     min_scene_len: float = 0.5,
                     detector_type: str = 'content') -> List[Tuple[FrameTimecode, FrameTimecode]]:
        """
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å—Ü–µ–Ω –≤ –≤–∏–¥–µ–æ
        
        :param threshold: –ü–æ—Ä–æ–≥ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (1-100, –º–µ–Ω—å—à–µ = –±–æ–ª—å—à–µ —Å—Ü–µ–Ω)
        :param min_scene_len: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å—Ü–µ–Ω—ã –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        :param detector_type: –¢–∏–ø –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ ('content' –∏–ª–∏ 'adaptive')
        :return: –°–ø–∏—Å–æ–∫ —Å—Ü–µ–Ω —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
        """
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ
        cap = cv2.VideoCapture(str(self.video_path))
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = frame_count / fps if fps > 0 else 0
        cap.release()
        
        print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∏–¥–µ–æ: {self.video_path.name}")
        print(f"   –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration:.2f}—Å")
        print(f"   –ö–∞–¥—Ä–æ–≤: {frame_count}")
        print(f"   FPS: {fps:.2f}")
        print(f"   –î–µ—Ç–µ–∫—Ç–æ—Ä: {detector_type}")
        print(f"   –ü–æ—Ä–æ–≥: {threshold}")
        print(f"   –ú–∏–Ω. –¥–ª–∏–Ω–∞ —Å—Ü–µ–Ω—ã: {min_scene_len}—Å")
        
        # –í—ã–±–∏—Ä–∞–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä
        if detector_type == 'adaptive':
            detector = AdaptiveDetector(
                adaptive_threshold=threshold,
                min_scene_len=int(min_scene_len * 30)  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –∫–∞–¥—Ä—ã (–ø—Ä–∏–º–µ—Ä–Ω–æ 30fps)
            )
        else:
            detector = ContentDetector(
                threshold=threshold,
                min_scene_len=int(min_scene_len * 30)
            )
        
        # –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ–º —Å—Ü–µ–Ω—ã
        try:
            self.scene_list = detect(str(self.video_path), detector)
            
            print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å—Ü–µ–Ω: {len(self.scene_list)}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ü–µ–Ω–∞—Ö
            self.scenes = []
            for i, (start_time, end_time) in enumerate(self.scene_list):
                duration = end_time - start_time
                scene_info = {
                    'index': i,
                    'start_time': start_time.get_seconds(),
                    'end_time': end_time.get_seconds(),
                    'duration': duration.get_seconds(),
                    'start_frame': start_time.get_frames(),
                    'end_frame': end_time.get_frames()
                }
                self.scenes.append(scene_info)
                
                print(f"   –°—Ü–µ–Ω–∞ {i+1:03d}: {self._format_time(scene_info['start_time'])} - "
                      f"{self._format_time(scene_info['end_time'])} "
                      f"(–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {scene_info['duration']:.2f}—Å)")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            self._save_metadata()
            
            return self.scene_list
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ —Å—Ü–µ–Ω: {str(e)}")
            return []
    
    def extract_frames(self, 
                      frame_type: str = 'middle',
                      quality: int = 95) -> List[str]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ –∏–∑ –∫–∞–∂–¥–æ–π —Å—Ü–µ–Ω—ã
        
        :param frame_type: –¢–∏–ø –∫–∞–¥—Ä–∞ ('first', 'middle', 'last', 'best')
        :param quality: –ö–∞—á–µ—Å—Ç–≤–æ JPEG (1-100)
        :return: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–º –∫–∞–¥—Ä–∞–º
        """
        if not self.scenes:
            print("‚ö†Ô∏è  –°–Ω–∞—á–∞–ª–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ–±–Ω–∞—Ä—É–∂–∏—Ç—å —Å—Ü–µ–Ω—ã!")
            return []
        
        print(f"\nüì∏ –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã ({frame_type}) –∏–∑ {len(self.scenes)} —Å—Ü–µ–Ω...")
        
        cap = cv2.VideoCapture(str(self.video_path))
        if not cap.isOpened():
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {self.video_path}")
            return []
        
        saved_frames = []
        
        try:
            for scene in self.scenes:
                frame_num = self._get_frame_number(scene, frame_type)
                
                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –Ω—É–∂–Ω–æ–º—É –∫–∞–¥—Ä—É
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
                ret, frame = cap.read()
                
                if ret:
                    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞
                    time_str = self._format_time(scene['start_time'], for_filename=True)
                    frame_path = self.frames_dir / f"scene_{scene['index']+1:03d}_{time_str}.jpg"
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–¥—Ä
                    cv2.imwrite(str(frame_path), frame, 
                               [cv2.IMWRITE_JPEG_QUALITY, quality])
                    
                    saved_frames.append(str(frame_path))
                    print(f"   ‚úì –°—Ü–µ–Ω–∞ {scene['index']+1:03d} -> {frame_path.name}")
                else:
                    print(f"   ‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∫–∞–¥—Ä –¥–ª—è —Å—Ü–µ–Ω—ã {scene['index']+1}")
        
        finally:
            cap.release()
        
        print(f"\n‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–∞–¥—Ä–æ–≤: {len(saved_frames)}")
        return saved_frames
    
    def extract_clips(self, use_ffmpeg: bool = True) -> List[str]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–∏–¥–µ–æ –∫–ª–∏–ø–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ü–µ–Ω—ã
        
        :param use_ffmpeg: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å FFmpeg (True) –∏–ª–∏ OpenCV (False)
        :return: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–º –∫–ª–∏–ø–∞–º
        """
        if not self.scenes:
            print("‚ö†Ô∏è  –°–Ω–∞—á–∞–ª–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ–±–Ω–∞—Ä—É–∂–∏—Ç—å —Å—Ü–µ–Ω—ã!")
            return []
        
        print(f"\nüé¨ –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª–∏–ø—ã –∏–∑ {len(self.scenes)} —Å—Ü–µ–Ω...")
        
        saved_clips = []
        
        if use_ffmpeg:
            import subprocess
            
            for scene in self.scenes:
                # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞
                time_str = self._format_time(scene['start_time'], for_filename=True)
                clip_path = self.clips_dir / f"scene_{scene['index']+1:03d}_{time_str}.mp4"
                
                # –ö–æ–º–∞–Ω–¥–∞ FFmpeg –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª–∏–ø–∞
                cmd = [
                    "ffmpeg",
                    "-i", str(self.video_path),
                    "-ss", str(scene['start_time']),
                    "-t", str(scene['duration']),
                    "-c", "copy",  # –ö–æ–ø–∏—Ä—É–µ–º –±–µ–∑ –ø–µ—Ä–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
                    "-avoid_negative_ts", "make_zero",
                    "-y",
                    str(clip_path)
                ]
                
                try:
                    result = subprocess.run(cmd, 
                                          capture_output=True, 
                                          text=True)
                    if result.returncode == 0:
                        saved_clips.append(str(clip_path))
                        print(f"   ‚úì –°—Ü–µ–Ω–∞ {scene['index']+1:03d} -> {clip_path.name} "
                              f"({scene['duration']:.2f}—Å)")
                    else:
                        print(f"   ‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Å—Ü–µ–Ω—ã {scene['index']+1}")
                except Exception as e:
                    print(f"   ‚úó –û—à–∏–±–∫–∞: {str(e)}")
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º OpenCV (–º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç FFmpeg)
            cap = cv2.VideoCapture(str(self.video_path))
            fps = cap.get(cv2.CAP_PROP_FPS)
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            
            for scene in self.scenes:
                time_str = self._format_time(scene['start_time'], for_filename=True)
                clip_path = self.clips_dir / f"scene_{scene['index']+1:03d}_{time_str}.mp4"
                
                # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –≤–∏–¥–µ–æ writer
                cap.set(cv2.CAP_PROP_POS_FRAMES, scene['start_frame'])
                ret, frame = cap.read()
                if not ret:
                    continue
                    
                height, width = frame.shape[:2]
                out = cv2.VideoWriter(str(clip_path), fourcc, fps, (width, height))
                
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∫–∞–¥—Ä—ã
                for frame_num in range(scene['start_frame'], scene['end_frame']):
                    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
                    ret, frame = cap.read()
                    if ret:
                        out.write(frame)
                
                out.release()
                saved_clips.append(str(clip_path))
                print(f"   ‚úì –°—Ü–µ–Ω–∞ {scene['index']+1:03d} -> {clip_path.name}")
            
            cap.release()
        
        print(f"\n‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∫–ª–∏–ø–æ–≤: {len(saved_clips)}")
        return saved_clips
    
    def split_equal_parts(self, num_parts: int = 10) -> List[Tuple[float, float]]:
        """
        –†–∞–∑–±–∏—Ç—å –≤–∏–¥–µ–æ –Ω–∞ —Ä–∞–≤–Ω—ã–µ —á–∞—Å—Ç–∏ (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å—Ü–µ–Ω)
        
        :param num_parts: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å—Ç–µ–π
        :return: –°–ø–∏—Å–æ–∫ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
        """
        cap = cv2.VideoCapture(str(self.video_path))
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = frame_count / fps if fps > 0 else 0
        cap.release()
        
        print(f"\n‚úÇÔ∏è –†–∞–∑–±–∏–≤–∞–µ–º –≤–∏–¥–µ–æ –Ω–∞ {num_parts} —Ä–∞–≤–Ω—ã—Ö —á–∞—Å—Ç–µ–π")
        
        part_duration = duration / num_parts
        self.scenes = []
        
        for i in range(num_parts):
            start_time = i * part_duration
            end_time = min((i + 1) * part_duration, duration)
            
            scene_info = {
                'index': i,
                'start_time': start_time,
                'end_time': end_time,
                'duration': end_time - start_time,
                'start_frame': int(start_time * fps),
                'end_frame': int(end_time * fps)
            }
            self.scenes.append(scene_info)
            
            print(f"   –ß–∞—Å—Ç—å {i+1:03d}: {self._format_time(start_time)} - "
                  f"{self._format_time(end_time)} "
                  f"(–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {scene_info['duration']:.2f}—Å)")
        
        self._save_metadata()
        return self.scenes
    
    def _get_frame_number(self, scene: dict, frame_type: str) -> int:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–º–µ—Ä–∞ –∫–∞–¥—Ä–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞"""
        if frame_type == 'first':
            return scene['start_frame']
        elif frame_type == 'last':
            return scene['end_frame'] - 1
        elif frame_type == 'middle':
            return (scene['start_frame'] + scene['end_frame']) // 2
        else:  # 'best' - –±–µ—Ä–µ–º –∫–∞–¥—Ä —á—É—Ç—å –ø–æ—Å–ª–µ –Ω–∞—á–∞–ª–∞ (–æ–±—ã—á–Ω–æ –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–π)
            offset = min(30, (scene['end_frame'] - scene['start_frame']) // 10)
            return scene['start_frame'] + offset
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–º–µ—Ä–∞ –∫–∞–¥—Ä–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞"""
        if frame_type == 'first':
            return scene['start_frame']
        elif frame_type == 'last':
            return scene['end_frame'] - 1
        elif frame_type == 'middle':
            return (scene['start_frame'] + scene['end_frame']) // 2
        else:  # 'best' - –±–µ—Ä–µ–º –∫–∞–¥—Ä —á—É—Ç—å –ø–æ—Å–ª–µ –Ω–∞—á–∞–ª–∞ (–æ–±—ã—á–Ω–æ –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–π)
            offset = min(30, (scene['end_frame'] - scene['start_frame']) // 10)
            return scene['start_frame'] + offset
    
    def _format_time(self, seconds: float, for_filename: bool = False) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        
        if for_filename:
            return f"{hours:02d}h{minutes:02d}m{secs:02d}s"
        else:
            return f"{hours:02d}:{minutes:02d}:{secs:02d}"
    
    def _save_metadata(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –æ —Å—Ü–µ–Ω–∞—Ö"""
        metadata = {
            'video': str(self.video_path),
            'total_scenes': len(self.scenes),
            'scenes': self.scenes
        }
        
        metadata_path = self.output_dir / 'scenes_metadata.json'
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        print(f"\nüíæ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metadata_path}")
    
    def generate_summary(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏"""
        if not self.scenes:
            return
        
        html_content = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>–ê–Ω–∞–ª–∏–∑ —Å—Ü–µ–Ω: {self.video_path.name}</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }}
        h1 {{ color: #333; }}
        .scene {{ 
            background: white; 
            margin: 20px 0; 
            padding: 15px; 
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        .scene img {{ 
            max-width: 100%; 
            height: auto; 
            border-radius: 4px;
        }}
        .scene-info {{ 
            margin: 10px 0; 
            color: #666;
        }}
        .stats {{
            background: #e8f4f8;
            padding: 15px;
            border-radius: 8px;
            margin: 20px 0;
        }}
    </style>
</head>
<body>
    <h1>üìπ –ê–Ω–∞–ª–∏–∑ —Å—Ü–µ–Ω: {self.video_path.name}</h1>
    
    <div class="stats">
        <h2>üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞</h2>
        <p>–í—Å–µ–≥–æ —Å—Ü–µ–Ω: <strong>{len(self.scenes)}</strong></p>
        <p>–°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: <strong>{sum(s['duration'] for s in self.scenes) / len(self.scenes):.2f}</strong> —Å–µ–∫</p>
        <p>–û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: <strong>{sum(s['duration'] for s in self.scenes):.2f}</strong> —Å–µ–∫</p>
    </div>
    
    <h2>üé¨ –°—Ü–µ–Ω—ã</h2>
"""
        
        for scene in self.scenes:
            time_str = self._format_time(scene['start_time'], for_filename=True)
            frame_path = f"frames/scene_{scene['index']+1:03d}_{time_str}.jpg"
            
            html_content += f"""
    <div class="scene">
        <h3>–°—Ü–µ–Ω–∞ {scene['index']+1}</h3>
        <img src="{frame_path}" alt="–°—Ü–µ–Ω–∞ {scene['index']+1}">
        <div class="scene-info">
            <p>‚è±Ô∏è –í—Ä–µ–º—è: {self._format_time(scene['start_time'])} - {self._format_time(scene['end_time'])}</p>
            <p>‚è≥ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {scene['duration']:.2f} —Å–µ–∫</p>
            <p>üéûÔ∏è –ö–∞–¥—Ä—ã: {scene['start_frame']} - {scene['end_frame']}</p>
        </div>
    </div>
"""
        
        html_content += """
</body>
</html>
"""
        
        html_path = self.output_dir / 'summary.html'
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"üìÑ HTML –æ—Ç—á–µ—Ç: {html_path}")


def main():
    parser = argparse.ArgumentParser(
        description="–î–µ—Ç–µ–∫—Ç–æ—Ä –∏ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —Å—Ü–µ–Ω –∏–∑ –≤–∏–¥–µ–æ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  # –ë–∞–∑–æ–≤–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å—Ü–µ–Ω
  python scene_detector.py video.mp4
  
  # –° –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –∫–∞–¥—Ä–æ–≤
  python scene_detector.py video.mp4 --extract-frames
  
  # –° –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –∫–ª–∏–ø–æ–≤
  python scene_detector.py video.mp4 --extract-clips
  
  # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–º–µ–Ω—å—à–µ = –±–æ–ª—å—à–µ —Å—Ü–µ–Ω)
  python scene_detector.py video.mp4 --threshold 20
  
  # –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
  python scene_detector.py video.mp4 --extract-frames --extract-clips --html
        """
    )
    
    parser.add_argument(
        "video",
        help="–ü—É—Ç—å –∫ –≤–∏–¥–µ–æ —Ñ–∞–π–ª—É"
    )
    
    parser.add_argument(
        "-o", "--output",
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
        default=None
    )
    
    parser.add_argument(
        "--threshold",
        type=float,
        default=30.0,
        help="–ü–æ—Ä–æ–≥ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (1-100, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 30)"
    )
    
    parser.add_argument(
        "--min-scene-len",
        type=float,
        default=0.5,
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å—Ü–µ–Ω—ã –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.5)"
    )
    
    parser.add_argument(
        "--detector",
        choices=['content', 'adaptive'],
        default='content',
        help="–¢–∏–ø –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: content)"
    )
    
    parser.add_argument(
        "--extract-frames",
        action="store_true",
        help="–ò–∑–≤–ª–µ—á—å –∫–∞–¥—Ä—ã –∏–∑ —Å—Ü–µ–Ω"
    )
    
    parser.add_argument(
        "--frame-type",
        choices=['first', 'middle', 'last', 'best'],
        default='middle',
        help="–ö–∞–∫–æ–π –∫–∞–¥—Ä –∏–∑–≤–ª–µ–∫–∞—Ç—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: middle)"
    )
    
    parser.add_argument(
        "--extract-clips",
        action="store_true",
        help="–ò–∑–≤–ª–µ—á—å –≤–∏–¥–µ–æ –∫–ª–∏–ø—ã –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ü–µ–Ω—ã"
    )
    
    parser.add_argument(
        "--html",
        action="store_true",
        help="–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å HTML –æ—Ç—á–µ—Ç"
    )
    
    parser.add_argument(
        "--split-equal",
        type=int,
        metavar="N",
        help="–†–∞–∑–±–∏—Ç—å –≤–∏–¥–µ–æ –Ω–∞ N —Ä–∞–≤–Ω—ã—Ö —á–∞—Å—Ç–µ–π –≤–º–µ—Å—Ç–æ –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å—Ü–µ–Ω"
    )
    
    parser.add_argument(
        "--quality",
        type=int,
        default=95,
        help="–ö–∞—á–µ—Å—Ç–≤–æ JPEG –¥–ª—è –∫–∞–¥—Ä–æ–≤ (1-100, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 95)"
    )
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
    extractor = SceneExtractor(args.video, args.output)
    
    # –í—ã–±–∏—Ä–∞–µ–º –º–µ—Ç–æ–¥ —Ä–∞–∑–±–∏–µ–Ω–∏—è
    if args.split_equal:
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Ä–∞–≤–Ω—ã–µ —á–∞—Å—Ç–∏
        scenes = extractor.split_equal_parts(args.split_equal)
    else:
        # –û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ–º —Å—Ü–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        scenes = extractor.detect_scenes(
            threshold=args.threshold,
            min_scene_len=args.min_scene_len,
            detector_type=args.detector
        )
    
    if not scenes:
        print("‚ùå –°—Ü–µ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        sys.exit(1)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if args.extract_frames:
        extractor.extract_frames(
            frame_type=args.frame_type,
            quality=args.quality
        )
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª–∏–ø—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if args.extract_clips:
        extractor.extract_clips()
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º HTML –æ—Ç—á–µ—Ç
    if args.html:
        extractor.generate_summary()
    
    print(f"\n‚ú® –ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {extractor.output_dir}")


if __name__ == "__main__":
    main()