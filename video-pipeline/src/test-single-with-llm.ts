import dotenv from 'dotenv'
import { FileUtils } from './utils/file-utils.js'
import { SimpleHtmlParser } from './utils/simple-html-parser.js'
import { SimpleLLMService } from './services/simple-llm-service.js'
import { PipelineConfig, CourseModule } from './types/index.js'

// Load environment variables
dotenv.config()

async function testSingleModuleWithLLM() {
  try {
    console.log('üß™ Testing single module processing with LLM...')
    
    // Configuration
    const config: PipelineConfig = {
      inputDir: process.env.INPUT_DIR || 'course_output_20250821_122616',
      outputDir: 'test_output',
      templateFile: process.env.TEMPLATE_FILE || 'template.md',
      openaiApiKey: process.env.OPENAI_API_KEY || '',
      model: 'gpt-4-turbo-preview',
      temperature: 0.3,
      maxTokens: 4000
    }

    // Validate configuration
    if (!config.openaiApiKey) {
      throw new Error('OPENAI_API_KEY is required. Please set it in your .env file.')
    }

    // Test with a specific module
    const testModuleName = '1._28._Third-Party_MCP_Hubs'
    const modulePath = `${config.inputDir}/${testModuleName}`
    
    if (!await FileUtils.directoryExists(modulePath)) {
      throw new Error(`Test module directory does not exist: ${modulePath}`)
    }

    // Parse module
    const module = FileUtils.parseModuleFromDirectory(testModuleName, config.inputDir)
    console.log(`üìö Testing module: ${module.title}`)

    // Get transcript content
    let transcript = ''
    if (await FileUtils.fileExists(module.htmlPath!)) {
      transcript = await SimpleHtmlParser.extractTranscriptFromHtml(module.htmlPath!)
      console.log(`‚úÖ Extracted transcript from HTML (${transcript.length} characters)`)
    } else if (await FileUtils.fileExists(module.transcriptPath!)) {
      transcript = await FileUtils.readFile(module.transcriptPath!)
      console.log(`‚úÖ Read transcript from txt file (${transcript.length} characters)`)
    } else {
      throw new Error('No transcript content found')
    }

    // Load template
    let template = ''
    try {
      template = await FileUtils.readFile(config.templateFile)
      console.log(`‚úÖ Loaded template from ${config.templateFile}`)
    } catch (error) {
      console.log('‚ö†Ô∏è Template file not found, using default template')
      template = `# {MODULE_TITLE}

## Overview
{OVERVIEW_SECTION}

## Key Concepts
{KEY_CONCEPTS_SECTION}

## Main Content
{MAIN_CONTENT_SECTION}

## Summary
{SUMMARY_SECTION}`
    }

    // Initialize LLM service
    const llmService = new SimpleLLMService({
      openaiApiKey: config.openaiApiKey,
      model: config.model,
      temperature: config.temperature,
      maxTokens: config.maxTokens
    })

    // Process with LLM (using a small chunk for testing)
    const testChunk = transcript.substring(0, 2000) // First 2000 characters
    console.log(`üì§ Sending ${testChunk.length} characters to LLM...`)
    
    const llmResponse = await llmService.processContent(
      testChunk,
      template,
      module.title
    )
    
    console.log(`‚úÖ LLM processing successful!`)
    console.log(`üìä Response length: ${llmResponse.content.length} characters`)
    console.log(`üí° First 500 characters of response:`)
    console.log(llmResponse.content.substring(0, 500) + '...')
    
    if (llmResponse.usage) {
      console.log(`üî¢ Token usage: ${llmResponse.usage.totalTokens} tokens`)
      console.log(`üì§ Prompt tokens: ${llmResponse.usage.promptTokens}`)
      console.log(`üì• Completion tokens: ${llmResponse.usage.completionTokens}`)
    }

    // Save test output
    const outputPath = `${config.outputDir}/test_${module.id}.md`
    await FileUtils.writeFile(outputPath, llmResponse.content)
    console.log(`üíæ Test output saved to: ${outputPath}`)

    console.log('\n‚úÖ Single module LLM test completed successfully!')

  } catch (error) {
    console.error('‚ùå Test failed:', error)
    process.exit(1)
  }
}

// Run the test
testSingleModuleWithLLM()
